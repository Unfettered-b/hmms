{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99fd6d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "rightnow = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "LINEAGE_LEVEL = \"family\"\n",
    "HMM_FILE = \"ascogs_escrt_system_20260116_121403.tsv\"\n",
    "FLANK_K = 0               # number of 'other' tokens allowed at each flank\n",
    "\n",
    "NOTEBOOK_PATH = Path.cwd() / \"ESCRT_system_synteny.ipynb\"\n",
    "\n",
    "WINDOW = 5\n",
    "CORE_TARGETS = (\"vps\", \"escrt\", \"katanin\", \"eap\", \"flad\")\n",
    "\n",
    "MAIN_OUTDIR = os.path.join(os.getcwd(), f\"ESCRT_synteny_pipeline_output_{LINEAGE_LEVEL}_{rightnow}\")\n",
    "os.makedirs(MAIN_OUTDIR, exist_ok=True)\n",
    "\n",
    "def setup_logging(log_file=None):\n",
    "    \"\"\"\n",
    "    Configure logging for the pipeline.\n",
    "    Logs to stdout and optionally to a file.\n",
    "    \"\"\"\n",
    "    handlers = [logging.StreamHandler(sys.stdout)]\n",
    "    if log_file:\n",
    "        handlers.append(logging.FileHandler(log_file))\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "        handlers=handlers,\n",
    "        force=True  # Force reconfiguration if already set\n",
    "    )\n",
    "\n",
    "\n",
    "STEP = 0\n",
    "\n",
    "setup_logging(os.path.join(MAIN_OUTDIR, f\"ESCRT_synteny_pipeline{rightnow}.log\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25546ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:08:12,880 [INFO] HMM hits file: /home/anirudh/synteny/hmms/ESCRT_results/hits/ESCRT_hits_final.csv\n",
      "2026-01-21 11:08:12,881 [INFO] Protein metadata file: /home/anirudh/synteny/proteins_genomes_cp90_con5.csv\n",
      "2026-01-21 11:08:12,881 [INFO] Merged output file: /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/[STEP:1]ESCRT_hits_final_merged_2026-01-21-11-08-12.csv\n",
      "2026-01-21 11:08:12,905 [INFO] HMM hits columns: ['target', 'tacc', 'tlen', 'query', 'qacc', 'qlen', 'full_evalue', 'full_score', 'full_bias', 'dom_idx', 'dom_count', 'c_evalue', 'i_evalue', 'dom_score', 'dom_bias', 'hmm_from', 'hmm_to', 'ali_from', 'ali_to', 'env_from', 'env_to', 'acc', 'description', 'source_file']\n",
      "2026-01-21 11:08:12,906 [INFO] HMM hits rows: 24597\n",
      "2026-01-21 11:08:16,911 [INFO] Protein metadata columns: ['Name', 'Completeness', 'Contamination', 'Completeness_Model_Used', 'Translation_Table_Used', 'Coding_Density', 'Contig_N50', 'Average_Gene_Length', 'Genome_Size', 'GC_Content', 'Total_Coding_Sequences', 'Total_Contigs', 'Max_Contig_Length', 'Additional_Notes', 'Unnamed: 0', 'organism_name', 'breed', 'strain', 'cds_id', 'header', 'genome_file', 'sequence']\n",
      "2026-01-21 11:08:16,912 [INFO] Protein metadata rows: 390025\n",
      "2026-01-21 11:08:16,912 [INFO] Input sanity checks passed\n",
      "2026-01-21 11:08:16,913 [INFO] Merging HMM hits with protein metadata\n",
      "2026-01-21 11:08:16,913 [INFO] Rows before merge: hits=24597, proteins=390025\n",
      "2026-01-21 11:08:16,971 [INFO] Rows after merge: 24597\n",
      "2026-01-21 11:08:16,973 [INFO] Unique targets merged: 7285\n",
      "2026-01-21 11:08:17,283 [INFO] Merged output written to: /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/[STEP:1]ESCRT_hits_final_merged_2026-01-21-11-08-12.csv\n"
     ]
    }
   ],
   "source": [
    "# Merge HMM hits with protein metadata\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Input files\n",
    "# ----------------------------\n",
    "hits_file = \"/home/anirudh/synteny/hmms/ESCRT_results/hits/ESCRT_hits_final.csv\"\n",
    "proteins_file = \"/home/anirudh/synteny/proteins_genomes_cp90_con5.csv\"\n",
    "\n",
    "# ----------------------------\n",
    "# Output file naming\n",
    "# ----------------------------\n",
    "hits_file_name = os.path.basename(hits_file).split(\".\")[0]\n",
    "STEP += 1\n",
    "merge_file_name = os.path.join(MAIN_OUTDIR, f\"[STEP:{STEP}]{hits_file_name}_merged_{rightnow}.csv\")\n",
    "\n",
    "logging.info(\"HMM hits file: %s\", hits_file)\n",
    "logging.info(\"Protein metadata file: %s\", proteins_file)\n",
    "logging.info(\"Merged output file: %s\", merge_file_name)\n",
    "\n",
    "# ----------------------------\n",
    "# Load HMM hits\n",
    "# ----------------------------\n",
    "try:\n",
    "    hits = pd.read_csv(hits_file)\n",
    "except Exception as e:\n",
    "    logging.error(\"Failed to load HMM hits file: %s\", e)\n",
    "    raise\n",
    "\n",
    "hits.columns = hits.columns.str.strip()\n",
    "logging.info(\"HMM hits columns: %s\", list(hits.columns))\n",
    "logging.info(\"HMM hits rows: %d\", len(hits))\n",
    "\n",
    "# ----------------------------\n",
    "# Load protein metadata\n",
    "# ----------------------------\n",
    "try:\n",
    "    proteins = pd.read_csv(proteins_file)\n",
    "except Exception as e:\n",
    "    logging.error(\"Failed to load protein metadata file: %s\", e)\n",
    "    raise\n",
    "\n",
    "proteins.columns = proteins.columns.str.strip()\n",
    "logging.info(\"Protein metadata columns: %s\", list(proteins.columns))\n",
    "logging.info(\"Protein metadata rows: %d\", len(proteins))\n",
    "\n",
    "# ----------------------------\n",
    "# Sanity checks before merge\n",
    "# ----------------------------\n",
    "required_hits_cols = {\"target\"}\n",
    "required_prot_cols = {\"cds_id\"}\n",
    "\n",
    "missing_hits = required_hits_cols - set(hits.columns)\n",
    "missing_prots = required_prot_cols - set(proteins.columns)\n",
    "\n",
    "if missing_hits:\n",
    "    logging.error(\"Missing required columns in HMM hits file: %s\", missing_hits)\n",
    "    raise ValueError(f\"Missing columns in hits file: {missing_hits}\")\n",
    "\n",
    "if missing_prots:\n",
    "    logging.error(\"Missing required columns in protein metadata file: %s\", missing_prots)\n",
    "    raise ValueError(f\"Missing columns in proteins file: {missing_prots}\")\n",
    "\n",
    "logging.info(\"Input sanity checks passed\")\n",
    "\n",
    "# ----------------------------\n",
    "# Merge HMM hits with protein metadata\n",
    "# ----------------------------\n",
    "logging.info(\"Merging HMM hits with protein metadata\")\n",
    "logging.info(\"Rows before merge: hits=%d, proteins=%d\", len(hits), len(proteins))\n",
    "\n",
    "merged = pd.merge(\n",
    "    hits,\n",
    "    proteins,\n",
    "    left_on=\"target\",\n",
    "    right_on=\"cds_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "logging.info(\"Rows after merge: %d\", len(merged))\n",
    "logging.info(\"Unique targets merged: %d\", merged[\"target\"].nunique())\n",
    "\n",
    "# ----------------------------\n",
    "# Write output\n",
    "# ----------------------------\n",
    "try:\n",
    "    \n",
    "    merged.to_csv(merge_file_name, index=False)\n",
    "except Exception as e:\n",
    "    logging.error(\"Failed to write merged output file %s: %s\", merge_file_name, e)\n",
    "    raise\n",
    "\n",
    "logging.info(\"Merged output written to: %s\", merge_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5357cf73",
   "metadata": {},
   "source": [
    "Merge with the ascogs definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53f1d3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:08:17,290 [INFO] Loading AsCOGs from: /home/anirudh/synteny/hmms/Sources/ascogs_escrt_system_20260116_121403.tsv\n",
      "2026-01-21 11:08:17,292 [INFO] AsCOGs columns: ['ascog_id', 'arcog_id', 'category', 'gene', 'description']\n",
      "2026-01-21 11:08:17,293 [INFO] AsCOGs rows: 89\n",
      "2026-01-21 11:08:17,294 [INFO] AsCOGs sanity check passed\n",
      "2026-01-21 11:08:17,294 [INFO] Merging HMM hits with AsCOG annotations\n",
      "2026-01-21 11:08:17,295 [INFO] HMM hits rows before merge: 24597\n",
      "2026-01-21 11:08:17,305 [INFO] Rows after AsCOG merge: 24597\n",
      "2026-01-21 11:08:17,306 [INFO] Unique AsCOGs matched: 88\n",
      "2026-01-21 11:08:17,308 [INFO] Unique proteins matched: 7285\n",
      "2026-01-21 11:08:17,434 [INFO] Final merged file written to: /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/[STEP:2]ESCRT_hits_final_merged_2026-01-21-11-08-12_ascog.csv\n"
     ]
    }
   ],
   "source": [
    "# Merge HMM hits with AsCOG annotations\n",
    "\n",
    "# ----------------------------\n",
    "# Load AsCOG annotation table\n",
    "# ----------------------------\n",
    "ascogs_tsv = f\"/home/anirudh/synteny/hmms/Sources/{HMM_FILE}\"\n",
    "logging.info(\"Loading AsCOGs from: %s\", ascogs_tsv)\n",
    "\n",
    "try:\n",
    "    ascogs = pd.read_csv(ascogs_tsv, sep=\"\\t\")\n",
    "except Exception as e:\n",
    "    logging.error(\"Failed to load AsCOGs file: %s\", e)\n",
    "    raise\n",
    "\n",
    "ascogs.columns = ascogs.columns.str.strip()\n",
    "\n",
    "logging.info(\"AsCOGs columns: %s\", list(ascogs.columns))\n",
    "logging.info(\"AsCOGs rows: %d\", len(ascogs))\n",
    "\n",
    "# ----------------------------\n",
    "# Sanity checks\n",
    "# ----------------------------\n",
    "required_cols = {\"ascog_id\"}\n",
    "missing = required_cols - set(ascogs.columns)\n",
    "\n",
    "if missing:\n",
    "    logging.error(\"Missing required columns in AsCOGs file: %s\", missing)\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "logging.info(\"AsCOGs sanity check passed\")\n",
    "\n",
    "# ----------------------------\n",
    "# Merge HMM hits with AsCOGs\n",
    "# ----------------------------\n",
    "logging.info(\"Merging HMM hits with AsCOG annotations\")\n",
    "logging.info(\"HMM hits rows before merge: %d\", len(merged))\n",
    "\n",
    "merged_ascogs = pd.merge(\n",
    "    merged,\n",
    "    ascogs,\n",
    "    left_on=\"query\",\n",
    "    right_on=\"ascog_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "logging.info(\"Rows after AsCOG merge: %d\", len(merged_ascogs))\n",
    "logging.info(\"Unique AsCOGs matched: %d\", merged_ascogs[\"ascog_id\"].nunique())\n",
    "logging.info(\"Unique proteins matched: %d\", merged_ascogs[\"target\"].nunique())\n",
    "\n",
    "# ----------------------------\n",
    "# Write output\n",
    "# ----------------------------\n",
    "STEP += 1\n",
    "final_output_file = os.path.join(MAIN_OUTDIR, f\"[STEP:{STEP}]ESCRT_hits_final_merged_{rightnow}_ascog.csv\")\n",
    "\n",
    "merged_ascogs = merged_ascogs[[\"target\", \"tacc\", \"tlen\", \"query\", \"qacc\", \"qlen\", \"c_evalue\", \"i_evalue\", \"dom_score\",  \"hmm_from\", \"hmm_to\", \"ali_from\", \"ali_to\", \"env_from\", \"env_to\", \"acc\", \"Name\", \"Completeness\", \"Contamination\", \"Contig_N50\", \"Total_Contigs\", \"organism_name\", \"cds_id\", \"header\", \"gene\", \"description_y\"]]\n",
    "\n",
    "try:\n",
    "    merged_ascogs.to_csv(final_output_file, index=False)\n",
    "except Exception as e:\n",
    "    logging.error(\"Failed to write output file %s: %s\", final_output_file, e)\n",
    "    raise\n",
    "\n",
    "logging.info(\"Final merged file written to: %s\", final_output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "626cee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:08:17,494 [INFO] Best hits file written to: /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/[STEP:3]ESCRT_hits_final_merged_2026-01-21-11-08-12_ascog_best_hits.csv\n"
     ]
    }
   ],
   "source": [
    "# Select best hits based on e-value and coverage\n",
    "\n",
    "merged_ascogs[\"coverage\"] = (\n",
    "    (merged_ascogs[\"hmm_to\"] - merged_ascogs[\"hmm_from\"] + 1)\n",
    "    / merged_ascogs[\"qlen\"]\n",
    ")\n",
    "\n",
    "merged_ascogs = (\n",
    "    merged_ascogs\n",
    "    .sort_values(\n",
    "        by=[\"target\", \"query\", \"i_evalue\", \"coverage\", \"dom_score\"],\n",
    "        ascending=[True, True, True, False, False]\n",
    "    )\n",
    ")\n",
    "best_hits = (\n",
    "    merged_ascogs\n",
    "    .drop_duplicates(subset=[\"target\", \"query\"], keep=\"first\")\n",
    ")\n",
    "\n",
    "best_hits = best_hits[(best_hits[\"i_evalue\"] <= 1e-5) & (best_hits[\"coverage\"] >= 0.65)]\n",
    "\n",
    "best_hits = best_hits[[\"target\",\"query\",\"gene\",\"dom_score\",\"i_evalue\",\"coverage\",\"description_y\",\"tacc\",\"tlen\",\"qacc\",\"qlen\",\"c_evalue\",\"hmm_from\",\"hmm_to\",\"ali_from\",\"ali_to\",\"env_from\",\"env_to\",\"acc\",\"Name\",\"Completeness\",\"Contamination\",\"Contig_N50\",\"Total_Contigs\",\"organism_name\"]]\n",
    "\n",
    "STEP += 1\n",
    "best_hits_file = os.path.join(MAIN_OUTDIR, f\"[STEP:{STEP}]ESCRT_hits_final_merged_{rightnow}_ascog_best_hits.csv\")\n",
    "\n",
    "best_hits.to_csv(best_hits_file, index=False)\n",
    "logging.info(\"Best hits file written to: %s\", best_hits_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b722f80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:08:17,576 [INFO] Computed protein counts with AsCOG hits\n"
     ]
    }
   ],
   "source": [
    "# Compute protein counts with AsCOG hits\n",
    "\n",
    "\n",
    "protein_counts = (\n",
    "    best_hits\n",
    "    .dropna(subset=[\"gene\", \"query\"])\n",
    "    .assign(\n",
    "        gene=lambda df: df[\"gene\"].str.strip(),\n",
    "        ascog_id=lambda df: df[\"query\"].str.strip()\n",
    "    )\n",
    "    .groupby(\"target\")\n",
    "    .agg(\n",
    "        ascog_hits=(\"gene\", lambda x: list(x.unique())),\n",
    "        ascog_ids=(\"query\", lambda x: list(x.unique()))\n",
    "    )\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        ascog_count=lambda df: df[\"ascog_hits\"].apply(len)\n",
    "    )\n",
    "    .sort_values(by = [\"ascog_count\"], ascending=[False])\n",
    "    .assign(\n",
    "        arch_str=lambda d: d[\"ascog_hits\"].apply(lambda x: \"+\".join(sorted(x)))\n",
    "    )\n",
    "    .sort_values(\n",
    "        by=[\"ascog_count\", \"arch_str\"],\n",
    "        ascending=[False, True]\n",
    "    )\n",
    ")\n",
    "\n",
    "logging.info(\"Computed protein counts with AsCOG hits\")\n",
    "\n",
    "STEP += 1\n",
    "protein_counts_file = os.path.join(MAIN_OUTDIR, f\"[STEP:{STEP}]protein_ascog_counts_{rightnow}.csv\")\n",
    "try:\n",
    "    protein_counts.to_csv(protein_counts_file, index=False)\n",
    "except Exception as e:\n",
    "    logging.error(\"Failed to write protein counts file %s: %s\", protein_counts_file, e)\n",
    "    raise ValueError(f\"Failed to write protein counts file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e59d2985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:08:19,662 [INFO] Inferred architectures for proteins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_930/1008619236.py:71: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(infer_architecture)\n"
     ]
    }
   ],
   "source": [
    "# Infer architectures based on rules\n",
    "\n",
    "# Order matters: first match wins\n",
    "ARCH_RULES = [\n",
    "    # Vps23 canonical\n",
    "    ({\"CC-Vps23\", \"PH-Vps23\", \"Vps23\"}, \"CC-PH-Vps23\"),\n",
    "    ({\"CC-Vps23\", \"PH-Vps23\"}, \"CC-PH-Vps23\"),\n",
    "\n",
    "    # E2–Vps23 fusion\n",
    "    ({\"E2-Vps23\", \"E2\", \"Vps23\"}, \"E2-Vps23\"),\n",
    "    ({\"E2-Vps23\", \"E2\"}, \"E2-Vps23\"),\n",
    "    ({\"E2-Vps23\", \"Vps23\"}, \"E2-Vps23\"),\n",
    "\n",
    "    # ESCRT-I–linked E2\n",
    "    ({\"Vps28\", \"E2-Vps23\", \"E2\"}, \"E2-ESCRT-I\"),\n",
    "\n",
    "    # ESCRT-II Vps22-Vps36 fusion\n",
    "    ({\"CC-Vps23\", \"EAP30\"}, \"Vps23-EAP30\"),\n",
    "\n",
    "    # MPN-E3_doms\n",
    "    ({\"MPN\", \"E3-dom\"}, \"MPN-E3-dom\"),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def infer_architecture(group: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Infer a single architecture for one protein (target)\n",
    "    using explicit rules, else fallback to best i-Evalue hit.\n",
    "    \"\"\"\n",
    "\n",
    "    # Clean gene names\n",
    "    genes = set(\n",
    "        group[\"gene\"]\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "    # 1. Apply rule-based architecture inference\n",
    "    for rule_genes, architecture in ARCH_RULES:\n",
    "        if rule_genes.issubset(genes):\n",
    "            return pd.Series({\n",
    "                \"architecture\": architecture,\n",
    "                \"architecture_method\": \"rule\",\n",
    "                \"architecture_components\": \",\".join(sorted(rule_genes))\n",
    "            })\n",
    "\n",
    "    # 2. Fallback: best single hit by independent E-value\n",
    "    best_hit = (\n",
    "        group\n",
    "        .dropna(subset=[\"i_evalue\"])\n",
    "        .sort_values(\"i_evalue\", ascending=True)\n",
    "        .iloc[0]\n",
    "    )\n",
    "\n",
    "    return pd.Series({\n",
    "        \"architecture\": best_hit[\"gene\"],\n",
    "        \"architecture_method\": \"best_i_evalue\",\n",
    "        \"architecture_components\": best_hit[\"gene\"]\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "architecture_df = (\n",
    "    best_hits\n",
    "    .dropna(subset=[\"target\", \"gene\", \"i_evalue\"])\n",
    "    .groupby(\"target\", group_keys=False)\n",
    "    .apply(infer_architecture)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df_with_arch = best_hits.merge(\n",
    "    architecture_df,\n",
    "    on=\"target\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "df_with_arch = df_with_arch[[\"target\",\"Name\",\"Completeness\",\"Contamination\",\"Contig_N50\",\"Total_Contigs\",\"organism_name\",\"architecture\",\"architecture_method\",\"architecture_components\"]]\n",
    "\n",
    "df_with_arch.drop_duplicates(inplace=True)\n",
    "logging.info(\"Inferred architectures for proteins\")\n",
    "\n",
    "STEP += 1\n",
    "df_with_arch_file = os.path.join(MAIN_OUTDIR, f\"[STEP:{STEP}]ESCRT_hits_with_architectures_{rightnow}.csv\")\n",
    "try:\n",
    "    df_with_arch.to_csv(df_with_arch_file, index=False)\n",
    "except Exception as e: \n",
    "    logging.error(\"Failed to write architecture output file %s: %s\", df_with_arch_file, e)\n",
    "    raise ValueError(f\"Failed to write architecture output file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0982af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ------------------------------------------------------------\n",
    "# # Parse Prodigal GFF and assign gene order PER CONTIG\n",
    "# # ------------------------------------------------------------\n",
    "# def parse_prodigal_gff(gff_path, genome_id):\n",
    "#     \"\"\"\n",
    "#     Parse a Prodigal GFF3 file and extract CDS gene order per contig.\n",
    "\n",
    "#     Gene order is defined by appearance order in the GFF,\n",
    "#     which corresponds to genomic order for Prodigal output.\n",
    "    \n",
    "#     Args:\n",
    "#         gff_path: Path to the GFF file\n",
    "#         genome_id: Identifier for the genome\n",
    "        \n",
    "#     Returns:\n",
    "#         DataFrame with columns: genome_id, contig, gene_index, \n",
    "#                                 protein_id, start, end, strand\n",
    "#     \"\"\"\n",
    "\n",
    "#     rows = []\n",
    "#     gene_counter = {}  # separate gene index per contig\n",
    "\n",
    "#     logging.info(f\"Parsing GFF: {gff_path.name}\")\n",
    "\n",
    "#     with open(gff_path) as f:\n",
    "#         for line in f:\n",
    "#             # Skip comment lines\n",
    "#             if line.startswith(\"#\"):\n",
    "#                 continue\n",
    "\n",
    "#             parts = line.rstrip().split(\"\\t\")\n",
    "#             if len(parts) != 9:\n",
    "#                 continue\n",
    "\n",
    "#             contig, source, feature, start, end, score, strand, phase, attrs = parts\n",
    "\n",
    "#             # Only process CDS features\n",
    "#             if feature != \"CDS\":\n",
    "#                 continue\n",
    "\n",
    "#             # Parse attributes to extract protein ID\n",
    "#             attr_dict = {}\n",
    "#             for item in attrs.split(\";\"):\n",
    "#                 if \"=\" in item:\n",
    "#                     k, v = item.split(\"=\", 1)\n",
    "#                     attr_dict[k] = v\n",
    "\n",
    "#             protein_id = attr_dict.get(\"ID\")\n",
    "#             if protein_id is None:\n",
    "#                 continue\n",
    "\n",
    "#             # Increment gene index PER CONTIG (not genome-wide)\n",
    "#             gene_counter.setdefault(contig, 0)\n",
    "#             gene_counter[contig] += 1\n",
    "\n",
    "#             rows.append({\n",
    "#                 \"genome_id\": genome_id,\n",
    "#                 \"contig\": contig,\n",
    "#                 \"gene_index\": gene_counter[contig],\n",
    "#                 \"protein_id\": protein_id,\n",
    "#                 \"start\": int(start),\n",
    "#                 \"end\": int(end),\n",
    "#                 \"strand\": strand\n",
    "#             })\n",
    "\n",
    "#     logging.info(f\"  → Parsed {len(rows)} CDS features across {len(gene_counter)} contigs\")\n",
    "#     return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# # ------------------------------------------------------------\n",
    "# # Load only the GFFs required by the hits table\n",
    "# # ------------------------------------------------------------\n",
    "# def load_gffs_from_hits(hits_df, gff_dir):\n",
    "#     \"\"\"\n",
    "#     Parse GFF files only for genomes present in the hits dataframe.\n",
    "#     GFF filenames are inferred as: <genome_file>_genomic/<genome_file>_genomic.gff\n",
    "    \n",
    "#     Args:\n",
    "#         hits_df: DataFrame containing hits with 'genome_file' column\n",
    "#         gff_dir: Directory containing GFF files\n",
    "        \n",
    "#     Returns:\n",
    "#         Combined DataFrame of all parsed GFF files\n",
    "#     \"\"\"\n",
    "\n",
    "#     all_gff_rows = []\n",
    "    \n",
    "#     unique_genomes = hits_df[\"Name\"].unique()\n",
    "#     logging.info(f\"Loading GFFs for {len(unique_genomes)} unique genomes\")\n",
    "\n",
    "#     for genome_id in unique_genomes:\n",
    "#         gff_path = gff_dir / f\"{genome_id}_genomic\" / f\"{genome_id}_genomic.gff\"\n",
    "\n",
    "#         if not gff_path.exists():\n",
    "#             logging.warning(f\"Missing GFF: {gff_path}\")\n",
    "#             continue\n",
    "\n",
    "#         gff_df = parse_prodigal_gff(gff_path, genome_id)\n",
    "#         all_gff_rows.append(gff_df)\n",
    "\n",
    "#     if not all_gff_rows:\n",
    "#         logging.error(\"No GFF files were successfully loaded.\")\n",
    "#         sys.exit(1)\n",
    "\n",
    "#     combined_gff = pd.concat(all_gff_rows, ignore_index=True)\n",
    "#     logging.info(f\"Total CDS features loaded: {len(combined_gff)}\")\n",
    "    \n",
    "#     return combined_gff\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def extract_neighborhoods(anchor_df, gff_df, window=5):\n",
    "#     \"\"\"\n",
    "#     Extract ±window gene neighborhoods around ESCRT-related anchor genes only.\n",
    "#     Anchors are filtered by architecture name containing:\n",
    "#     vps, escrt, or katanin (case-insensitive).\n",
    "#     \"\"\"\n",
    "\n",
    "#     blocks = []\n",
    "\n",
    "#     # keywords defining ESCRT relevance\n",
    "#     keywords = (\"vps\", \"escrt\", \"katanin\", \"eap\", \"flad\", \"zn-ph\")\n",
    "\n",
    "#     logging.info(f\"Starting neighborhood extraction (±{window} genes)\")\n",
    "#     logging.info(f\"Initial anchors: {len(anchor_df)}\")\n",
    "\n",
    "#     # Filter anchors by architecture name\n",
    "#     filtered_anchors = anchor_df[\n",
    "#         anchor_df[\"architecture\"]\n",
    "#         .astype(str)\n",
    "#         .str.lower()\n",
    "#         .str.contains(\"|\".join(keywords))\n",
    "#     ]\n",
    "\n",
    "#     filtered_anchors.to_csv(os.path.join(MAIN_OUTDIR, f\"[STEP:{STEP}.5]filtered_anchors_ESCRT_{rightnow}.csv\"), index=False)\n",
    "\n",
    "#     logging.info(\n",
    "#         f\"Anchors after ESCRT filter: {len(filtered_anchors)} \"\n",
    "#         f\"(skipped {len(anchor_df) - len(filtered_anchors)})\"\n",
    "#     )\n",
    "\n",
    "#     for _, row in filtered_anchors.iterrows():\n",
    "#         genome = row[\"genome_id\"]\n",
    "#         contig = row[\"contig\"]\n",
    "#         center = row[\"gene_index\"]\n",
    "\n",
    "#         if blocks and center in blocks[-1]['gene_index']:\n",
    "#             continue\n",
    "\n",
    "#         block = gff_df[\n",
    "#             (gff_df[\"genome_id\"] == genome) &\n",
    "#             (gff_df[\"contig\"] == contig) &\n",
    "#             (gff_df[\"gene_index\"].between(center - window, center + window))\n",
    "#         ].copy()\n",
    "\n",
    "#         if block.empty:\n",
    "#             continue\n",
    "\n",
    "#         block[\"center_protein\"] = row[\"protein_id\"]\n",
    "#         block[\"center_gene\"] = row[\"architecture\"]\n",
    "#         block[\"relative_pos\"] = block[\"gene_index\"] - center\n",
    "\n",
    "#         blocks.append(block)\n",
    "\n",
    "#     if not blocks:\n",
    "#         logging.error(\"No neighborhood blocks extracted after ESCRT filtering!\")\n",
    "#         sys.exit(1)\n",
    "\n",
    "#     combined_neighborhoods = pd.concat(blocks, ignore_index=True)\n",
    "\n",
    "#     logging.info(\n",
    "#         f\"Extracted {len(combined_neighborhoods)} genes \"\n",
    "#         f\"from {len(blocks)} ESCRT-related neighborhoods\"\n",
    "#     )\n",
    "\n",
    "#     return combined_neighborhoods\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def build_windows(anchor_df, window):\n",
    "#     \"\"\"\n",
    "#     Build genomic windows (start, end) around anchor genes.\n",
    "#     \"\"\"\n",
    "#     windows = []\n",
    "\n",
    "#     for _, row in anchor_df.iterrows():\n",
    "#         windows.append({\n",
    "#             \"genome_id\": row[\"genome_id\"],\n",
    "#             \"contig\": row[\"contig\"],\n",
    "#             \"winstart\": row[\"gene_index\"] - window,\n",
    "#             \"winend\": row[\"gene_index\"] + window,\n",
    "#             \"wincenter\": row[\"gene_index\"],\n",
    "#             \"protein_id\": row[\"protein_id\"],\n",
    "#             \"architecture\": row[\"architecture\"],\n",
    "#         })\n",
    "\n",
    "#     return pd.DataFrame(windows)\n",
    "\n",
    "\n",
    "# def merge_windows(windows_df):\n",
    "#     \"\"\"\n",
    "#     Merge overlapping windows per genome/contig.\n",
    "#     \"\"\"\n",
    "#     merged = []\n",
    "\n",
    "#     for (genome, contig), grp in windows_df.groupby([\"genome_id\", \"contig\"]):\n",
    "#         grp = grp.sort_values(\"winstart\")\n",
    "\n",
    "#         cur_start = None\n",
    "#         cur_end = None\n",
    "#         cur_centers = []\n",
    "\n",
    "#         for _, row in grp.iterrows():\n",
    "#             if cur_start is None:\n",
    "#                 cur_start = row[\"winstart\"]\n",
    "#                 cur_end = row[\"winend\"]\n",
    "#                 cur_centers = [row]\n",
    "#                 continue\n",
    "\n",
    "#             if row[\"winstart\"] <= cur_end + 1:\n",
    "#                 # overlap → extend\n",
    "#                 cur_end = max(cur_end, row[\"winend\"])\n",
    "#                 cur_centers.append(row)\n",
    "#             else:\n",
    "#                 merged.append({\n",
    "#                     \"genome_id\": genome,\n",
    "#                     \"contig\": contig,\n",
    "#                     \"winstart\": cur_start,\n",
    "#                     \"winend\": cur_end,\n",
    "#                     \"anchors\": cur_centers\n",
    "#                 })\n",
    "#                 cur_start = row[\"winstart\"]\n",
    "#                 cur_end = row[\"winend\"]\n",
    "#                 cur_centers = [row]\n",
    "\n",
    "#         merged.append({\n",
    "#             \"genome_id\": genome,\n",
    "#             \"contig\": contig,\n",
    "#             \"winstart\": cur_start,\n",
    "#             \"winend\": cur_end,\n",
    "#             \"anchors\": cur_centers\n",
    "#         })\n",
    "\n",
    "#     return merged\n",
    "\n",
    "\n",
    "\n",
    "# def extract_merged_neighborhoods(merged_windows, gff_df):\n",
    "#     blocks = []\n",
    "\n",
    "#     for win in merged_windows:\n",
    "#         block = gff_df[\n",
    "#             (gff_df[\"genome_id\"] == win[\"genome_id\"]) &\n",
    "#             (gff_df[\"contig\"] == win[\"contig\"]) &\n",
    "#             (gff_df[\"gene_index\"].between(win[\"winstart\"], win[\"winend\"]))\n",
    "#         ].copy()\n",
    "\n",
    "#         if block.empty:\n",
    "#             continue\n",
    "\n",
    "#         # pick a representative anchor (central-most)\n",
    "#         centers = [a[\"wincenter\"] for a in win[\"anchors\"]]\n",
    "#         rep_center = min(centers, key=lambda x: abs(x - (win[\"winstart\"] + win[\"winend\"]) / 2))\n",
    "\n",
    "#         block[\"relative_pos\"] = block[\"gene_index\"] - rep_center\n",
    "#         block[\"center_protein\"] = win[\"anchors\"][0][\"protein_id\"]\n",
    "#         block[\"center_gene\"] = win[\"anchors\"][0][\"architecture\"]\n",
    "\n",
    "#         blocks.append(block)\n",
    "\n",
    "#     return pd.concat(blocks, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# def extract_neighborhoods(anchor_df, gff_df, window=5):\n",
    "\n",
    "#     keywords = (\"vps\", \"escrt\", \"katanin\", \"eap\", \"flad\", \"zn-ph\")\n",
    "\n",
    "#     logging.info(f\"Starting neighborhood extraction (±{window} genes)\")\n",
    "#     logging.info(f\"Initial anchors: {len(anchor_df)}\")\n",
    "\n",
    "#     filtered_anchors = anchor_df[\n",
    "#         anchor_df[\"architecture\"]\n",
    "#         .astype(str)\n",
    "#         .str.lower()\n",
    "#         .str.contains(\"|\".join(keywords))\n",
    "#     ]\n",
    "\n",
    "#     logging.info(f\"Anchors after ESCRT filter: {len(filtered_anchors)}\")\n",
    "\n",
    "#     if filtered_anchors.empty:\n",
    "#         logging.error(\"No ESCRT-related anchors found\")\n",
    "#         sys.exit(1)\n",
    "\n",
    "#     windows_df = build_windows(filtered_anchors, window)\n",
    "#     merged_windows = merge_windows(windows_df)\n",
    "\n",
    "#     logging.info(\n",
    "#         f\"Merged {len(windows_df)} anchor windows into \"\n",
    "#         f\"{len(merged_windows)} non-overlapping regions\"\n",
    "#     )\n",
    "\n",
    "#     combined_neighborhoods = extract_merged_neighborhoods(\n",
    "#         merged_windows, gff_df\n",
    "#     )\n",
    "\n",
    "#     logging.info(\n",
    "#         f\"Extracted {len(combined_neighborhoods)} genes \"\n",
    "#         f\"from {len(merged_windows)} merged neighborhoods\"\n",
    "#     )\n",
    "\n",
    "#     return combined_neighborhoods\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------\n",
    "# # Load GTDB taxonomy\n",
    "# # ------------------------------------------------------------\n",
    "# def load_gtdb_taxonomy(gtdb_tsv):\n",
    "#     \"\"\"\n",
    "#     Load GTDB taxonomy file and split into rank-specific columns.\n",
    "    \n",
    "#     GTDB format: genome_id\\td__Domain;p__Phylum;c__Class;o__Order;f__Family;g__Genus;s__Species\n",
    "    \n",
    "#     Args:\n",
    "#         gtdb_tsv: Path to GTDB taxonomy TSV file\n",
    "        \n",
    "#     Returns:\n",
    "#         DataFrame with columns: genome_id, domain, phylum, class, order, family, genus, species\n",
    "#     \"\"\"\n",
    "#     logging.info(f\"Loading GTDB taxonomy from: {gtdb_tsv}\")\n",
    "    \n",
    "#     # Read the taxonomy file\n",
    "#     tax_df = pd.read_csv(\n",
    "#         gtdb_tsv,\n",
    "#         sep=\"\\t\",\n",
    "#         header=None,\n",
    "#         names=[\"genome_id\", \"taxonomy\"],\n",
    "#         dtype=str\n",
    "#     )\n",
    "    \n",
    "#     tax_df[\"genome_id_base\"] = tax_df[\"genome_id\"].str.split(\"_\", n=1).str[1]\n",
    "#     logging.info(f\"Loaded taxonomy for {len(tax_df)} genomes\")\n",
    "#     logging.info(f\"Sample taxonomy entry: {tax_df['taxonomy'].iloc[0]}\")\n",
    "    \n",
    "#     # Split taxonomy string by semicolons\n",
    "#     tax_split = tax_df[\"taxonomy\"].str.split(\";\", expand=True)\n",
    "#     logging.info(f\"Taxonomy split into {tax_split.shape[1]} columns\")\n",
    "    \n",
    "#     # Map column indices to taxonomic ranks\n",
    "#     rank_map = {\n",
    "#         0: \"domain\",\n",
    "#         1: \"phylum\",\n",
    "#         2: \"class\",\n",
    "#         3: \"order\",\n",
    "#         4: \"family\",\n",
    "#         5: \"genus\",\n",
    "#         6: \"species\"\n",
    "#     }\n",
    "    \n",
    "#     # Extract each rank and remove the prefix (e.g., \"d__\", \"p__\")\n",
    "#     for idx, rank in rank_map.items():\n",
    "#         if idx < tax_split.shape[1]:\n",
    "#             # Remove the rank prefix using regex (e.g., \"p__\" from \"p__Crenarchaeota\")\n",
    "#             tax_df[rank] = tax_split[idx].str.replace(r\"^[a-z]__\", \"\", regex=True)\n",
    "#             logging.info(f\"Extracted {rank}: {tax_df[rank].notna().sum()} non-null values\")\n",
    "#         else:\n",
    "#             tax_df[rank] = pd.NA\n",
    "#             logging.warning(f\"Column {idx} for rank '{rank}' not found in taxonomy data\")\n",
    "    \n",
    "#     # Drop the original concatenated taxonomy string\n",
    "#     tax_df.drop(columns=[\"taxonomy\"], inplace=True)\n",
    "    \n",
    "#     # Log sample of parsed taxonomy\n",
    "#     logging.info(f\"Sample parsed taxonomy:\")\n",
    "#     logging.info(tax_df[[\"genome_id\", \"domain\", \"phylum\", \"class\"]].head().to_string())\n",
    "    \n",
    "#     return tax_df\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------\n",
    "# # Merge taxonomy into neighborhood data\n",
    "# # ------------------------------------------------------------\n",
    "# def merge_taxonomy(escrt_csv, gtdb_tsv, out_csv):\n",
    "#     \"\"\"\n",
    "#     Merge GTDB taxonomy into ESCRT neighborhood dataframe.\n",
    "    \n",
    "#     Args:\n",
    "#         escrt_csv: Path to ESCRT neighborhoods CSV\n",
    "#         gtdb_tsv: Path to GTDB taxonomy TSV\n",
    "#         out_csv: Output path for merged CSV\n",
    "        \n",
    "#     Returns:\n",
    "#         Merged DataFrame with taxonomy columns added\n",
    "#     \"\"\"\n",
    "#     logging.info(\"=\" * 70)\n",
    "#     logging.info(\"STARTING TAXONOMY MERGE\")\n",
    "#     logging.info(\"=\" * 70)\n",
    "    \n",
    "#     # Load neighborhood data\n",
    "#     logging.info(f\"Loading neighborhood data from: {escrt_csv}\")\n",
    "#     escrt_df = pd.read_csv(escrt_csv)\n",
    "#     escrt_df['genome_id_base'] = (\n",
    "#     escrt_df['genome_id']\n",
    "#     .str.split(\"_\", n=2)\n",
    "#     .str[0:2]\n",
    "#     .str.join(\"_\")\n",
    "# )\n",
    "\n",
    "#     logging.info(f\"Neighborhood data: {len(escrt_df)} rows, {len(escrt_df['genome_id'].unique())} unique genomes\")\n",
    "    \n",
    "#     # Load taxonomy data\n",
    "#     tax_df = load_gtdb_taxonomy(gtdb_tsv)\n",
    "    \n",
    "#     # Check for overlap between datasets\n",
    "#     escrt_genomes = set(escrt_df[\"genome_id_base\"].unique())\n",
    "#     tax_genomes = set(tax_df[\"genome_id_base\"].unique())\n",
    "#     overlap = escrt_genomes.intersection(tax_genomes)\n",
    "    \n",
    "#     logging.info(f\"Genome ID overlap check:\")\n",
    "#     logging.info(f\"  Genomes in neighborhood data: {len(escrt_genomes)}\")\n",
    "#     logging.info(f\"  Genomes in taxonomy data: {len(tax_genomes)}\")\n",
    "#     logging.info(f\"  Overlapping genomes: {len(overlap)}\")\n",
    "    \n",
    "#     if len(overlap) == 0:\n",
    "#         logging.error(\"NO OVERLAP between genome IDs!\")\n",
    "#         logging.error(f\"Sample neighborhood genome IDs: {list(escrt_genomes)[:5]}\")\n",
    "#         logging.error(f\"Sample taxonomy genome IDs: {list(tax_genomes)[:5]}\")\n",
    "#         logging.error(\"Check if genome_id formats match between files!\")\n",
    "#         sys.exit(1)\n",
    "    \n",
    "#     if len(overlap) < len(escrt_genomes):\n",
    "#         missing = len(escrt_genomes) - len(overlap)\n",
    "#         logging.warning(f\"{missing} genomes from neighborhood data not found in taxonomy!\")\n",
    "    \n",
    "#     # Perform the merge\n",
    "#     logging.info(\"Performing left join on genome_id...\")\n",
    "#     merged = escrt_df.merge(\n",
    "#         tax_df,\n",
    "#         on=\"genome_id_base\",\n",
    "#         how=\"left\"\n",
    "#     )\n",
    "    \n",
    "#     # Validate merge results\n",
    "#     logging.info(f\"Merge complete: {len(merged)} rows\")\n",
    "    \n",
    "#     # Check how many rows got taxonomy data\n",
    "#     tax_columns = [\"domain\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\"]\n",
    "#     for col in tax_columns:\n",
    "#         non_null = merged[col].notna().sum()\n",
    "#         pct = (non_null / len(merged)) * 100\n",
    "#         logging.info(f\"  {col}: {non_null} non-null ({pct:.1f}%)\")\n",
    "    \n",
    "#     # Save to CSV\n",
    "#     logging.info(f\"Saving merged data to: {out_csv}\")\n",
    "#     merged.to_csv(out_csv, index=False)\n",
    "    \n",
    "#     # Show sample of merged data\n",
    "#     logging.info(\"Sample of merged data with taxonomy:\")\n",
    "#     sample_cols = [\"genome_id\", \"protein_id\", \"domain\", \"phylum\", \"class\", \"order\"]\n",
    "#     available_cols = [col for col in sample_cols if col in merged.columns]\n",
    "#     logging.info(merged[available_cols].head(10).to_string())\n",
    "    \n",
    "#     logging.info(\"=\" * 70)\n",
    "#     logging.info(\"TAXONOMY MERGE COMPLETE\")\n",
    "#     logging.info(\"=\" * 70)\n",
    "    \n",
    "#     return merged\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "109ab58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# Parse Prodigal GFF and assign gene order PER CONTIG\n",
    "# ------------------------------------------------------------\n",
    "def parse_prodigal_gff(gff_path, genome_id):\n",
    "    \"\"\"\n",
    "    Parse a Prodigal GFF3 file and extract CDS gene order per contig.\n",
    "\n",
    "    Gene order is defined by appearance order in the GFF,\n",
    "    which corresponds to genomic order for Prodigal output.\n",
    "    \n",
    "    Args:\n",
    "        gff_path: Path to the GFF file\n",
    "        genome_id: Identifier for the genome\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: genome_id, contig, gene_index, \n",
    "                                protein_id, start, end, strand\n",
    "    \"\"\"\n",
    "\n",
    "    rows = []\n",
    "    gene_counter = {}  # separate gene index per contig\n",
    "\n",
    "    logging.info(f\"Parsing GFF: {gff_path.name}\")\n",
    "\n",
    "    with open(gff_path) as f:\n",
    "        for line in f:\n",
    "            # Skip comment lines\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            parts = line.rstrip().split(\"\\t\")\n",
    "            if len(parts) != 9:\n",
    "                continue\n",
    "\n",
    "            contig, source, feature, start, end, score, strand, phase, attrs = parts\n",
    "\n",
    "            # Only process CDS features\n",
    "            if feature != \"CDS\":\n",
    "                continue\n",
    "\n",
    "            # Parse attributes to extract protein ID\n",
    "            attr_dict = {}\n",
    "            for item in attrs.split(\";\"):\n",
    "                if \"=\" in item:\n",
    "                    k, v = item.split(\"=\", 1)\n",
    "                    attr_dict[k] = v\n",
    "\n",
    "            protein_id = attr_dict.get(\"ID\")\n",
    "            if protein_id is None:\n",
    "                continue\n",
    "\n",
    "            # Increment gene index PER CONTIG (not genome-wide)\n",
    "            gene_counter.setdefault(contig, 0)\n",
    "            gene_counter[contig] += 1\n",
    "\n",
    "            rows.append({\n",
    "                \"genome_id\": genome_id,\n",
    "                \"contig\": contig,\n",
    "                \"gene_index\": gene_counter[contig],\n",
    "                \"protein_id\": protein_id,\n",
    "                \"start\": int(start),\n",
    "                \"end\": int(end),\n",
    "                \"strand\": strand\n",
    "            })\n",
    "\n",
    "    logging.info(f\"  → Parsed {len(rows)} CDS features across {len(gene_counter)} contigs\")\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load only the GFFs required by the hits table\n",
    "# ------------------------------------------------------------\n",
    "def load_gffs_from_hits(hits_df, gff_dir):\n",
    "    \"\"\"\n",
    "    Parse GFF files only for genomes present in the hits dataframe.\n",
    "    GFF filenames are inferred as: <genome_file>_genomic/<genome_file>_genomic.gff\n",
    "    \n",
    "    Args:\n",
    "        hits_df: DataFrame containing hits with 'genome_file' column\n",
    "        gff_dir: Directory containing GFF files\n",
    "        \n",
    "    Returns:\n",
    "        Combined DataFrame of all parsed GFF files\n",
    "    \"\"\"\n",
    "\n",
    "    all_gff_rows = []\n",
    "    \n",
    "    unique_genomes = hits_df[\"Name\"].unique()\n",
    "    logging.info(f\"Loading GFFs for {len(unique_genomes)} unique genomes\")\n",
    "\n",
    "    for genome_id in unique_genomes:\n",
    "        gff_path = gff_dir / f\"{genome_id}_genomic\" / f\"{genome_id}_genomic.gff\"\n",
    "\n",
    "        if not gff_path.exists():\n",
    "            logging.warning(f\"Missing GFF: {gff_path}\")\n",
    "            continue\n",
    "\n",
    "        gff_df = parse_prodigal_gff(gff_path, genome_id)\n",
    "        all_gff_rows.append(gff_df)\n",
    "\n",
    "    if not all_gff_rows:\n",
    "        logging.error(\"No GFF files were successfully loaded.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    combined_gff = pd.concat(all_gff_rows, ignore_index=True)\n",
    "    logging.info(f\"Total CDS features loaded: {len(combined_gff)}\")\n",
    "    \n",
    "    return combined_gff\n",
    "\n",
    "\n",
    "def build_windows(anchor_df, window):\n",
    "    \"\"\"\n",
    "    Build genomic windows (start, end) around anchor genes.\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "\n",
    "    for _, row in anchor_df.iterrows():\n",
    "        windows.append({\n",
    "            \"genome_id\": row[\"genome_id\"],\n",
    "            \"contig\": row[\"contig\"],\n",
    "            \"winstart\": row[\"gene_index\"] - window,\n",
    "            \"winend\": row[\"gene_index\"] + window,\n",
    "            \"wincenter\": row[\"gene_index\"],\n",
    "            \"protein_id\": row[\"protein_id\"],\n",
    "            \"architecture\": row[\"architecture\"],\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(windows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_windows(windows_df):\n",
    "    \"\"\"\n",
    "    Merge overlapping windows per genome/contig.\n",
    "    \"\"\"\n",
    "    merged = []\n",
    "\n",
    "    for (genome, contig), grp in windows_df.groupby([\"genome_id\", \"contig\"]):\n",
    "        grp = grp.sort_values(\"winstart\")\n",
    "\n",
    "        cur_start = None\n",
    "        cur_end = None\n",
    "        cur_centers = []\n",
    "\n",
    "        for _, row in grp.iterrows():\n",
    "            if cur_start is None:\n",
    "                cur_start = row[\"winstart\"]\n",
    "                cur_end = row[\"winend\"]\n",
    "                cur_centers = [row]\n",
    "                continue\n",
    "\n",
    "            if row[\"winstart\"] <= cur_end + 1:\n",
    "                # overlap → extend\n",
    "                cur_end = max(cur_end, row[\"winend\"])\n",
    "                cur_centers.append(row)\n",
    "            else:\n",
    "                merged.append({\n",
    "                    \"genome_id\": genome,\n",
    "                    \"contig\": contig,\n",
    "                    \"winstart\": cur_start,\n",
    "                    \"winend\": cur_end,\n",
    "                    \"anchors\": cur_centers\n",
    "                })\n",
    "                cur_start = row[\"winstart\"]\n",
    "                cur_end = row[\"winend\"]\n",
    "                cur_centers = [row]\n",
    "\n",
    "        merged.append({\n",
    "            \"genome_id\": genome,\n",
    "            \"contig\": contig,\n",
    "            \"winstart\": cur_start,\n",
    "            \"winend\": cur_end,\n",
    "            \"anchors\": cur_centers\n",
    "        })\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "\n",
    "def extract_merged_neighborhoods(merged_windows, gff_df):\n",
    "    blocks = []\n",
    "\n",
    "    for win in merged_windows:\n",
    "        block = gff_df[\n",
    "            (gff_df[\"genome_id\"] == win[\"genome_id\"]) &\n",
    "            (gff_df[\"contig\"] == win[\"contig\"]) &\n",
    "            (gff_df[\"gene_index\"].between(win[\"winstart\"], win[\"winend\"]))\n",
    "        ].copy()\n",
    "\n",
    "        if block.empty:\n",
    "            continue\n",
    "\n",
    "        # pick a representative anchor (central-most)\n",
    "        centers = [a[\"wincenter\"] for a in win[\"anchors\"]]\n",
    "        rep_center = min(centers, key=lambda x: abs(x - (win[\"winstart\"] + win[\"winend\"]) / 2))\n",
    "\n",
    "        block[\"relative_pos\"] = block[\"gene_index\"] - rep_center\n",
    "        block[\"center_protein\"] = win[\"anchors\"][0][\"protein_id\"]\n",
    "        block[\"center_gene\"] = win[\"anchors\"][0][\"architecture\"]\n",
    "\n",
    "        blocks.append(block)\n",
    "\n",
    "    return pd.concat(blocks, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "def extract_neighborhoods(anchor_df, gff_df, window=5):\n",
    "\n",
    "    keywords = (\"vps\", \"escrt\", \"katanin\", \"eap\", \"flad\", \"zn-ph\")\n",
    "\n",
    "    logging.info(f\"Starting neighborhood extraction (±{window} genes)\")\n",
    "    logging.info(f\"Initial anchors: {len(anchor_df)}\")\n",
    "\n",
    "    filtered_anchors = anchor_df[\n",
    "        anchor_df[\"architecture\"]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .str.contains(\"|\".join(keywords))\n",
    "    ]\n",
    "\n",
    "    logging.info(f\"Anchors after ESCRT filter: {len(filtered_anchors)}\")\n",
    "\n",
    "    if filtered_anchors.empty:\n",
    "        logging.error(\"No ESCRT-related anchors found\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    windows_df = build_windows(filtered_anchors, window)\n",
    "    merged_windows = merge_windows(windows_df)\n",
    "\n",
    "    logging.info(\n",
    "        f\"Merged {len(windows_df)} anchor windows into \"\n",
    "        f\"{len(merged_windows)} non-overlapping regions\"\n",
    "    )\n",
    "\n",
    "    combined_neighborhoods = extract_merged_neighborhoods(\n",
    "        merged_windows, gff_df\n",
    "    )\n",
    "\n",
    "    logging.info(\n",
    "        f\"Extracted {len(combined_neighborhoods)} genes \"\n",
    "        f\"from {len(merged_windows)} merged neighborhoods\"\n",
    "    )\n",
    "\n",
    "    return combined_neighborhoods\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load GTDB taxonomy\n",
    "# ------------------------------------------------------------\n",
    "def load_gtdb_taxonomy(gtdb_tsv):\n",
    "    \"\"\"\n",
    "    Load GTDB taxonomy file and split into rank-specific columns.\n",
    "    \n",
    "    GTDB format: genome_id\\td__Domain;p__Phylum;c__Class;o__Order;f__Family;g__Genus;s__Species\n",
    "    \n",
    "    Args:\n",
    "        gtdb_tsv: Path to GTDB taxonomy TSV file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: genome_id, domain, phylum, class, order, family, genus, species\n",
    "    \"\"\"\n",
    "    logging.info(f\"Loading GTDB taxonomy from: {gtdb_tsv}\")\n",
    "    \n",
    "    # Read the taxonomy file\n",
    "    tax_df = pd.read_csv(\n",
    "        gtdb_tsv,\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=[\"genome_id\", \"taxonomy\"],\n",
    "        dtype=str\n",
    "    )\n",
    "    \n",
    "    tax_df[\"genome_id_base\"] = tax_df[\"genome_id\"].str.split(\"_\", n=1).str[1]\n",
    "    logging.info(f\"Loaded taxonomy for {len(tax_df)} genomes\")\n",
    "    logging.info(f\"Sample taxonomy entry: {tax_df['taxonomy'].iloc[0]}\")\n",
    "    \n",
    "    # Split taxonomy string by semicolons\n",
    "    tax_split = tax_df[\"taxonomy\"].str.split(\";\", expand=True)\n",
    "    logging.info(f\"Taxonomy split into {tax_split.shape[1]} columns\")\n",
    "    \n",
    "    # Map column indices to taxonomic ranks\n",
    "    rank_map = {\n",
    "        0: \"domain\",\n",
    "        1: \"phylum\",\n",
    "        2: \"class\",\n",
    "        3: \"order\",\n",
    "        4: \"family\",\n",
    "        5: \"genus\",\n",
    "        6: \"species\"\n",
    "    }\n",
    "    \n",
    "    # Extract each rank and remove the prefix (e.g., \"d__\", \"p__\")\n",
    "    for idx, rank in rank_map.items():\n",
    "        if idx < tax_split.shape[1]:\n",
    "            # Remove the rank prefix using regex (e.g., \"p__\" from \"p__Crenarchaeota\")\n",
    "            tax_df[rank] = tax_split[idx].str.replace(r\"^[a-z]__\", \"\", regex=True)\n",
    "            logging.info(f\"Extracted {rank}: {tax_df[rank].notna().sum()} non-null values\")\n",
    "        else:\n",
    "            tax_df[rank] = pd.NA\n",
    "            logging.warning(f\"Column {idx} for rank '{rank}' not found in taxonomy data\")\n",
    "    \n",
    "    # Drop the original concatenated taxonomy string\n",
    "    tax_df.drop(columns=[\"taxonomy\"], inplace=True)\n",
    "    \n",
    "    # Log sample of parsed taxonomy\n",
    "    logging.info(f\"Sample parsed taxonomy:\")\n",
    "    logging.info(tax_df[[\"genome_id\", \"domain\", \"phylum\", \"class\"]].head().to_string())\n",
    "    \n",
    "    return tax_df\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Merge taxonomy into neighborhood data\n",
    "# ------------------------------------------------------------\n",
    "def merge_taxonomy(escrt_csv, gtdb_tsv, out_csv):\n",
    "    \"\"\"\n",
    "    Merge GTDB taxonomy into ESCRT neighborhood dataframe.\n",
    "    \n",
    "    Args:\n",
    "        escrt_csv: Path to ESCRT neighborhoods CSV\n",
    "        gtdb_tsv: Path to GTDB taxonomy TSV\n",
    "        out_csv: Output path for merged CSV\n",
    "        \n",
    "    Returns:\n",
    "        Merged DataFrame with taxonomy columns added\n",
    "    \"\"\"\n",
    "    logging.info(\"=\" * 70)\n",
    "    logging.info(\"STARTING TAXONOMY MERGE\")\n",
    "    logging.info(\"=\" * 70)\n",
    "    \n",
    "    # Load neighborhood data\n",
    "    logging.info(f\"Loading neighborhood data from: {escrt_csv}\")\n",
    "    escrt_df = pd.read_csv(escrt_csv)\n",
    "    escrt_df['genome_id_base'] = (\n",
    "    escrt_df['genome_id']\n",
    "    .str.split(\"_\", n=2)\n",
    "    .str[0:2]\n",
    "    .str.join(\"_\")\n",
    ")\n",
    "\n",
    "    logging.info(f\"Neighborhood data: {len(escrt_df)} rows, {len(escrt_df['genome_id'].unique())} unique genomes\")\n",
    "    \n",
    "    # Load taxonomy data\n",
    "    tax_df = load_gtdb_taxonomy(gtdb_tsv)\n",
    "    \n",
    "    # Check for overlap between datasets\n",
    "    escrt_genomes = set(escrt_df[\"genome_id_base\"].unique())\n",
    "    tax_genomes = set(tax_df[\"genome_id_base\"].unique())\n",
    "    overlap = escrt_genomes.intersection(tax_genomes)\n",
    "    \n",
    "    logging.info(f\"Genome ID overlap check:\")\n",
    "    logging.info(f\"  Genomes in neighborhood data: {len(escrt_genomes)}\")\n",
    "    logging.info(f\"  Genomes in taxonomy data: {len(tax_genomes)}\")\n",
    "    logging.info(f\"  Overlapping genomes: {len(overlap)}\")\n",
    "    \n",
    "    if len(overlap) == 0:\n",
    "        logging.error(\"NO OVERLAP between genome IDs!\")\n",
    "        logging.error(f\"Sample neighborhood genome IDs: {list(escrt_genomes)[:5]}\")\n",
    "        logging.error(f\"Sample taxonomy genome IDs: {list(tax_genomes)[:5]}\")\n",
    "        logging.error(\"Check if genome_id formats match between files!\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    if len(overlap) < len(escrt_genomes):\n",
    "        missing = len(escrt_genomes) - len(overlap)\n",
    "        logging.warning(f\"{missing} genomes from neighborhood data not found in taxonomy!\")\n",
    "    \n",
    "    # Perform the merge\n",
    "    logging.info(\"Performing left join on genome_id...\")\n",
    "    merged = escrt_df.merge(\n",
    "        tax_df,\n",
    "        on=\"genome_id_base\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Validate merge results\n",
    "    logging.info(f\"Merge complete: {len(merged)} rows\")\n",
    "    \n",
    "    # Check how many rows got taxonomy data\n",
    "    tax_columns = [\"domain\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\"]\n",
    "    for col in tax_columns:\n",
    "        non_null = merged[col].notna().sum()\n",
    "        pct = (non_null / len(merged)) * 100\n",
    "        logging.info(f\"  {col}: {non_null} non-null ({pct:.1f}%)\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    logging.info(f\"Saving merged data to: {out_csv}\")\n",
    "    merged.to_csv(out_csv, index=False)\n",
    "    \n",
    "    # Show sample of merged data\n",
    "    logging.info(\"Sample of merged data with taxonomy:\")\n",
    "    sample_cols = [\"genome_id\", \"protein_id\", \"domain\", \"phylum\", \"class\", \"order\"]\n",
    "    available_cols = [col for col in sample_cols if col in merged.columns]\n",
    "    logging.info(merged[available_cols].head(10).to_string())\n",
    "    \n",
    "    logging.info(\"=\" * 70)\n",
    "    logging.info(\"TAXONOMY MERGE COMPLETE\")\n",
    "    logging.info(\"=\" * 70)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d774e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main pipeline\n",
    "# ------------------------------------------------------------\n",
    "def run_synteny_pipeline(\n",
    "    hits_df,\n",
    "    gff_dir,\n",
    "    window=5,\n",
    "    min_coverage=0.65,\n",
    "    max_i_evalue=1e-5,\n",
    "):\n",
    "\n",
    "    logging.info(\"=\" * 70)\n",
    "    logging.info(\"STARTING SYNTENY PIPELINE\")\n",
    "    logging.info(\"=\" * 70)\n",
    "    logging.info(f\"Hits DataFrame: {hits_df}\")\n",
    "    logging.info(f\"GFF directory: {gff_dir}\")\n",
    "    logging.info(f\"Window size: ±{window} genes\")\n",
    "\n",
    "\n",
    "    gff_dir = Path(gff_dir)\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Load GFFs\n",
    "    # --------------------------------------------------------\n",
    "    logging.info(\"\\n[STEP 1] Loading GFF files...\")\n",
    "    gff_df = load_gffs_from_hits(hits_df, gff_dir)\n",
    "\n",
    "\n",
    "    gff_df.to_csv(os.path.join(MAIN_OUTDIR, f\"[STEP:{STEP}.5]gff_dataframe_{rightnow}.csv\"), index=False)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Map anchor hits to gene order\n",
    "    # --------------------------------------------------------\n",
    "    logging.info(\"\\n[STEP 2] Mapping hits to gene order...\")\n",
    "    anchor_df = hits_df.merge(\n",
    "        gff_df,\n",
    "        left_on=\"target\",\n",
    "        right_on=\"protein_id\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "\n",
    "    if anchor_df.empty:\n",
    "        logging.error(\"No hits could be mapped to GFFs (protein ID mismatch?)\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    protein_to_arch = (\n",
    "    anchor_df\n",
    "    .drop_duplicates(\"protein_id\")\n",
    "    .set_index(\"protein_id\")[\"architecture\"]\n",
    "    .to_dict()\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Extract neighborhoods\n",
    "    # --------------------------------------------------------\n",
    "    logging.info(\"\\n[STEP 3] Extracting gene neighborhoods...\")\n",
    "    neigh_df = extract_neighborhoods(anchor_df, gff_df, window=window)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Annotate EACH neighbor with its own query identity\n",
    "    # --------------------------------------------------------\n",
    "    logging.info(\"\\n[STEP 4] Annotating neighbors with query IDs...\")\n",
    "    neigh_df[\"neighbor_architecture\"] = neigh_df[\"protein_id\"].map(protein_to_arch)\n",
    "    neigh_df[\"is_target_family\"] = neigh_df[\"neighbor_architecture\"].notna()\n",
    "\n",
    "    # Debug: Check neighbor_query values\n",
    "    logging.info(f\"Total genes in neighborhoods: {len(neigh_df)}\")\n",
    "    logging.info(f\"Genes with neighbor_query annotation: {neigh_df['neighbor_architecture'].notna().sum()}\")\n",
    "    logging.info(f\"Sample neighbor_query values: {neigh_df['neighbor_architecture'].dropna().unique()[:10].tolist()}\")\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Merge center gene annotations - WITH DEBUGGING\n",
    "    # --------------------------------------------------------\n",
    "    logging.info(\"\\n[STEP 5] Merging center gene AsCOG annotations...\")\n",
    "\n",
    "    # Strip whitespace from center_gene\n",
    "    neigh_df[\"center_gene\"] = neigh_df[\"center_gene\"].str.strip()\n",
    "\n",
    "\n",
    "    logging.info(\n",
    "        f\"\\nAnnotated neighborhoods: {len(neigh_df)} total genes\"\n",
    "    )\n",
    "\n",
    "    logging.info(\"=\" * 70)\n",
    "    logging.info(\"SYNTENY PIPELINE COMPLETED SUCCESSFULLY\")\n",
    "    logging.info(\"=\" * 70)\n",
    "\n",
    "    return neigh_df, anchor_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f56369a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:08:19,731 [INFO] ======================================================================\n",
      "2026-01-21 11:08:19,732 [INFO] STARTING SYNTENY PIPELINE\n",
      "2026-01-21 11:08:19,733 [INFO] ======================================================================\n",
      "2026-01-21 11:08:19,735 [INFO] Hits DataFrame:               target                          Name  Completeness  \\\n",
      "0     AAEOKEPF_00166  GCA_021498095.1_ASM2149809v1         93.44   \n",
      "3     AAEOKEPF_00273  GCA_021498095.1_ASM2149809v1         93.44   \n",
      "6     AAEOKEPF_00322  GCA_021498095.1_ASM2149809v1         93.44   \n",
      "8     AAEOKEPF_00337  GCA_021498095.1_ASM2149809v1         93.44   \n",
      "10    AAEOKEPF_00338  GCA_021498095.1_ASM2149809v1         93.44   \n",
      "...              ...                           ...           ...   \n",
      "6669  PLALBJDB_03422  GCA_019058015.1_ASM1905801v1         92.80   \n",
      "6674  PLALBJDB_03434  GCA_019058015.1_ASM1905801v1         92.80   \n",
      "6681  PLALBJDB_03435  GCA_019058015.1_ASM1905801v1         92.80   \n",
      "6688  PLALBJDB_03536  GCA_019058015.1_ASM1905801v1         92.80   \n",
      "6690  PLALBJDB_03537  GCA_019058015.1_ASM1905801v1         92.80   \n",
      "\n",
      "      Contamination  Contig_N50  Total_Contigs  \\\n",
      "0              4.36     4361485              1   \n",
      "3              4.36     4361485              1   \n",
      "6              4.36     4361485              1   \n",
      "8              4.36     4361485              1   \n",
      "10             4.36     4361485              1   \n",
      "...             ...         ...            ...   \n",
      "6669           3.44       25082            283   \n",
      "6674           3.44       25082            283   \n",
      "6681           3.44       25082            283   \n",
      "6688           3.44       25082            283   \n",
      "6690           3.44       25082            283   \n",
      "\n",
      "                            organism_name architecture architecture_method  \\\n",
      "0     Candidatus Harpocratesius repetitus           E2       best_i_evalue   \n",
      "3     Candidatus Harpocratesius repetitus       E3-UFM       best_i_evalue   \n",
      "6     Candidatus Harpocratesius repetitus           E1       best_i_evalue   \n",
      "8     Candidatus Harpocratesius repetitus           E1       best_i_evalue   \n",
      "10    Candidatus Harpocratesius repetitus          MPN       best_i_evalue   \n",
      "...                                   ...          ...                 ...   \n",
      "6669           Promethearchaeota archaeon          MPN       best_i_evalue   \n",
      "6674           Promethearchaeota archaeon          MPN       best_i_evalue   \n",
      "6681           Promethearchaeota archaeon          MPN       best_i_evalue   \n",
      "6688           Promethearchaeota archaeon     ESCRTIII       best_i_evalue   \n",
      "6690           Promethearchaeota archaeon        VPS23       best_i_evalue   \n",
      "\n",
      "     architecture_components  \n",
      "0                         E2  \n",
      "3                     E3-UFM  \n",
      "6                         E1  \n",
      "8                         E1  \n",
      "10                       MPN  \n",
      "...                      ...  \n",
      "6669                     MPN  \n",
      "6674                     MPN  \n",
      "6681                     MPN  \n",
      "6688                ESCRTIII  \n",
      "6690                   VPS23  \n",
      "\n",
      "[3325 rows x 10 columns]\n",
      "2026-01-21 11:08:19,735 [INFO] GFF directory: /home/anirudh/genomes/selected_genomes/prokka_results\n",
      "2026-01-21 11:08:19,735 [INFO] Window size: ±5 genes\n",
      "2026-01-21 11:08:19,736 [INFO] \n",
      "[STEP 1] Loading GFF files...\n",
      "2026-01-21 11:08:19,736 [INFO] Loading GFFs for 129 unique genomes\n",
      "2026-01-21 11:08:19,737 [INFO] Parsing GFF: GCA_021498095.1_ASM2149809v1_genomic.gff\n",
      "2026-01-21 11:08:19,750 [INFO]   → Parsed 3694 CDS features across 1 contigs\n",
      "2026-01-21 11:08:19,753 [INFO] Parsing GFF: GCA_005191425.1_ASM519142v1_genomic.gff\n",
      "2026-01-21 11:08:19,765 [INFO]   → Parsed 3164 CDS features across 182 contigs\n",
      "2026-01-21 11:08:19,768 [INFO] Parsing GFF: GCA_048882285.1_ASM4888228v1_genomic.gff\n",
      "2026-01-21 11:08:19,779 [INFO]   → Parsed 3583 CDS features across 321 contigs\n",
      "2026-01-21 11:08:19,783 [INFO] Parsing GFF: GCA_048882045.1_ASM4888204v1_genomic.gff\n",
      "2026-01-21 11:08:19,794 [INFO]   → Parsed 3427 CDS features across 93 contigs\n",
      "2026-01-21 11:08:19,797 [INFO] Parsing GFF: GCA_048941715.1_ASM4894171v1_genomic.gff\n",
      "2026-01-21 11:08:19,806 [INFO]   → Parsed 2417 CDS features across 120 contigs\n",
      "2026-01-21 11:08:19,808 [INFO] Parsing GFF: GCA_019058445.1_ASM1905844v1_genomic.gff\n",
      "2026-01-21 11:08:19,823 [INFO]   → Parsed 4140 CDS features across 10 contigs\n",
      "2026-01-21 11:08:19,826 [INFO] Parsing GFF: GCA_038866325.1_ASM3886632v1_genomic.gff\n",
      "2026-01-21 11:08:19,834 [INFO]   → Parsed 2379 CDS features across 27 contigs\n",
      "2026-01-21 11:08:19,837 [INFO] Parsing GFF: GCA_016839585.1_ASM1683958v1_genomic.gff\n",
      "2026-01-21 11:08:19,847 [INFO]   → Parsed 3289 CDS features across 91 contigs\n",
      "2026-01-21 11:08:19,851 [INFO] Parsing GFF: GCA_052584815.1_ASM5258481v1_genomic.gff\n",
      "2026-01-21 11:08:19,860 [INFO]   → Parsed 2573 CDS features across 105 contigs\n",
      "2026-01-21 11:08:19,862 [INFO] Parsing GFF: GCA_023705685.1_ASM2370568v1_genomic.gff\n",
      "2026-01-21 11:08:19,873 [INFO]   → Parsed 2723 CDS features across 720 contigs\n",
      "2026-01-21 11:08:19,875 [INFO] Parsing GFF: GCA_030018135.1_ASM3001813v1_genomic.gff\n",
      "2026-01-21 11:08:19,880 [INFO]   → Parsed 1290 CDS features across 42 contigs\n",
      "2026-01-21 11:08:19,882 [INFO] Parsing GFF: GCA_048941605.1_ASM4894160v1_genomic.gff\n",
      "2026-01-21 11:08:19,894 [INFO]   → Parsed 3314 CDS features across 241 contigs\n",
      "2026-01-21 11:08:19,896 [INFO] Parsing GFF: GCA_019058165.1_ASM1905816v1_genomic.gff\n",
      "2026-01-21 11:08:19,910 [INFO]   → Parsed 3102 CDS features across 253 contigs\n",
      "2026-01-21 11:08:19,913 [INFO] Parsing GFF: GCA_019057575.1_ASM1905757v1_genomic.gff\n",
      "2026-01-21 11:08:19,926 [INFO]   → Parsed 3832 CDS features across 71 contigs\n",
      "2026-01-21 11:08:19,929 [INFO] Parsing GFF: GCA_030641055.1_ASM3064105v1_genomic.gff\n",
      "2026-01-21 11:08:19,937 [INFO]   → Parsed 2083 CDS features across 271 contigs\n",
      "2026-01-21 11:08:19,941 [INFO] Parsing GFF: GCA_048941015.1_ASM4894101v1_genomic.gff\n",
      "2026-01-21 11:08:19,953 [INFO]   → Parsed 3325 CDS features across 144 contigs\n",
      "2026-01-21 11:08:19,956 [INFO] Parsing GFF: GCA_029855935.1_ASM2985593v1_genomic.gff\n",
      "2026-01-21 11:08:19,966 [INFO]   → Parsed 2731 CDS features across 32 contigs\n",
      "2026-01-21 11:08:19,968 [INFO] Parsing GFF: GCA_048885525.1_ASM4888552v1_genomic.gff\n",
      "2026-01-21 11:08:19,980 [INFO]   → Parsed 3342 CDS features across 87 contigs\n",
      "2026-01-21 11:08:19,982 [INFO] Parsing GFF: GCA_038861695.1_ASM3886169v1_genomic.gff\n",
      "2026-01-21 11:08:19,990 [INFO]   → Parsed 2148 CDS features across 20 contigs\n",
      "2026-01-21 11:08:19,992 [INFO] Parsing GFF: GCA_048882565.1_ASM4888256v1_genomic.gff\n",
      "2026-01-21 11:08:20,009 [INFO]   → Parsed 3362 CDS features across 131 contigs\n",
      "2026-01-21 11:08:20,012 [INFO] Parsing GFF: GCA_019058095.1_ASM1905809v1_genomic.gff\n",
      "2026-01-21 11:08:20,026 [INFO]   → Parsed 4094 CDS features across 174 contigs\n",
      "2026-01-21 11:08:20,030 [INFO] Parsing GFF: GCA_048885575.1_ASM4888557v1_genomic.gff\n",
      "2026-01-21 11:08:20,043 [INFO]   → Parsed 2880 CDS features across 491 contigs\n",
      "2026-01-21 11:08:20,046 [INFO] Parsing GFF: GCA_018335335.1_ASM1833533v1_genomic.gff\n",
      "2026-01-21 11:08:20,058 [INFO]   → Parsed 2695 CDS features across 176 contigs\n",
      "2026-01-21 11:08:20,061 [INFO] Parsing GFF: GCA_048882745.1_ASM4888274v1_genomic.gff\n",
      "2026-01-21 11:08:20,074 [INFO]   → Parsed 3633 CDS features across 216 contigs\n",
      "2026-01-21 11:08:20,077 [INFO] Parsing GFF: GCA_019056805.1_ASM1905680v1_genomic.gff\n",
      "2026-01-21 11:08:20,085 [INFO]   → Parsed 1888 CDS features across 18 contigs\n",
      "2026-01-21 11:08:20,087 [INFO] Parsing GFF: GCA_048885705.1_ASM4888570v1_genomic.gff\n",
      "2026-01-21 11:08:20,099 [INFO]   → Parsed 3157 CDS features across 238 contigs\n",
      "2026-01-21 11:08:20,102 [INFO] Parsing GFF: GCA_046482545.1_ASM4648254v1_genomic.gff\n",
      "2026-01-21 11:08:20,111 [INFO]   → Parsed 2899 CDS features across 45 contigs\n",
      "2026-01-21 11:08:20,114 [INFO] Parsing GFF: GCA_019057865.1_ASM1905786v1_genomic.gff\n",
      "2026-01-21 11:08:20,128 [INFO]   → Parsed 4113 CDS features across 87 contigs\n",
      "2026-01-21 11:08:20,131 [INFO] Parsing GFF: GCA_048938295.1_ASM4893829v1_genomic.gff\n",
      "2026-01-21 11:08:20,140 [INFO]   → Parsed 2472 CDS features across 66 contigs\n",
      "2026-01-21 11:08:20,143 [INFO] Parsing GFF: GCA_029856045.1_ASM2985604v1_genomic.gff\n",
      "2026-01-21 11:08:20,153 [INFO]   → Parsed 3076 CDS features across 55 contigs\n",
      "2026-01-21 11:08:20,156 [INFO] Parsing GFF: GCA_016839765.1_ASM1683976v1_genomic.gff\n",
      "2026-01-21 11:08:20,166 [INFO]   → Parsed 3131 CDS features across 96 contigs\n",
      "2026-01-21 11:08:20,170 [INFO] Parsing GFF: GCA_003144275.1_ASM314427v1_genomic.gff\n",
      "2026-01-21 11:08:20,183 [INFO]   → Parsed 3520 CDS features across 103 contigs\n",
      "2026-01-21 11:08:20,186 [INFO] Parsing GFF: GCA_004524535.1_ASM452453v1_genomic.gff\n",
      "2026-01-21 11:08:20,200 [INFO]   → Parsed 3464 CDS features across 198 contigs\n",
      "2026-01-21 11:08:20,203 [INFO] Parsing GFF: GCA_030587545.2_ASM3058754v2_genomic.gff\n",
      "2026-01-21 11:08:20,225 [INFO]   → Parsed 5086 CDS features across 293 contigs\n",
      "2026-01-21 11:08:20,229 [INFO] Parsing GFF: GCA_030606485.1_ASM3060648v1_genomic.gff\n",
      "2026-01-21 11:08:20,242 [INFO]   → Parsed 3504 CDS features across 13 contigs\n",
      "2026-01-21 11:08:20,245 [INFO] Parsing GFF: GCA_038826135.1_ASM3882613v1_genomic.gff\n",
      "2026-01-21 11:08:20,252 [INFO]   → Parsed 1320 CDS features across 104 contigs\n",
      "2026-01-21 11:08:20,253 [INFO] Parsing GFF: GCA_013166775.1_ASM1316677v1_genomic.gff\n",
      "2026-01-21 11:08:20,266 [INFO]   → Parsed 3642 CDS features across 115 contigs\n",
      "2026-01-21 11:08:20,269 [INFO] Parsing GFF: GCA_048939465.1_ASM4893946v1_genomic.gff\n",
      "2026-01-21 11:08:20,277 [INFO]   → Parsed 1995 CDS features across 152 contigs\n",
      "2026-01-21 11:08:20,279 [INFO] Parsing GFF: GCA_051746095.1_ASM5174609v1_genomic.gff\n",
      "2026-01-21 11:08:20,292 [INFO]   → Parsed 3416 CDS features across 200 contigs\n",
      "2026-01-21 11:08:20,295 [INFO] Parsing GFF: GCA_021498085.1_ASM2149808v1_genomic.gff\n",
      "2026-01-21 11:08:20,307 [INFO]   → Parsed 2793 CDS features across 11 contigs\n",
      "2026-01-21 11:08:20,311 [INFO] Parsing GFF: GCA_048938825.1_ASM4893882v1_genomic.gff\n",
      "2026-01-21 11:08:20,321 [INFO]   → Parsed 2966 CDS features across 460 contigs\n",
      "2026-01-21 11:08:20,324 [INFO] Parsing GFF: GCA_048938885.1_ASM4893888v1_genomic.gff\n",
      "2026-01-21 11:08:20,347 [INFO]   → Parsed 4164 CDS features across 263 contigs\n",
      "2026-01-21 11:08:20,350 [INFO] Parsing GFF: GCA_048885535.1_ASM4888553v1_genomic.gff\n",
      "2026-01-21 11:08:20,362 [INFO]   → Parsed 2919 CDS features across 112 contigs\n",
      "2026-01-21 11:08:20,364 [INFO] Parsing GFF: GCA_048939995.1_ASM4893999v1_genomic.gff\n",
      "2026-01-21 11:08:20,378 [INFO]   → Parsed 3535 CDS features across 38 contigs\n",
      "2026-01-21 11:08:20,381 [INFO] Parsing GFF: GCA_016926735.1_ASM1692673v1_genomic.gff\n",
      "2026-01-21 11:08:20,396 [INFO]   → Parsed 3506 CDS features across 238 contigs\n",
      "2026-01-21 11:08:20,399 [INFO] Parsing GFF: GCA_029856525.1_ASM2985652v1_genomic.gff\n",
      "2026-01-21 11:08:20,404 [INFO]   → Parsed 1344 CDS features across 126 contigs\n",
      "2026-01-21 11:08:20,406 [INFO] Parsing GFF: GCA_048941465.1_ASM4894146v1_genomic.gff\n",
      "2026-01-21 11:08:20,416 [INFO]   → Parsed 3186 CDS features across 124 contigs\n",
      "2026-01-21 11:08:20,419 [INFO] Parsing GFF: GCA_018238345.1_ASM1823834v1_genomic.gff\n",
      "2026-01-21 11:08:20,433 [INFO]   → Parsed 3317 CDS features across 288 contigs\n",
      "2026-01-21 11:08:20,436 [INFO] Parsing GFF: GCA_038858525.1_ASM3885852v1_genomic.gff\n",
      "2026-01-21 11:08:20,445 [INFO]   → Parsed 2145 CDS features across 63 contigs\n",
      "2026-01-21 11:08:20,448 [INFO] Parsing GFF: GCA_019058035.1_ASM1905803v1_genomic.gff\n",
      "2026-01-21 11:08:20,463 [INFO]   → Parsed 3768 CDS features across 377 contigs\n",
      "2026-01-21 11:08:20,466 [INFO] Parsing GFF: GCA_049671145.1_ASM4967114v1_genomic.gff\n",
      "2026-01-21 11:08:20,481 [INFO]   → Parsed 3522 CDS features across 346 contigs\n",
      "2026-01-21 11:08:20,484 [INFO] Parsing GFF: GCA_016839265.1_ASM1683926v1_genomic.gff\n",
      "2026-01-21 11:08:20,490 [INFO]   → Parsed 1388 CDS features across 6 contigs\n",
      "2026-01-21 11:08:20,493 [INFO] Parsing GFF: GCA_038889235.1_ASM3888923v1_genomic.gff\n",
      "2026-01-21 11:08:20,501 [INFO]   → Parsed 2119 CDS features across 8 contigs\n",
      "2026-01-21 11:08:20,503 [INFO] Parsing GFF: GCA_038854135.1_ASM3885413v1_genomic.gff\n",
      "2026-01-21 11:08:20,514 [INFO]   → Parsed 2335 CDS features across 67 contigs\n",
      "2026-01-21 11:08:20,516 [INFO] Parsing GFF: GCA_046483985.1_ASM4648398v1_genomic.gff\n",
      "2026-01-21 11:08:20,531 [INFO]   → Parsed 3746 CDS features across 127 contigs\n",
      "2026-01-21 11:08:20,534 [INFO] Parsing GFF: GCA_038855695.1_ASM3885569v1_genomic.gff\n",
      "2026-01-21 11:08:20,542 [INFO]   → Parsed 2185 CDS features across 68 contigs\n",
      "2026-01-21 11:08:20,544 [INFO] Parsing GFF: GCA_048882325.1_ASM4888232v1_genomic.gff\n",
      "2026-01-21 11:08:20,561 [INFO]   → Parsed 3400 CDS features across 89 contigs\n",
      "2026-01-21 11:08:20,565 [INFO] Parsing GFF: GCA_038846665.1_ASM3884666v1_genomic.gff\n",
      "2026-01-21 11:08:20,573 [INFO]   → Parsed 2446 CDS features across 35 contigs\n",
      "2026-01-21 11:08:20,576 [INFO] Parsing GFF: GCA_029856545.1_ASM2985654v1_genomic.gff\n",
      "2026-01-21 11:08:20,585 [INFO]   → Parsed 3115 CDS features across 318 contigs\n",
      "2026-01-21 11:08:20,588 [INFO] Parsing GFF: GCA_046497275.1_ASM4649727v1_genomic.gff\n",
      "2026-01-21 11:08:20,603 [INFO]   → Parsed 3535 CDS features across 188 contigs\n",
      "2026-01-21 11:08:20,607 [INFO] Parsing GFF: GCA_021498125.1_ASM2149812v1_genomic.gff\n",
      "2026-01-21 11:08:20,617 [INFO]   → Parsed 2866 CDS features across 14 contigs\n",
      "2026-01-21 11:08:20,621 [INFO] Parsing GFF: GCA_048939265.1_ASM4893926v1_genomic.gff\n",
      "2026-01-21 11:08:20,633 [INFO]   → Parsed 3494 CDS features across 342 contigs\n",
      "2026-01-21 11:08:20,636 [INFO] Parsing GFF: GCA_048885325.1_ASM4888532v1_genomic.gff\n",
      "2026-01-21 11:08:20,646 [INFO]   → Parsed 3117 CDS features across 320 contigs\n",
      "2026-01-21 11:08:20,649 [INFO] Parsing GFF: GCA_038819355.1_ASM3881935v1_genomic.gff\n",
      "2026-01-21 11:08:20,657 [INFO]   → Parsed 2360 CDS features across 37 contigs\n",
      "2026-01-21 11:08:20,659 [INFO] Parsing GFF: GCA_016840425.1_ASM1684042v1_genomic.gff\n",
      "2026-01-21 11:08:20,667 [INFO]   → Parsed 2100 CDS features across 277 contigs\n",
      "2026-01-21 11:08:20,669 [INFO] Parsing GFF: GCA_016839295.1_ASM1683929v1_genomic.gff\n",
      "2026-01-21 11:08:20,680 [INFO]   → Parsed 3498 CDS features across 71 contigs\n",
      "2026-01-21 11:08:20,683 [INFO] Parsing GFF: GCA_030614005.1_ASM3061400v1_genomic.gff\n",
      "2026-01-21 11:08:20,695 [INFO]   → Parsed 3303 CDS features across 126 contigs\n",
      "2026-01-21 11:08:20,698 [INFO] Parsing GFF: GCA_018238545.1_ASM1823854v1_genomic.gff\n",
      "2026-01-21 11:08:20,710 [INFO]   → Parsed 3436 CDS features across 128 contigs\n",
      "2026-01-21 11:08:20,713 [INFO] Parsing GFF: GCA_048938985.1_ASM4893898v1_genomic.gff\n",
      "2026-01-21 11:08:20,727 [INFO]   → Parsed 3442 CDS features across 530 contigs\n",
      "2026-01-21 11:08:20,730 [INFO] Parsing GFF: GCA_019058055.1_ASM1905805v1_genomic.gff\n",
      "2026-01-21 11:08:20,741 [INFO]   → Parsed 2842 CDS features across 443 contigs\n",
      "2026-01-21 11:08:20,744 [INFO] Parsing GFF: GCA_027031765.1_ASM2703176v1_genomic.gff\n",
      "2026-01-21 11:08:20,753 [INFO]   → Parsed 2805 CDS features across 229 contigs\n",
      "2026-01-21 11:08:20,756 [INFO] Parsing GFF: GCA_048886755.1_ASM4888675v1_genomic.gff\n",
      "2026-01-21 11:08:20,763 [INFO]   → Parsed 1814 CDS features across 60 contigs\n",
      "2026-01-21 11:08:20,765 [INFO] Parsing GFF: GCA_030149205.1_ASM3014920v1_genomic.gff\n",
      "2026-01-21 11:08:20,779 [INFO]   → Parsed 3000 CDS features across 12 contigs\n",
      "2026-01-21 11:08:20,782 [INFO] Parsing GFF: GCA_018238585.1_ASM1823858v1_genomic.gff\n",
      "2026-01-21 11:08:20,797 [INFO]   → Parsed 3132 CDS features across 276 contigs\n",
      "2026-01-21 11:08:20,800 [INFO] Parsing GFF: GCA_003345555.1_ASM334555v1_genomic.gff\n",
      "2026-01-21 11:08:20,809 [INFO]   → Parsed 2118 CDS features across 82 contigs\n",
      "2026-01-21 11:08:20,812 [INFO] Parsing GFF: GCA_013388835.1_ASM1338883v1_genomic.gff\n",
      "2026-01-21 11:08:20,824 [INFO]   → Parsed 2761 CDS features across 123 contigs\n",
      "2026-01-21 11:08:20,826 [INFO] Parsing GFF: GCA_008080745.1_ASM808074v1_genomic.gff\n",
      "2026-01-21 11:08:20,836 [INFO]   → Parsed 2874 CDS features across 19 contigs\n",
      "2026-01-21 11:08:20,839 [INFO] Parsing GFF: GCA_026993975.1_ASM2699397v1_genomic.gff\n",
      "2026-01-21 11:08:20,846 [INFO]   → Parsed 2287 CDS features across 216 contigs\n",
      "2026-01-21 11:08:20,848 [INFO] Parsing GFF: GCA_021513695.1_ASM2151369v1_genomic.gff\n",
      "2026-01-21 11:08:20,860 [INFO]   → Parsed 2671 CDS features across 1 contigs\n",
      "2026-01-21 11:08:20,863 [INFO] Parsing GFF: GCA_016840465.1_ASM1684046v1_genomic.gff\n",
      "2026-01-21 11:08:20,872 [INFO]   → Parsed 2367 CDS features across 100 contigs\n",
      "2026-01-21 11:08:20,874 [INFO] Parsing GFF: GCA_019057635.1_ASM1905763v1_genomic.gff\n",
      "2026-01-21 11:08:20,885 [INFO]   → Parsed 2957 CDS features across 214 contigs\n",
      "2026-01-21 11:08:20,887 [INFO] Parsing GFF: GCA_048941285.1_ASM4894128v1_genomic.gff\n",
      "2026-01-21 11:08:20,898 [INFO]   → Parsed 3337 CDS features across 101 contigs\n",
      "2026-01-21 11:08:20,901 [INFO] Parsing GFF: GCA_021513715.1_ASM2151371v1_genomic.gff\n",
      "2026-01-21 11:08:20,912 [INFO]   → Parsed 2842 CDS features across 1 contigs\n",
      "2026-01-21 11:08:20,914 [INFO] Parsing GFF: GCA_038897395.1_ASM3889739v1_genomic.gff\n",
      "2026-01-21 11:08:20,922 [INFO]   → Parsed 2095 CDS features across 37 contigs\n",
      "2026-01-21 11:08:20,925 [INFO] Parsing GFF: GCA_038825615.1_ASM3882561v1_genomic.gff\n",
      "2026-01-21 11:08:20,937 [INFO]   → Parsed 3096 CDS features across 125 contigs\n",
      "2026-01-21 11:08:20,940 [INFO] Parsing GFF: GCA_048885925.1_ASM4888592v1_genomic.gff\n",
      "2026-01-21 11:08:20,954 [INFO]   → Parsed 3623 CDS features across 181 contigs\n",
      "2026-01-21 11:08:20,957 [INFO] Parsing GFF: GCA_048882505.1_ASM4888250v1_genomic.gff\n",
      "2026-01-21 11:08:20,972 [INFO]   → Parsed 3757 CDS features across 83 contigs\n",
      "2026-01-21 11:08:20,975 [INFO] Parsing GFF: GCA_048882965.1_ASM4888296v1_genomic.gff\n",
      "2026-01-21 11:08:20,988 [INFO]   → Parsed 3368 CDS features across 302 contigs\n",
      "2026-01-21 11:08:20,991 [INFO] Parsing GFF: GCA_014730275.1_ASM1473027v1_genomic.gff\n",
      "2026-01-21 11:08:21,003 [INFO]   → Parsed 3226 CDS features across 151 contigs\n",
      "2026-01-21 11:08:21,006 [INFO] Parsing GFF: GCA_038824485.1_ASM3882448v1_genomic.gff\n",
      "2026-01-21 11:08:21,015 [INFO]   → Parsed 2121 CDS features across 20 contigs\n",
      "2026-01-21 11:08:21,018 [INFO] Parsing GFF: GCA_029882335.1_ASM2988233v1_genomic.gff\n",
      "2026-01-21 11:08:21,033 [INFO]   → Parsed 3851 CDS features across 634 contigs\n",
      "2026-01-21 11:08:21,036 [INFO] Parsing GFF: GCA_048882945.1_ASM4888294v1_genomic.gff\n",
      "2026-01-21 11:08:21,049 [INFO]   → Parsed 3368 CDS features across 302 contigs\n",
      "2026-01-21 11:08:21,052 [INFO] Parsing GFF: GCA_027031745.1_ASM2703174v1_genomic.gff\n",
      "2026-01-21 11:08:21,062 [INFO]   → Parsed 2697 CDS features across 20 contigs\n",
      "2026-01-21 11:08:21,065 [INFO] Parsing GFF: GCA_038822405.1_ASM3882240v1_genomic.gff\n",
      "2026-01-21 11:08:21,072 [INFO]   → Parsed 2032 CDS features across 17 contigs\n",
      "2026-01-21 11:08:21,074 [INFO] Parsing GFF: GCA_048885565.1_ASM4888556v1_genomic.gff\n",
      "2026-01-21 11:08:21,086 [INFO]   → Parsed 3452 CDS features across 316 contigs\n",
      "2026-01-21 11:08:21,089 [INFO] Parsing GFF: GCA_019894715.1_ASM1989471v1_genomic.gff\n",
      "2026-01-21 11:08:21,100 [INFO]   → Parsed 3039 CDS features across 285 contigs\n",
      "2026-01-21 11:08:21,103 [INFO] Parsing GFF: GCA_019057815.1_ASM1905781v1_genomic.gff\n",
      "2026-01-21 11:08:21,115 [INFO]   → Parsed 3269 CDS features across 48 contigs\n",
      "2026-01-21 11:08:21,118 [INFO] Parsing GFF: GCA_014730165.1_ASM1473016v1_genomic.gff\n",
      "2026-01-21 11:08:21,134 [INFO]   → Parsed 4131 CDS features across 391 contigs\n",
      "2026-01-21 11:08:21,137 [INFO] Parsing GFF: GCA_029856435.1_ASM2985643v1_genomic.gff\n",
      "2026-01-21 11:08:21,154 [INFO]   → Parsed 3257 CDS features across 180 contigs\n",
      "2026-01-21 11:08:21,157 [INFO] Parsing GFF: GCA_019057955.1_ASM1905795v1_genomic.gff\n",
      "2026-01-21 11:08:21,167 [INFO]   → Parsed 2873 CDS features across 258 contigs\n",
      "2026-01-21 11:08:21,170 [INFO] Parsing GFF: GCA_038881135.1_ASM3888113v1_genomic.gff\n",
      "2026-01-21 11:08:21,179 [INFO]   → Parsed 2366 CDS features across 34 contigs\n",
      "2026-01-21 11:08:21,181 [INFO] Parsing GFF: GCA_048887225.1_ASM4888722v1_genomic.gff\n",
      "2026-01-21 11:08:21,191 [INFO]   → Parsed 3005 CDS features across 49 contigs\n",
      "2026-01-21 11:08:21,194 [INFO] Parsing GFF: GCA_029210805.1_ASM2921080v1_genomic.gff\n",
      "2026-01-21 11:08:21,207 [INFO]   → Parsed 3958 CDS features across 675 contigs\n",
      "2026-01-21 11:08:21,210 [INFO] Parsing GFF: GCA_048887165.1_ASM4888716v1_genomic.gff\n",
      "2026-01-21 11:08:21,225 [INFO]   → Parsed 3859 CDS features across 219 contigs\n",
      "2026-01-21 11:08:21,228 [INFO] Parsing GFF: GCA_038884015.1_ASM3888401v1_genomic.gff\n",
      "2026-01-21 11:08:21,238 [INFO]   → Parsed 2542 CDS features across 26 contigs\n",
      "2026-01-21 11:08:21,240 [INFO] Parsing GFF: GCA_030667705.1_ASM3066770v1_genomic.gff\n",
      "2026-01-21 11:08:21,250 [INFO]   → Parsed 3016 CDS features across 228 contigs\n",
      "2026-01-21 11:08:21,253 [INFO] Parsing GFF: GCA_023705985.1_ASM2370598v1_genomic.gff\n",
      "2026-01-21 11:08:21,265 [INFO]   → Parsed 3383 CDS features across 378 contigs\n",
      "2026-01-21 11:08:21,267 [INFO] Parsing GFF: GCA_019057475.1_ASM1905747v1_genomic.gff\n",
      "2026-01-21 11:08:21,282 [INFO]   → Parsed 3164 CDS features across 56 contigs\n",
      "2026-01-21 11:08:21,285 [INFO] Parsing GFF: GCA_965612995.1_SRR6823440_concoct_113_genomic.gff\n",
      "2026-01-21 11:08:21,298 [INFO]   → Parsed 2836 CDS features across 119 contigs\n",
      "2026-01-21 11:08:21,300 [INFO] Parsing GFF: GCA_029856505.1_ASM2985650v1_genomic.gff\n",
      "2026-01-21 11:08:21,308 [INFO]   → Parsed 2300 CDS features across 132 contigs\n",
      "2026-01-21 11:08:21,310 [INFO] Parsing GFF: GCA_016933055.1_ASM1693305v1_genomic.gff\n",
      "2026-01-21 11:08:21,324 [INFO]   → Parsed 3322 CDS features across 36 contigs\n",
      "2026-01-21 11:08:21,327 [INFO] Parsing GFF: GCA_001940665.2_ASM194066v2_genomic.gff\n",
      "2026-01-21 11:08:21,332 [INFO]   → Parsed 1464 CDS features across 1 contigs\n",
      "2026-01-21 11:08:21,334 [INFO] Parsing GFF: GCA_048940445.1_ASM4894044v1_genomic.gff\n",
      "2026-01-21 11:08:21,345 [INFO]   → Parsed 3387 CDS features across 138 contigs\n",
      "2026-01-21 11:08:21,348 [INFO] Parsing GFF: GCA_038131005.1_139573_S174.scaffolds.fasta_genomic.gff\n",
      "2026-01-21 11:08:21,353 [INFO]   → Parsed 1501 CDS features across 50 contigs\n",
      "2026-01-21 11:08:21,355 [INFO] Parsing GFF: GCA_937877725.1_SRR6823441_bin.193_CONCOCT_v1.1_MAG_genomic.gff\n",
      "2026-01-21 11:08:21,367 [INFO]   → Parsed 3701 CDS features across 240 contigs\n",
      "2026-01-21 11:08:21,370 [INFO] Parsing GFF: GCA_019058135.1_ASM1905813v1_genomic.gff\n",
      "2026-01-21 11:08:21,383 [INFO]   → Parsed 3523 CDS features across 547 contigs\n",
      "2026-01-21 11:08:21,386 [INFO] Parsing GFF: GCA_004376705.1_ASM437670v1_genomic.gff\n",
      "2026-01-21 11:08:21,396 [INFO]   → Parsed 2529 CDS features across 307 contigs\n",
      "2026-01-21 11:08:21,398 [INFO] Parsing GFF: GCA_011364925.1_ASM1136492v1_genomic.gff\n",
      "2026-01-21 11:08:21,411 [INFO]   → Parsed 3616 CDS features across 112 contigs\n",
      "2026-01-21 11:08:21,414 [INFO] Parsing GFF: GCA_048938025.1_ASM4893802v1_genomic.gff\n",
      "2026-01-21 11:08:21,425 [INFO]   → Parsed 3277 CDS features across 88 contigs\n",
      "2026-01-21 11:08:21,428 [INFO] Parsing GFF: GCA_038820475.1_ASM3882047v1_genomic.gff\n",
      "2026-01-21 11:08:21,435 [INFO]   → Parsed 2006 CDS features across 33 contigs\n",
      "2026-01-21 11:08:21,437 [INFO] Parsing GFF: GCA_030668875.1_ASM3066887v1_genomic.gff\n",
      "2026-01-21 11:08:21,450 [INFO]   → Parsed 2972 CDS features across 99 contigs\n",
      "2026-01-21 11:08:21,452 [INFO] Parsing GFF: GCA_029856875.1_ASM2985687v1_genomic.gff\n",
      "2026-01-21 11:08:21,461 [INFO]   → Parsed 2741 CDS features across 361 contigs\n",
      "2026-01-21 11:08:21,464 [INFO] Parsing GFF: GCA_030612005.1_ASM3061200v1_genomic.gff\n",
      "2026-01-21 11:08:21,477 [INFO]   → Parsed 3441 CDS features across 270 contigs\n",
      "2026-01-21 11:08:21,480 [INFO] Parsing GFF: GCA_014730125.1_ASM1473012v1_genomic.gff\n",
      "2026-01-21 11:08:21,498 [INFO]   → Parsed 4818 CDS features across 487 contigs\n",
      "2026-01-21 11:08:21,501 [INFO] Parsing GFF: GCA_048938455.1_ASM4893845v1_genomic.gff\n",
      "2026-01-21 11:08:21,516 [INFO]   → Parsed 4144 CDS features across 90 contigs\n",
      "2026-01-21 11:08:21,519 [INFO] Parsing GFF: GCA_038840315.1_ASM3884031v1_genomic.gff\n",
      "2026-01-21 11:08:21,528 [INFO]   → Parsed 2311 CDS features across 25 contigs\n",
      "2026-01-21 11:08:21,531 [INFO] Parsing GFF: GCA_015523565.1_ASM1552356v1_genomic.gff\n",
      "2026-01-21 11:08:21,542 [INFO]   → Parsed 3158 CDS features across 233 contigs\n",
      "2026-01-21 11:08:21,545 [INFO] Parsing GFF: GCA_005223125.1_ASM522312v1_genomic.gff\n",
      "2026-01-21 11:08:21,564 [INFO]   → Parsed 4010 CDS features across 71 contigs\n",
      "2026-01-21 11:08:21,567 [INFO] Parsing GFF: GCA_019058015.1_ASM1905801v1_genomic.gff\n",
      "2026-01-21 11:08:21,579 [INFO]   → Parsed 3660 CDS features across 283 contigs\n",
      "2026-01-21 11:08:21,593 [INFO] Total CDS features loaded: 390025\n",
      "2026-01-21 11:08:22,026 [INFO] \n",
      "[STEP 2] Mapping hits to gene order...\n",
      "2026-01-21 11:08:22,060 [INFO] \n",
      "[STEP 3] Extracting gene neighborhoods...\n",
      "2026-01-21 11:08:22,061 [INFO] Starting neighborhood extraction (±5 genes)\n",
      "2026-01-21 11:08:22,061 [INFO] Initial anchors: 3325\n",
      "2026-01-21 11:08:22,063 [INFO] Anchors after ESCRT filter: 1480\n",
      "2026-01-21 11:08:22,166 [INFO] Merged 1480 anchor windows into 876 non-overlapping regions\n",
      "2026-01-21 11:08:42,886 [INFO] Extracted 9312 genes from 876 merged neighborhoods\n",
      "2026-01-21 11:08:42,888 [INFO] \n",
      "[STEP 4] Annotating neighbors with query IDs...\n",
      "2026-01-21 11:08:42,891 [INFO] Total genes in neighborhoods: 9312\n",
      "2026-01-21 11:08:42,892 [INFO] Genes with neighbor_query annotation: 1584\n",
      "2026-01-21 11:08:42,893 [INFO] Sample neighbor_query values: ['E2-VPS23', 'Vps4', 'E1', 'E2', 'Ub-like', 'Vps28', 'EAP30', 'VPS25', 'ESCRTIII', 'E3-dom']\n",
      "2026-01-21 11:08:42,893 [INFO] \n",
      "[STEP 5] Merging center gene AsCOG annotations...\n",
      "2026-01-21 11:08:42,894 [INFO] \n",
      "Annotated neighborhoods: 9312 total genes\n",
      "2026-01-21 11:08:42,894 [INFO] ======================================================================\n",
      "2026-01-21 11:08:42,894 [INFO] SYNTENY PIPELINE COMPLETED SUCCESSFULLY\n",
      "2026-01-21 11:08:42,895 [INFO] ======================================================================\n",
      "2026-01-21 11:08:42,908 [INFO] \n",
      "======================================================================\n",
      "2026-01-21 11:08:42,909 [INFO] PIPELINE OUTPUT SUMMARY\n",
      "2026-01-21 11:08:42,909 [INFO] ======================================================================\n",
      "2026-01-21 11:08:42,910 [INFO] \n",
      "Anchor gene Architecture distribution:\n",
      "2026-01-21 11:08:42,911 [INFO] architecture\n",
      "MPN             662\n",
      "Vps4            497\n",
      "E1              415\n",
      "Ub-like         282\n",
      "EAP30           280\n",
      "ESCRTIII        245\n",
      "E2              212\n",
      "VPS25           119\n",
      "Vps28           113\n",
      "BRO1             70\n",
      "E2-VPS23         69\n",
      "PH-VPS23         51\n",
      "E3-HEAT          47\n",
      "CC-VPS23         45\n",
      "E3-UFM           42\n",
      "E2-E3            37\n",
      "URM1             36\n",
      "FlaD             20\n",
      "E3               20\n",
      "E3-dom           18\n",
      "BAR-VPS28        17\n",
      "Zn-PH            10\n",
      "VPS28-longin      6\n",
      "VPS23             5\n",
      "katanin           3\n",
      "Ub-dom            2\n",
      "E3-PCI            1\n",
      "MPN-E3-dom        1\n",
      "2026-01-21 11:08:42,911 [INFO] \n",
      "First few neighborhood entries:\n",
      "2026-01-21 11:08:42,913 [INFO]                      genome_id      contig  gene_index      protein_id   start     end strand  relative_pos  center_protein center_gene neighbor_architecture  is_target_family\n",
      "0  GCA_001940665.2_ASM194066v2  CP091871.1         136  NDAMOAGK_00136  139607  140479      +            -5  NDAMOAGK_00141    E2-VPS23                   NaN             False\n",
      "1  GCA_001940665.2_ASM194066v2  CP091871.1         137  NDAMOAGK_00137  140483  141823      +            -4  NDAMOAGK_00141    E2-VPS23                   NaN             False\n",
      "2  GCA_001940665.2_ASM194066v2  CP091871.1         138  NDAMOAGK_00138  141813  143192      +            -3  NDAMOAGK_00141    E2-VPS23                   NaN             False\n",
      "3  GCA_001940665.2_ASM194066v2  CP091871.1         139  NDAMOAGK_00139  143217  144101      +            -2  NDAMOAGK_00141    E2-VPS23                   NaN             False\n",
      "4  GCA_001940665.2_ASM194066v2  CP091871.1         140  NDAMOAGK_00140  144124  145431      -            -1  NDAMOAGK_00141    E2-VPS23                   NaN             False\n",
      "2026-01-21 11:08:42,913 [INFO] \n",
      "Genome distribution:\n",
      "2026-01-21 11:08:42,914 [INFO] genome_id\n",
      "GCA_008080745.1_ASM808074v1                            142\n",
      "GCA_021498125.1_ASM2149812v1                           138\n",
      "GCA_021498095.1_ASM2149809v1                           122\n",
      "GCA_021498085.1_ASM2149808v1                           122\n",
      "GCA_027031745.1_ASM2703174v1                           116\n",
      "GCA_029855935.1_ASM2985593v1                           114\n",
      "GCA_019057475.1_ASM1905747v1                           112\n",
      "GCA_048882325.1_ASM4888232v1                           108\n",
      "GCA_052584815.1_ASM5258481v1                           107\n",
      "GCA_030614005.1_ASM3061400v1                           105\n",
      "GCA_005191425.1_ASM519142v1                            105\n",
      "GCA_048882945.1_ASM4888294v1                           104\n",
      "GCA_048882965.1_ASM4888296v1                           104\n",
      "GCA_016839295.1_ASM1683929v1                           102\n",
      "GCA_048882505.1_ASM4888250v1                           102\n",
      "GCA_016839765.1_ASM1683976v1                           101\n",
      "GCA_016933055.1_ASM1693305v1                           101\n",
      "GCA_048882565.1_ASM4888256v1                           101\n",
      "GCA_029856045.1_ASM2985604v1                            97\n",
      "GCA_030587545.2_ASM3058754v2                            95\n",
      "GCA_014730275.1_ASM1473027v1                            93\n",
      "GCA_046482545.1_ASM4648254v1                            92\n",
      "GCA_048938885.1_ASM4893888v1                            91\n",
      "GCA_048938455.1_ASM4893845v1                            91\n",
      "GCA_019058445.1_ASM1905844v1                            90\n",
      "GCA_048939995.1_ASM4893999v1                            90\n",
      "GCA_021513695.1_ASM2151369v1                            90\n",
      "GCA_019057865.1_ASM1905786v1                            88\n",
      "GCA_049671145.1_ASM4967114v1                            88\n",
      "GCA_019058165.1_ASM1905816v1                            88\n",
      "GCA_021513715.1_ASM2151371v1                            86\n",
      "GCA_013388835.1_ASM1338883v1                            86\n",
      "GCA_048885925.1_ASM4888592v1                            85\n",
      "GCA_048941465.1_ASM4894146v1                            84\n",
      "GCA_048882045.1_ASM4888204v1                            84\n",
      "GCA_048939265.1_ASM4893926v1                            84\n",
      "GCA_013166775.1_ASM1316677v1                            84\n",
      "GCA_014730165.1_ASM1473016v1                            84\n",
      "GCA_019057815.1_ASM1905781v1                            84\n",
      "GCA_029856435.1_ASM2985643v1                            84\n",
      "GCA_018335335.1_ASM1833533v1                            84\n",
      "GCA_003144275.1_ASM314427v1                             83\n",
      "GCA_046483985.1_ASM4648398v1                            83\n",
      "GCA_030606485.1_ASM3060648v1                            82\n",
      "GCA_030612005.1_ASM3061200v1                            82\n",
      "GCA_019057575.1_ASM1905757v1                            80\n",
      "GCA_003345555.1_ASM334555v1                             80\n",
      "GCA_048882745.1_ASM4888274v1                            79\n",
      "GCA_048938025.1_ASM4893802v1                            79\n",
      "GCA_019057635.1_ASM1905763v1                            79\n",
      "GCA_048887225.1_ASM4888722v1                            78\n",
      "GCA_048941015.1_ASM4894101v1                            77\n",
      "GCA_019057955.1_ASM1905795v1                            77\n",
      "GCA_014730125.1_ASM1473012v1                            77\n",
      "GCA_016839585.1_ASM1683958v1                            77\n",
      "GCA_015523565.1_ASM1552356v1                            76\n",
      "GCA_016926735.1_ASM1692673v1                            76\n",
      "GCA_038825615.1_ASM3882561v1                            76\n",
      "GCA_048885565.1_ASM4888556v1                            74\n",
      "GCA_048885535.1_ASM4888553v1                            74\n",
      "GCA_048885525.1_ASM4888552v1                            73\n",
      "GCA_019056805.1_ASM1905680v1                            73\n",
      "GCA_030149205.1_ASM3014920v1                            72\n",
      "GCA_023705985.1_ASM2370598v1                            71\n",
      "GCA_030667705.1_ASM3066770v1                            71\n",
      "GCA_005223125.1_ASM522312v1                             71\n",
      "GCA_048887165.1_ASM4888716v1                            71\n",
      "GCA_019894715.1_ASM1989471v1                            70\n",
      "GCA_048941605.1_ASM4894160v1                            70\n",
      "GCA_048941715.1_ASM4894171v1                            70\n",
      "GCA_018238545.1_ASM1823854v1                            69\n",
      "GCA_019058095.1_ASM1905809v1                            69\n",
      "GCA_046497275.1_ASM4649727v1                            68\n",
      "GCA_018238345.1_ASM1823834v1                            67\n",
      "GCA_019058015.1_ASM1905801v1                            66\n",
      "GCA_048938295.1_ASM4893829v1                            66\n",
      "GCA_048938825.1_ASM4893882v1                            64\n",
      "GCA_029210805.1_ASM2921080v1                            64\n",
      "GCA_038846665.1_ASM3884666v1                            63\n",
      "GCA_038884015.1_ASM3888401v1                            63\n",
      "GCA_038889235.1_ASM3888923v1                            63\n",
      "GCA_038866325.1_ASM3886632v1                            63\n",
      "GCA_004376705.1_ASM437670v1                             63\n",
      "GCA_038824485.1_ASM3882448v1                            63\n",
      "GCA_038881135.1_ASM3888113v1                            62\n",
      "GCA_038897395.1_ASM3889739v1                            62\n",
      "GCA_038840315.1_ASM3884031v1                            62\n",
      "GCA_001940665.2_ASM194066v2                             61\n",
      "GCA_038861695.1_ASM3886169v1                            61\n",
      "GCA_038819355.1_ASM3881935v1                            61\n",
      "GCA_030668875.1_ASM3066887v1                            61\n",
      "GCA_038820475.1_ASM3882047v1                            60\n",
      "GCA_048938985.1_ASM4893898v1                            60\n",
      "GCA_048941285.1_ASM4894128v1                            60\n",
      "GCA_048940445.1_ASM4894044v1                            60\n",
      "GCA_004524535.1_ASM452453v1                             58\n",
      "GCA_051746095.1_ASM5174609v1                            58\n",
      "GCA_038131005.1_139573_S174.scaffolds.fasta             57\n",
      "GCA_019058035.1_ASM1905803v1                            56\n",
      "GCA_011364925.1_ASM1136492v1                            56\n",
      "GCA_038854135.1_ASM3885413v1                            55\n",
      "GCA_027031765.1_ASM2703176v1                            54\n",
      "GCA_048882285.1_ASM4888228v1                            54\n",
      "GCA_038822405.1_ASM3882240v1                            53\n",
      "GCA_018238585.1_ASM1823858v1                            53\n",
      "GCA_048886755.1_ASM4888675v1                            53\n",
      "GCA_038858525.1_ASM3885852v1                            53\n",
      "GCA_029882335.1_ASM2988233v1                            51\n",
      "GCA_048885705.1_ASM4888570v1                            51\n",
      "GCA_048885325.1_ASM4888532v1                            50\n",
      "GCA_016839265.1_ASM1683926v1                            50\n",
      "GCA_965612995.1_SRR6823440_concoct_113                  49\n",
      "GCA_026993975.1_ASM2699397v1                            48\n",
      "GCA_029856505.1_ASM2985650v1                            47\n",
      "GCA_937877725.1_SRR6823441_bin.193_CONCOCT_v1.1_MAG     46\n",
      "GCA_048939465.1_ASM4893946v1                            46\n",
      "GCA_029856545.1_ASM2985654v1                            46\n",
      "GCA_038855695.1_ASM3885569v1                            44\n",
      "GCA_019058135.1_ASM1905813v1                            44\n",
      "GCA_030641055.1_ASM3064105v1                            40\n",
      "GCA_023705685.1_ASM2370568v1                            34\n",
      "GCA_048885575.1_ASM4888557v1                            33\n",
      "GCA_016840425.1_ASM1684042v1                            32\n",
      "GCA_016840465.1_ASM1684046v1                            30\n",
      "GCA_029856525.1_ASM2985652v1                            27\n",
      "GCA_019058055.1_ASM1905805v1                            26\n",
      "GCA_029856875.1_ASM2985687v1                            24\n",
      "GCA_038826135.1_ASM3882613v1                            24\n",
      "2026-01-21 11:08:42,915 [INFO] \n",
      "Saving neighborhood data...\n",
      "2026-01-21 11:08:42,932 [INFO] Saved: [STEP:6]escrt_neighborhoods_2026-01-21-11-08-12.csv\n",
      "2026-01-21 11:08:42,933 [INFO] Saving anchor hits...\n",
      "2026-01-21 11:08:42,945 [INFO] Saved: [STEP:7]escrt_anchor_hits_2026-01-21-11-08-12.csv\n",
      "2026-01-21 11:08:42,945 [INFO] \n",
      "======================================================================\n",
      "2026-01-21 11:08:42,946 [INFO] ADDING TAXONOMY INFORMATION\n",
      "2026-01-21 11:08:42,946 [INFO] ======================================================================\n",
      "2026-01-21 11:08:42,947 [INFO] ======================================================================\n",
      "2026-01-21 11:08:42,947 [INFO] STARTING TAXONOMY MERGE\n",
      "2026-01-21 11:08:42,948 [INFO] ======================================================================\n",
      "2026-01-21 11:08:42,948 [INFO] Loading neighborhood data from: /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/[STEP:6]escrt_neighborhoods_2026-01-21-11-08-12.csv\n",
      "2026-01-21 11:08:42,961 [INFO] Neighborhood data: 9312 rows, 128 unique genomes\n",
      "2026-01-21 11:08:42,961 [INFO] Loading GTDB taxonomy from: /home/anirudh/synteny/ar53_taxonomy_r226.tsv\n",
      "2026-01-21 11:08:42,979 [INFO] Loaded taxonomy for 17245 genomes\n",
      "2026-01-21 11:08:42,980 [INFO] Sample taxonomy entry: d__Archaea;p__Methanobacteriota;c__Methanobacteria;o__Methanobacteriales;f__Methanobacteriaceae;g__Methanocatella;s__Methanocatella smithii\n",
      "2026-01-21 11:08:42,991 [INFO] Taxonomy split into 7 columns\n",
      "2026-01-21 11:08:42,999 [INFO] Extracted domain: 17245 non-null values\n",
      "2026-01-21 11:08:43,006 [INFO] Extracted phylum: 17245 non-null values\n",
      "2026-01-21 11:08:43,012 [INFO] Extracted class: 17245 non-null values\n",
      "2026-01-21 11:08:43,018 [INFO] Extracted order: 17245 non-null values\n",
      "2026-01-21 11:08:43,024 [INFO] Extracted family: 17245 non-null values\n",
      "2026-01-21 11:08:43,030 [INFO] Extracted genus: 17245 non-null values\n",
      "2026-01-21 11:08:43,036 [INFO] Extracted species: 17245 non-null values\n",
      "2026-01-21 11:08:43,039 [INFO] Sample parsed taxonomy:\n",
      "2026-01-21 11:08:43,042 [INFO]             genome_id   domain             phylum            class\n",
      "0  RS_GCF_945873965.1  Archaea  Methanobacteriota  Methanobacteria\n",
      "1  GB_GCA_963642515.1  Archaea  Methanobacteriota  Methanobacteria\n",
      "2  GB_GCA_023453475.1  Archaea  Methanobacteriota  Methanobacteria\n",
      "3  RS_GCF_000189895.1  Archaea  Methanobacteriota  Methanobacteria\n",
      "4  RS_GCF_000189795.1  Archaea  Methanobacteriota  Methanobacteria\n",
      "2026-01-21 11:08:43,044 [INFO] Genome ID overlap check:\n",
      "2026-01-21 11:08:43,045 [INFO]   Genomes in neighborhood data: 128\n",
      "2026-01-21 11:08:43,045 [INFO]   Genomes in taxonomy data: 17245\n",
      "2026-01-21 11:08:43,046 [INFO]   Overlapping genomes: 87\n",
      "2026-01-21 11:08:43,046 [WARNING] 41 genomes from neighborhood data not found in taxonomy!\n",
      "2026-01-21 11:08:43,047 [INFO] Performing left join on genome_id...\n",
      "2026-01-21 11:08:43,054 [INFO] Merge complete: 9312 rows\n",
      "2026-01-21 11:08:43,055 [INFO]   domain: 6263 non-null (67.3%)\n",
      "2026-01-21 11:08:43,056 [INFO]   phylum: 6263 non-null (67.3%)\n",
      "2026-01-21 11:08:43,057 [INFO]   class: 6263 non-null (67.3%)\n",
      "2026-01-21 11:08:43,058 [INFO]   order: 6263 non-null (67.3%)\n",
      "2026-01-21 11:08:43,059 [INFO]   family: 6263 non-null (67.3%)\n",
      "2026-01-21 11:08:43,060 [INFO]   genus: 6263 non-null (67.3%)\n",
      "2026-01-21 11:08:43,061 [INFO]   species: 6263 non-null (67.3%)\n",
      "2026-01-21 11:08:43,061 [INFO] Saving merged data to: /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/[STEP:8]escrt_neighborhoods_with_taxonomy_2026-01-21-11-08-12.csv\n",
      "2026-01-21 11:08:43,089 [INFO] Sample of merged data with taxonomy:\n",
      "2026-01-21 11:08:43,091 [INFO]        protein_id   domain           phylum         class           order\n",
      "0  NDAMOAGK_00136  Archaea  Asgardarchaeota  Odinarchaeia  Odinarchaeales\n",
      "1  NDAMOAGK_00137  Archaea  Asgardarchaeota  Odinarchaeia  Odinarchaeales\n",
      "2  NDAMOAGK_00138  Archaea  Asgardarchaeota  Odinarchaeia  Odinarchaeales\n",
      "3  NDAMOAGK_00139  Archaea  Asgardarchaeota  Odinarchaeia  Odinarchaeales\n",
      "4  NDAMOAGK_00140  Archaea  Asgardarchaeota  Odinarchaeia  Odinarchaeales\n",
      "5  NDAMOAGK_00141  Archaea  Asgardarchaeota  Odinarchaeia  Odinarchaeales\n",
      "6  NDAMOAGK_00142  Archaea  Asgardarchaeota  Odinarchaeia  Odinarchaeales\n",
      "7  NDAMOAGK_00143  Archaea  Asgardarchaeota  Odinarchaeia  Odinarchaeales\n",
      "8  NDAMOAGK_00144  Archaea  Asgardarchaeota  Odinarchaeia  Odinarchaeales\n",
      "9  NDAMOAGK_00145  Archaea  Asgardarchaeota  Odinarchaeia  Odinarchaeales\n",
      "2026-01-21 11:08:43,091 [INFO] ======================================================================\n",
      "2026-01-21 11:08:43,092 [INFO] TAXONOMY MERGE COMPLETE\n",
      "2026-01-21 11:08:43,092 [INFO] ======================================================================\n",
      "2026-01-21 11:08:43,095 [INFO] \n",
      "Taxonomic diversity in results:\n",
      "2026-01-21 11:08:43,096 [INFO] Unique phyla: 1\n",
      "2026-01-21 11:08:43,096 [INFO] Unique classes: 8\n",
      "2026-01-21 11:08:43,097 [INFO] Unique orders: 11\n",
      "2026-01-21 11:08:43,097 [INFO] \n",
      "Sample genomes with taxonomy:\n",
      "2026-01-21 11:08:43,101 [INFO]       genome_id_base           phylum             class               order\n",
      "0    GCA_001940665.2  Asgardarchaeota      Odinarchaeia      Odinarchaeales\n",
      "61   GCA_003144275.1  Asgardarchaeota  Heimdallarchaeia       Hodarchaeales\n",
      "144  GCA_003345555.1  Asgardarchaeota      Thorarchaeia      Thorarchaeales\n",
      "224  GCA_004376705.1  Asgardarchaeota      Lokiarchaeia     Sigynarchaeales\n",
      "287  GCA_004524535.1  Asgardarchaeota      Lokiarchaeia     Sigynarchaeales\n",
      "345  GCA_005191425.1  Asgardarchaeota      Lokiarchaeia       Helarchaeales\n",
      "450  GCA_005223125.1  Asgardarchaeota      Lokiarchaeia     Sigynarchaeales\n",
      "521  GCA_008080745.1  Asgardarchaeota      Thorarchaeia      Thorarchaeales\n",
      "663  GCA_011364925.1  Asgardarchaeota      Lokiarchaeia     Sigynarchaeales\n",
      "719  GCA_013166775.1  Asgardarchaeota  Heimdallarchaeia  Heimdallarchaeales\n",
      "2026-01-21 11:08:43,101 [INFO] \n",
      "======================================================================\n",
      "2026-01-21 11:08:43,102 [INFO] ALL PROCESSING COMPLETE\n",
      "2026-01-21 11:08:43,102 [INFO] ======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run the main synteny pipeline\n",
    "neigh_df, anchor_df = run_synteny_pipeline(\n",
    "    hits_df = df_with_arch,\n",
    "    gff_dir=\"/home/anirudh/genomes/selected_genomes/prokka_results\",\n",
    "    window=5,\n",
    "    min_coverage=0.65,\n",
    "    max_i_evalue=1e-5,\n",
    ")\n",
    "\n",
    "# Quick sanity checks\n",
    "logging.info(\"\\n\" + \"=\" * 70)\n",
    "logging.info(\"PIPELINE OUTPUT SUMMARY\")\n",
    "logging.info(\"=\" * 70)\n",
    "\n",
    "logging.info(\"\\nAnchor gene Architecture distribution:\")\n",
    "logging.info(anchor_df[\"architecture\"].value_counts().to_string())\n",
    "\n",
    "logging.info(\"\\nFirst few neighborhood entries:\")\n",
    "logging.info(neigh_df.head().to_string())\n",
    "\n",
    "logging.info(\"\\nGenome distribution:\")\n",
    "logging.info(neigh_df['genome_id'].value_counts().to_string())\n",
    "\n",
    "\n",
    "# Save intermediate results\n",
    "logging.info(\"\\nSaving neighborhood data...\")\n",
    "STEP += 1\n",
    "\n",
    "escrt_nieghborhoods_file = os.path.join(MAIN_OUTDIR, f\"[STEP:{STEP}]escrt_neighborhoods_{rightnow}.csv\")\n",
    "neigh_df.to_csv(escrt_nieghborhoods_file, index=False)\n",
    "logging.info(f\"Saved: [STEP:{STEP}]escrt_neighborhoods_{rightnow}.csv\")\n",
    "\n",
    "logging.info(\"Saving anchor hits...\")\n",
    "STEP += 1\n",
    "anchor_df.to_csv(os.path.join(MAIN_OUTDIR, f\"[STEP:{STEP}]escrt_anchor_hits_{rightnow}.csv\"), index=False)\n",
    "logging.info(f\"Saved: [STEP:{STEP}]escrt_anchor_hits_{rightnow}.csv\")\n",
    "\n",
    "# Merge with taxonomy\n",
    "logging.info(\"\\n\" + \"=\" * 70)\n",
    "logging.info(\"ADDING TAXONOMY INFORMATION\")\n",
    "logging.info(\"=\" * 70)\n",
    "\n",
    "STEP += 1\n",
    "out_csv = os.path.join(MAIN_OUTDIR, f\"[STEP:{STEP}]escrt_neighborhoods_with_taxonomy_{rightnow}.csv\")\n",
    "df = merge_taxonomy(\n",
    "    escrt_nieghborhoods_file, \n",
    "    \"/home/anirudh/synteny/ar53_taxonomy_r226.tsv\", \n",
    "    out_csv\n",
    ")\n",
    "\n",
    "# Show taxonomic diversity in results   \n",
    "logging.info(\"\\nTaxonomic diversity in results:\")\n",
    "logging.info(f\"Unique phyla: {df['phylum'].nunique()}\")\n",
    "logging.info(f\"Unique classes: {df['class'].nunique()}\") \n",
    "logging.info(f\"Unique orders: {df['order'].nunique()}\")\n",
    "\n",
    "logging.info(\"\\nSample genomes with taxonomy:\")\n",
    "logging.info(df[[\"genome_id_base\", \"phylum\", \"class\", \"order\"]].drop_duplicates().head(10).to_string())\n",
    "\n",
    "logging.info(\"\\n\" + \"=\" * 70)\n",
    "logging.info(\"ALL PROCESSING COMPLETE\")\n",
    "logging.info(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc91f487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:08:43,109 [INFO] \n",
      "======================================================================\n",
      "2026-01-21 11:08:43,110 [INFO] ARCHITECTURE FILTERING DIAGNOSTIC\n",
      "2026-01-21 11:08:43,111 [INFO] ======================================================================\n",
      "2026-01-21 11:08:43,111 [INFO] Total proteins with valid HMM hits (i_evalue ≤ 1e-5, coverage ≥ 0.65): 3325\n",
      "2026-01-21 11:08:43,112 [INFO] Proteins with architectures matching keywords: 1470\n",
      "2026-01-21 11:08:43,112 [INFO] Proteins with architectures NOT matching keywords: 1855\n",
      "2026-01-21 11:08:43,113 [WARNING] \n",
      "⚠️  WARNING: 1855 proteins will be EXCLUDED from neighborhoods:\n",
      "2026-01-21 11:08:43,117 [WARNING]             target architecture\n",
      "0   AAEOKEPF_00166           E2\n",
      "3   AAEOKEPF_00273       E3-UFM\n",
      "6   AAEOKEPF_00322           E1\n",
      "8   AAEOKEPF_00337           E1\n",
      "10  AAEOKEPF_00338          MPN\n",
      "12  AAEOKEPF_00690          MPN\n",
      "13  AAEOKEPF_00878          MPN\n",
      "15  AAEOKEPF_00882      Ub-like\n",
      "19  AAEOKEPF_01109          MPN\n",
      "20  AAEOKEPF_01385          MPN\n",
      "29  AAEOKEPF_01448          MPN\n",
      "38  AAEOKEPF_02039          MPN\n",
      "39  AAEOKEPF_02040           E1\n",
      "42  AAEOKEPF_02593           E1\n",
      "49  AAEOKEPF_02795           E1\n",
      "52  AAEOKEPF_02806      E3-HEAT\n",
      "58  AEGAMCKF_00140          MPN\n",
      "62  AEGAMCKF_00191          MPN\n",
      "67  AEGAMCKF_00193           E2\n",
      "71  AEGAMCKF_00268          MPN\n",
      "2026-01-21 11:08:43,117 [WARNING] \n",
      "Distribution of excluded architectures:\n",
      "2026-01-21 11:08:43,118 [WARNING] architecture\n",
      "MPN           662\n",
      "E1            415\n",
      "Ub-like       282\n",
      "E2            212\n",
      "BRO1           70\n",
      "E3-HEAT        47\n",
      "E3-UFM         42\n",
      "E2-E3          37\n",
      "URM1           36\n",
      "E3             20\n",
      "E3-dom         18\n",
      "Zn-PH          10\n",
      "Ub-dom          2\n",
      "MPN-E3-dom      1\n",
      "E3-PCI          1\n",
      "2026-01-21 11:08:43,122 [WARNING] \n",
      "Saved excluded proteins to: /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/[DIAGNOSTIC]excluded_proteins_by_keyword_filter_2026-01-21-11-08-12.csv\n",
      "2026-01-21 11:08:43,122 [INFO] ======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# DIAGNOSTIC: Check which architectures would be filtered by keywords\n",
    "# ------------------------------------------------------------------\n",
    "keywords = (\"vps\", \"escrt\", \"katanin\", \"eap\", \"flad\")\n",
    "keyword_pattern = \"|\".join(keywords)\n",
    "\n",
    "# Create a boolean mask for architectures matching keywords\n",
    "matches_keywords = (\n",
    "    df_with_arch[\"architecture\"]\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.contains(keyword_pattern)\n",
    ")\n",
    "\n",
    "# Count what would be kept vs discarded\n",
    "kept_count = matches_keywords.sum()\n",
    "discarded_count = (~matches_keywords).sum()\n",
    "\n",
    "logging.info(\"\\n\" + \"=\" * 70)\n",
    "logging.info(\"ARCHITECTURE FILTERING DIAGNOSTIC\")\n",
    "logging.info(\"=\" * 70)\n",
    "logging.info(f\"Total proteins with valid HMM hits (i_evalue ≤ 1e-5, coverage ≥ 0.65): {len(df_with_arch)}\")\n",
    "logging.info(f\"Proteins with architectures matching keywords: {kept_count}\")\n",
    "logging.info(f\"Proteins with architectures NOT matching keywords: {discarded_count}\")\n",
    "\n",
    "if discarded_count > 0:\n",
    "    logging.warning(f\"\\n⚠️  WARNING: {discarded_count} proteins will be EXCLUDED from neighborhoods:\")\n",
    "    excluded = df_with_arch[~matches_keywords][[\"target\", \"architecture\"]].drop_duplicates()\n",
    "    logging.warning(excluded.head(20).to_string())\n",
    "    \n",
    "    # Count distribution of excluded architectures\n",
    "    logging.warning(\"\\nDistribution of excluded architectures:\")\n",
    "    arch_counts = df_with_arch[~matches_keywords][\"architecture\"].value_counts()\n",
    "    logging.warning(arch_counts.head(20).to_string())\n",
    "    \n",
    "    # Save for review\n",
    "    excluded_file = os.path.join(MAIN_OUTDIR, f\"[DIAGNOSTIC]excluded_proteins_by_keyword_filter_{rightnow}.csv\")\n",
    "    df_with_arch[~matches_keywords][[\"target\", \"architecture\", \"architecture_method\"]].drop_duplicates().sort_values(by = ['architecture'], ascending=False).to_csv(excluded_file, index=False)\n",
    "    logging.warning(f\"\\nSaved excluded proteins to: {excluded_file}\")\n",
    "else:\n",
    "    logging.info(\"✓ All proteins with valid hits match keyword filter - no data loss\")\n",
    "\n",
    "logging.info(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2328c7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:08:43,140 [INFO] Loading annotated neighborhood table\n",
      "2026-01-21 11:08:43,155 [INFO] Loaded 9312 gene-level rows\n",
      "2026-01-21 11:08:43,155 [INFO] Encoding architecture tokens\n",
      "2026-01-21 11:08:43,156 [INFO] Constructing contig-level architectures\n",
      "2026-01-21 11:08:43,166 [INFO] Identified 574 contig-level architectures\n",
      "2026-01-21 11:08:43,169 [INFO] Trimming architectures (k=0) and collapsing inverses\n",
      "2026-01-21 11:08:43,173 [INFO] Collapsing architectures using inversion + subtuple equivalence\n",
      "2026-01-21 11:08:43,193 [INFO] Assigning architectures to maximal representatives (subtuple + inverse-aware)\n",
      "2026-01-21 11:08:43,200 [INFO] Counting architectures per family (inverse + subtuple collapsed)\n",
      "2026-01-21 11:08:43,203 [INFO] Selecting representative architecture per lineage\n",
      "2026-01-21 11:08:43,204 [INFO]                                   rep_arch_canonical  information  count\n",
      "0  (EAP30, Vps28, Vps28, E2-VPS23, ESCRTIII, ESCR...            9     16\n",
      "1        (CC-VPS23, ESCRTIII, ESCRTIII, Vps4, VPS25)            5      5\n",
      "2  (E1, E2, Ub-like, other, other, E2-VPS23, Vps2...            7      1\n",
      "3  (E2-VPS23, Vps28, EAP30, other, other, other, ...            4     35\n",
      "7                                      (VPS25, Vps4)            2     15\n",
      "4  (ESCRTIII, other, ESCRTIII, CC-VPS23, other, o...            4      8\n",
      "6  (ESCRTIII, other, other, ESCRTIII, CC-VPS23, o...            4      6\n",
      "5  (ESCRTIII, other, other, CC-VPS23, other, othe...            3      1\n",
      "9  (E2, Ub-like, other, other, E2-VPS23, Vps28, E...            9      8\n",
      "8                                        (CC-VPS23,)            1      1\n",
      "2026-01-21 11:08:43,210 [INFO] Selected 16 representative architectures\n",
      "2026-01-21 11:08:43,210 [INFO] Recovering genomes encoding longest architectures with maximal subtuple support\n",
      "2026-01-21 11:08:43,213 [INFO] Extracting gene-level rows for plotting (all contigs from representative genomes)\n",
      "rep_keys columns:  Index(['family', 'rep_arch_canonical', 'count', 'information', 'genome_id_x',\n",
      "       'contig', 'center_protein', 'arch_token_canonical',\n",
      "       'arch_token_trimmed'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:08:43,214 [INFO] Representative genomes identified: 16\n",
      "2026-01-21 11:08:43,217 [INFO] Plot df shape after genome-level filtering: (470, 23)\n",
      "2026-01-21 11:08:43,221 [INFO] Architecture analysis complete\n",
      "2026-01-21 11:08:43,221 [INFO] Results written to: /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/architecture_results_2026-01-21-11-08-12\n",
      "2026-01-21 11:08:43,222 [INFO] Files generated:\n",
      "2026-01-21 11:08:43,222 [INFO]   - [STEP:10]contig_architectures_trimmed_canonical.csv\n",
      "2026-01-21 11:08:43,224 [INFO]   - [STEP:11]collapsed_arch_df.csv\n",
      "2026-01-21 11:08:43,225 [INFO]   - [STEP:12]contig_architectures_with_representatives.csv\n",
      "2026-01-21 11:08:43,225 [INFO]   - [STEP:13]architecture_frequencies_inverse_subtuple_collapsed.csv\n",
      "2026-01-21 11:08:43,226 [INFO]   - [STEP:14]representative_architectures.csv\n",
      "2026-01-21 11:08:43,226 [INFO]   - [STEP:15]representative_architectures_with_genomes.csv\n",
      "2026-01-21 11:08:43,227 [INFO]   - [STEP:16]representative_genomes.csv\n",
      "2026-01-21 11:08:43,227 [INFO]   - [STEP:17]plot_ready_architectures.csv\n",
      "2026-01-21 11:08:43,228 [INFO]   - [STEP:9]contig_architectures_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# Architecture Analysis\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Architecture analysis and reduction script (orientation-invariant)\n",
    "=================================================================\n",
    "\n",
    "Input:\n",
    "  - Annotated neighborhood CSV with taxonomy and architecture labels\n",
    "\n",
    "Output:\n",
    "  - Contig-level trimmed & canonical architectures\n",
    "  - Lineage-level architecture counts (inverse + subtuple collapsed)\n",
    "  - Representative contigs per lineage\n",
    "  - Gene-level dataframe for plotting\n",
    "\n",
    "Key features:\n",
    "  - Flank trimming (k=2)\n",
    "  - Orientation-invariant (inverse) collapsing\n",
    "  - Counts incorporate reversed architectures\n",
    "  - Subtuple matching for architecture equivalence\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# CONFIG\n",
    "# ------------------------------------------------------------------\n",
    "INPUT_CSV = out_csv # Output from previous step with taxonomy [should be [step:8]escrt_neighborhoods_with_taxonomy_{rightnow}.csv]\n",
    "OUTDIR = Path(os.path.join(MAIN_OUTDIR, f\"architecture_results_{rightnow}\"))\n",
    "OUTDIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Helper functions\n",
    "# ------------------------------------------------------------------\n",
    "def trim_architecture(tokens, k=2):\n",
    "    \"\"\"\n",
    "    Trim architecture by keeping at most k 'other' tokens\n",
    "    at each flank while retaining internal structure.\n",
    "    \"\"\"\n",
    "    tokens = list(tokens)\n",
    "\n",
    "    left = 0\n",
    "    while left < len(tokens) and tokens[left] == \"other\":\n",
    "        left += 1\n",
    "    left = max(0, left - k)\n",
    "\n",
    "    right = len(tokens)\n",
    "    while right > 0 and tokens[right - 1] == \"other\":\n",
    "        right -= 1\n",
    "    right = min(len(tokens), right + k)\n",
    "\n",
    "    return tuple(tokens[left:right])\n",
    "\n",
    "\n",
    "def canonicalize_architecture(tokens):\n",
    "    \"\"\"\n",
    "    Orientation-invariant canonical form\n",
    "    \"\"\"\n",
    "    tokens = tuple(tokens)\n",
    "    return min(tokens, tokens[::-1])\n",
    "\n",
    "\n",
    "def is_subtuple(short, long):\n",
    "    \"\"\"\n",
    "    Check if `short` is a contiguous subtuple of `long`\n",
    "    \"\"\"\n",
    "    n, m = len(short), len(long)\n",
    "    if n > m:\n",
    "        return False\n",
    "    for i in range(m - n + 1):\n",
    "        if long[i:i+n] == short:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def architecture_equivalent(a, b):\n",
    "    \"\"\"\n",
    "    Equivalence under:\n",
    "      - inversion\n",
    "      - truncation (subtuple)\n",
    "      - inversion + truncation\n",
    "    \"\"\"\n",
    "    a = tuple(a)\n",
    "    b = tuple(b)\n",
    "\n",
    "    return (\n",
    "        is_subtuple(a, b) or\n",
    "        is_subtuple(a, b[::-1]) or\n",
    "        is_subtuple(a[::-1], b) or\n",
    "        is_subtuple(a[::-1], b[::-1])\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Step 1: Load data\n",
    "# ------------------------------------------------------------------\n",
    "logging.info(\"Loading annotated neighborhood table\")\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "df[\"neighbor_architecture\"] = df[\"neighbor_architecture\"].str.strip()\n",
    "\n",
    "required_cols = {\n",
    "    \"genome_id_x\", \"contig\", \"center_protein\",\n",
    "    \"relative_pos\", \"neighbor_architecture\",\n",
    "    LINEAGE_LEVEL\n",
    "}\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "logging.info(f\"Loaded {len(df)} gene-level rows\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Step 2: Encode architecture tokens\n",
    "# ------------------------------------------------------------------\n",
    "logging.info(\"Encoding architecture tokens\")\n",
    "\n",
    "df[\"arch_token\"] = df[\"neighbor_architecture\"].fillna(\"other\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Step 3: Build contig-level architectures\n",
    "# ------------------------------------------------------------------\n",
    "logging.info(\"Constructing contig-level architectures\")\n",
    "\n",
    "arch_df = (\n",
    "    df\n",
    "    .sort_values(\"relative_pos\")\n",
    "    .groupby(\n",
    "        [\"genome_id_x\", \"contig\", \"center_protein\", LINEAGE_LEVEL],\n",
    "        as_index=False\n",
    "    )\n",
    "    .agg(\n",
    "        arch_token=(\"arch_token\", lambda x: tuple(x)),\n",
    "        n_genes=(\"arch_token\", \"count\")\n",
    "    )\n",
    ")\n",
    "\n",
    "logging.info(f\"Identified {len(arch_df)} contig-level architectures\")\n",
    "\n",
    "STEP += 1\n",
    "arch_df.to_csv(\n",
    "    OUTDIR / f\"[STEP:{STEP}]contig_architectures_raw.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Step 4: Trim flanks + canonicalize\n",
    "# ------------------------------------------------------------------\n",
    "logging.info(f\"Trimming architectures (k={FLANK_K}) and collapsing inverses\")\n",
    "\n",
    "arch_df[\"arch_token_trimmed\"] = arch_df[\"arch_token\"].apply(\n",
    "    lambda x: trim_architecture(x, k=FLANK_K)\n",
    ")\n",
    "\n",
    "arch_df[\"arch_token_canonical\"] = arch_df[\"arch_token_trimmed\"].apply(\n",
    "    canonicalize_architecture\n",
    ")\n",
    "\n",
    "arch_df[\"trimmed_len\"] = arch_df[\"arch_token_trimmed\"].apply(len)\n",
    "\n",
    "STEP += 1\n",
    "arch_df.to_csv(\n",
    "    OUTDIR / f\"[STEP:{STEP}]contig_architectures_trimmed_canonical.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Step 5A: Collapse to maximal architectures per lineage\n",
    "# ------------------------------------------------------------------\n",
    "logging.info(\"Collapsing architectures using inversion + subtuple equivalence\")\n",
    "\n",
    "collapsed_rows = []\n",
    "representatives = {}  # lineage -> list of maximal architectures\n",
    "\n",
    "for lineage, subdf in arch_df.groupby(LINEAGE_LEVEL):\n",
    "    subdf = subdf.copy()\n",
    "    subdf[\"arch_len\"] = subdf[\"arch_token_trimmed\"].apply(len)\n",
    "    subdf = subdf.sort_values(\"arch_len\", ascending=False)\n",
    "\n",
    "    kept_archs = []\n",
    "\n",
    "    for _, row in subdf.iterrows():\n",
    "        arch = row[\"arch_token_trimmed\"]\n",
    "\n",
    "        if any(architecture_equivalent(arch, kept) for kept in kept_archs):\n",
    "            continue\n",
    "\n",
    "        kept_archs.append(arch)\n",
    "        collapsed_rows.append(row)\n",
    "\n",
    "    representatives[lineage] = kept_archs\n",
    "\n",
    "collapsed_arch_df = pd.DataFrame(collapsed_rows).drop(columns=\"arch_len\")\n",
    "\n",
    "STEP += 1\n",
    "collapsed_arch_df.to_csv(\n",
    "    OUTDIR / f\"[STEP:{STEP}]collapsed_arch_df.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Step 5B: Assign EVERY architecture to a representative\n",
    "# ------------------------------------------------------------------\n",
    "logging.info(\n",
    "    \"Assigning architectures to maximal representatives (subtuple + inverse-aware)\"\n",
    ")\n",
    "\n",
    "def assign_representative(row):\n",
    "    lineage = row[LINEAGE_LEVEL]\n",
    "    arch = row[\"arch_token_trimmed\"]\n",
    "\n",
    "    for rep in representatives[lineage]:\n",
    "        if architecture_equivalent(arch, rep):\n",
    "            return canonicalize_architecture(rep)\n",
    "\n",
    "    return None\n",
    "\n",
    "arch_df[\"rep_arch_canonical\"] = arch_df.apply(assign_representative, axis=1)\n",
    "\n",
    "if arch_df[\"rep_arch_canonical\"].isna().any():\n",
    "    raise RuntimeError(\"Some architectures could not be assigned to a representative\")\n",
    "\n",
    "STEP += 1\n",
    "arch_df.to_csv(\n",
    "    OUTDIR / f\"[STEP:{STEP}]contig_architectures_with_representatives.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Step 5C: Count INCLUDING subtuples\n",
    "# ------------------------------------------------------------------\n",
    "logging.info(\n",
    "    f\"Counting architectures per {LINEAGE_LEVEL} (inverse + subtuple collapsed)\"\n",
    ")\n",
    "\n",
    "arch_counts = (\n",
    "    arch_df\n",
    "    .groupby([LINEAGE_LEVEL, \"rep_arch_canonical\"], as_index=False)\n",
    "    .size()\n",
    "    .rename(columns={\"size\": \"count\"})\n",
    "    .sort_values([LINEAGE_LEVEL, \"count\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "STEP += 1\n",
    "arch_counts.to_csv(\n",
    "    OUTDIR / f\"[STEP:{STEP}]architecture_frequencies_inverse_subtuple_collapsed.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Step 6: Select representative architecture per lineage\n",
    "# ------------------------------------------------------------------------------\n",
    "logging.info(\"Selecting representative architecture per lineage\")\n",
    "\n",
    "\n",
    "# doesnt consider singlets for representative selection\n",
    "arch_counts[\"information\"] = arch_counts[\"rep_arch_canonical\"].apply(\n",
    "    lambda arch: sum(gene != \"other\" for gene in arch)\n",
    ")\n",
    "logging.info(arch_counts[[\"rep_arch_canonical\", \"information\", \"count\"]].head(10))\n",
    "\n",
    "\n",
    "rep_arch = (\n",
    "    arch_counts\n",
    "    .query(\"information >= 2\")\n",
    "    .sort_values([\"information\", \"count\"], ascending=[False, False])\n",
    "    .groupby(LINEAGE_LEVEL, as_index=False)\n",
    "    .head(1)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "STEP += 1\n",
    "rep_arch.to_csv(\n",
    "    OUTDIR / f\"[STEP:{STEP}]representative_architectures.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "logging.info(f\"Selected {len(rep_arch)} representative architectures\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Step 7: Recover genomes encoding the longest representative architectures\n",
    "# ------------------------------------------------------------------\n",
    "logging.info(\n",
    "    \"Recovering genomes encoding longest architectures with maximal subtuple support\"\n",
    ")\n",
    "\n",
    "# Only maximal (longest) architectures per lineage\n",
    "longest_arch_contigs = collapsed_arch_df[[\n",
    "    LINEAGE_LEVEL,\n",
    "    \"genome_id_x\",\n",
    "    \"contig\",\n",
    "    \"center_protein\",\n",
    "    \"arch_token_canonical\",\n",
    "    \"arch_token_trimmed\"\n",
    "]].copy()\n",
    "\n",
    "# Merge architecture counts → longest architecture contigs\n",
    "rep_keys = rep_arch.merge(\n",
    "    longest_arch_contigs,\n",
    "    left_on=[LINEAGE_LEVEL, \"rep_arch_canonical\"],\n",
    "    right_on=[LINEAGE_LEVEL, \"arch_token_canonical\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Defensive check: every representative should map to ≥1 genome\n",
    "if rep_keys[\"genome_id_x\"].isna().any():\n",
    "    raise RuntimeError(\n",
    "        \"Some representative architectures could not be mapped to a genome\"\n",
    "    )\n",
    "\n",
    "STEP += 1\n",
    "rep_keys.to_csv(\n",
    "    OUTDIR / f\"[STEP:{STEP}]representative_architectures_with_genomes.csv\",\n",
    "    index=False\n",
    ")\n",
    "# # ------------------------------------------------------------------\n",
    "# # Step 8: Recover gene-level rows for plotting (representative architectures only)\n",
    "# # ------------------------------------------------------------------\n",
    "# logging.info(\"Extracting gene-level rows for plotting (representative architectures)\")\n",
    "\n",
    "# logging.info(\"Columns in input df: %s\", str(\", \".join(df.columns.tolist())))\n",
    "\n",
    "# plot_df = df.merge(\n",
    "#     rep_keys[\n",
    "#         [\n",
    "#             LINEAGE_LEVEL,\n",
    "#             \"genome_id_x\",\n",
    "#             \"contig\",\n",
    "#             \"center_protein\",\n",
    "#             \"rep_arch_canonical\"\n",
    "#         ]\n",
    "#     ],\n",
    "#     on=[LINEAGE_LEVEL, \"genome_id_x\"],\n",
    "#     how=\"inner\"\n",
    "# )\n",
    "# logging.info(\n",
    "#     \"Columns in plot df: %s\",\n",
    "#     \", \".join(plot_df.columns.tolist())\n",
    "# )\n",
    "\n",
    "# plot_df = plot_df.sort_values(\n",
    "#     [LINEAGE_LEVEL, \"genome_id_x\", \"contig_x\", \"relative_pos\"]\n",
    "# )\n",
    "\n",
    "# STEP += 1\n",
    "# plot_df.to_csv(\n",
    "#     OUTDIR / f\"[STEP:{STEP}]plot_ready_architectures.csv\",\n",
    "#     index=False\n",
    "# )\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Step 8: Recover gene-level rows for plotting\n",
    "#   - include ALL contigs from representative genomes\n",
    "#   - ensure at least one contig encodes the representative architecture\n",
    "# ------------------------------------------------------------------\n",
    "logging.info(\n",
    "    \"Extracting gene-level rows for plotting (all contigs from representative genomes)\"\n",
    ")\n",
    "\n",
    "# 1. Identify representative genomes per lineage\n",
    "print(\"rep_keys columns: \", rep_keys.columns)\n",
    "\n",
    "\n",
    "rep_genomes = (\n",
    "    rep_keys[\n",
    "        [\n",
    "            LINEAGE_LEVEL,\n",
    "            \"genome_id_x\",\n",
    "            \"rep_arch_canonical\",\n",
    "            \"contig\"\n",
    "        ]\n",
    "    ]\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "\n",
    "STEP += 1\n",
    "rep_genomes.to_csv(\n",
    "    OUTDIR / f\"[STEP:{STEP}]representative_genomes.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "logging.info(\n",
    "    \"Representative genomes identified: %d\",\n",
    "    len(rep_genomes)\n",
    ")\n",
    "\n",
    "# 2. Pull ALL gene-level rows from those genomes\n",
    "plot_df = df.merge(\n",
    "    rep_genomes,\n",
    "    on=[LINEAGE_LEVEL, \"genome_id_x\", \"contig\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "logging.info(\n",
    "    \"Plot df shape after genome-level filtering: %s\",\n",
    "    plot_df.shape\n",
    ")\n",
    "\n",
    "# 3. Sort for clean plotting\n",
    "plot_df = plot_df.sort_values(\n",
    "    [LINEAGE_LEVEL, \"genome_id_x\", \"contig\", \"gene_index\"]\n",
    ")\n",
    "\n",
    "STEP += 1\n",
    "plot_df.to_csv(\n",
    "    OUTDIR / f\"[STEP:{STEP}]plot_ready_architectures.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "\n",
    "# Summary\n",
    "# ------------------------------------------------------------------\n",
    "logging.info(\"Architecture analysis complete\")\n",
    "logging.info(f\"Results written to: {OUTDIR.resolve()}\")\n",
    "\n",
    "logging.info(\"Files generated:\")\n",
    "for f in sorted(OUTDIR.iterdir()):\n",
    "    logging.info(f\"  - {f.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2191e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python3\n",
    "\n",
    "# # without count for subtuples\n",
    "# \"\"\"\n",
    "# Architecture analysis and reduction script (orientation-invariant)\n",
    "# =================================================================\n",
    "\n",
    "# Input:\n",
    "#   - Annotated neighborhood CSV with taxonomy and architecture labels\n",
    "\n",
    "# Output:\n",
    "#   - Contig-level trimmed & canonical architectures\n",
    "#   - Lineage-level architecture counts (inverse-collapsed)\n",
    "#   - Representative contigs per lineage\n",
    "#   - Gene-level dataframe for plotting\n",
    "\n",
    "# Key features:\n",
    "#   - Flank trimming (k=2)\n",
    "#   - Orientation-invariant (inverse) collapsing\n",
    "#   - Counts incorporate reversed architectures\n",
    "#   - Subtuple matching for architecture equivalence\n",
    "# \"\"\"\n",
    "\n",
    "# import pandas as pd\n",
    "# import logging\n",
    "# from pathlib import Path\n",
    "# from datetime import datetime\n",
    "\n",
    "# INPUT_CSV = out_csv # Output from previous step with taxonomy [should be [step:8]escrt_neighborhoods_with_taxonomy_{rightnow}.csv]\n",
    "# OUTDIR = Path(os.path.join(MAIN_OUTDIR, f\"architecture_results_{rightnow}\"))\n",
    "\n",
    "\n",
    "# OUTDIR.mkdir(exist_ok=True)\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Helper functions\n",
    "# # ------------------------------------------------------------------------------\n",
    "# def trim_architecture(tokens, k=2):\n",
    "#     \"\"\"\n",
    "#     Trim architecture by keeping at most k 'other' tokens\n",
    "#     at each flank while retaining internal structure.\n",
    "#     \"\"\"\n",
    "#     tokens = list(tokens)\n",
    "\n",
    "#     # Trim left\n",
    "#     left = 0\n",
    "#     while left < len(tokens) and tokens[left] == \"other\":\n",
    "#         left += 1\n",
    "#     left = max(0, left - k)\n",
    "\n",
    "#     # Trim right\n",
    "#     right = len(tokens)\n",
    "#     while right > 0 and tokens[right - 1] == \"other\":\n",
    "#         right -= 1\n",
    "#     right = min(len(tokens), right + k)\n",
    "\n",
    "#     return tuple(tokens[left:right])\n",
    "\n",
    "\n",
    "# def canonicalize_architecture(tokens):\n",
    "#     \"\"\"\n",
    "#     Make architecture orientation-invariant by collapsing\n",
    "#     forward and reverse into a single canonical form.\n",
    "#     \"\"\"\n",
    "#     tokens = tuple(tokens)\n",
    "#     rev = tokens[::-1]\n",
    "#     return min(tokens, rev)\n",
    "\n",
    "\n",
    "# def is_subtuple(short, long):\n",
    "#     \"\"\"\n",
    "#     Check if tuple `short` is a contiguous subtuple of `long`\n",
    "#     \"\"\"\n",
    "#     n, m = len(short), len(long)\n",
    "#     if n > m:\n",
    "#         return False\n",
    "#     for i in range(m - n + 1):\n",
    "#         if long[i:i+n] == short:\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "\n",
    "# def architecture_equivalent(a, b):\n",
    "#     \"\"\"\n",
    "#     True if architectures a and b are equivalent under:\n",
    "#       - inversion\n",
    "#       - truncation (subtuple)\n",
    "#       - inversion + truncation\n",
    "#     \"\"\"\n",
    "#     a = tuple(a)\n",
    "#     b = tuple(b)\n",
    "\n",
    "#     a_rev = a[::-1]\n",
    "#     b_rev = b[::-1]\n",
    "\n",
    "#     return (\n",
    "#         is_subtuple(a, b) or\n",
    "#         is_subtuple(a, b_rev) or\n",
    "#         is_subtuple(a_rev, b) or\n",
    "#         is_subtuple(a_rev, b_rev)\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Step 1: Load data\n",
    "# # ------------------------------------------------------------------------------\n",
    "# logging.info(\"Loading annotated neighborhood table\")\n",
    "# df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "\n",
    "# df['neighbor_architecture'] = df['neighbor_architecture'].str.strip()\n",
    "# required_cols = {\n",
    "#     \"genome_id_x\", \"contig\", \"center_protein\",\n",
    "#     \"relative_pos\", \"neighbor_architecture\",\n",
    "#     LINEAGE_LEVEL\n",
    "# }\n",
    "\n",
    "# missing = required_cols - set(df.columns)\n",
    "# if missing:\n",
    "#     raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# logging.info(f\"Loaded {len(df)} gene-level rows\")\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Step 2: Encode architecture tokens\n",
    "# # ------------------------------------------------------------------------------\n",
    "# logging.info(\"Encoding architecture tokens\")\n",
    "\n",
    "# df[\"arch_token\"] = (\n",
    "#     df[\"neighbor_architecture\"]\n",
    "#     .fillna(\"other\")\n",
    "# )\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Step 3: Build contig-level architectures\n",
    "# # ------------------------------------------------------------------------------\n",
    "# logging.info(\"Constructing contig-level architectures\")\n",
    "\n",
    "# arch_df = (\n",
    "#     df\n",
    "#     .sort_values(\"relative_pos\")\n",
    "#     .groupby(\n",
    "#         [\"genome_id_x\", \"contig\", \"center_protein\", LINEAGE_LEVEL],\n",
    "#         as_index=False\n",
    "#     )\n",
    "#     .agg(\n",
    "#         arch_token=(\"arch_token\", lambda x: tuple(x)),\n",
    "#         n_genes=(\"arch_token\", \"count\")\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# logging.info(f\"Identified {len(arch_df)} contig-level architectures\")\n",
    "\n",
    "# STEP += 1\n",
    "# arch_df.to_csv(OUTDIR / f\"[STEP:{STEP}]contig_architectures_raw.csv\", index=False)\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Step 4: Trim flanks + inverse collapse (CORE STEP)\n",
    "# # ------------------------------------------------------------------------------\n",
    "# logging.info(\n",
    "#     f\"Trimming architectures (k={FLANK_K}) and collapsing inverses\"\n",
    "# )\n",
    "\n",
    "# arch_df[\"arch_token_trimmed\"] = arch_df[\"arch_token\"].apply(\n",
    "#     lambda x: trim_architecture(x, k=FLANK_K)\n",
    "# )\n",
    "\n",
    "# arch_df[\"arch_token_canonical\"] = arch_df[\"arch_token_trimmed\"].apply(\n",
    "#     canonicalize_architecture\n",
    "# )\n",
    "\n",
    "# arch_df[\"trimmed_len\"] = arch_df[\"arch_token_trimmed\"].apply(len)\n",
    "\n",
    "\n",
    "# STEP += 1\n",
    "# arch_df.to_csv(\n",
    "#     OUTDIR / f\"[STEP:{STEP}]contig_architectures_trimmed_canonical.csv\",\n",
    "#     index=False\n",
    "# )\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Step 5: Count architectures by lineage (INVERSE-AWARE)\n",
    "# # ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# logging.info(\"Collapsing architectures using inversion + subtuple equivalence\")\n",
    "\n",
    "# collapsed_rows = []\n",
    "\n",
    "# for lineage, subdf in arch_df.groupby(LINEAGE_LEVEL):\n",
    "#     subdf = subdf.copy()\n",
    "#     subdf[\"arch_len\"] = subdf[\"arch_token_trimmed\"].apply(len)\n",
    "\n",
    "#     # longest-first ensures maximal architecture survives\n",
    "#     subdf = subdf.sort_values(\"arch_len\", ascending=False)\n",
    "\n",
    "#     kept_archs = []\n",
    "\n",
    "#     for _, row in subdf.iterrows():\n",
    "#         arch = row[\"arch_token_trimmed\"]\n",
    "\n",
    "#         if any(architecture_equivalent(arch, kept) for kept in kept_archs):\n",
    "#             continue\n",
    "\n",
    "#         kept_archs.append(arch)\n",
    "#         collapsed_rows.append(row)\n",
    "\n",
    "# collapsed_arch_df = pd.DataFrame(collapsed_rows).drop(columns=\"arch_len\")\n",
    "\n",
    "# STEP += 1\n",
    "\n",
    "# collapsed_arch_df.to_csv(\n",
    "#     OUTDIR / f\"[STEP:{STEP}]collapsed_arch_df.csv\",\n",
    "#     index=False\n",
    "# )\n",
    "\n",
    "\n",
    "# logging.info(\n",
    "#     f\"Counting architectures per {LINEAGE_LEVEL} (inverse-aware)\"\n",
    "# )\n",
    "\n",
    "# arch_counts = (\n",
    "#     collapsed_arch_df\n",
    "#     .groupby([LINEAGE_LEVEL, \"arch_token_canonical\"], as_index=False)\n",
    "#     .size()\n",
    "#     .rename(columns={\"size\": \"count\"})\n",
    "#     .sort_values([LINEAGE_LEVEL, \"count\"], ascending=[True, False])\n",
    "# )\n",
    "\n",
    "# STEP += 1\n",
    "\n",
    "# arch_counts.to_csv(\n",
    "#     OUTDIR / f\"[STEP:{STEP}]architecture_frequencies_inverse_collapsed.csv\",\n",
    "#     index=False\n",
    "# )\n",
    "\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # # Step 6: Select representative architecture per lineage\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # logging.info(\"Selecting representative architecture per lineage\")\n",
    "\n",
    "# # rep_arch = (\n",
    "# #     arch_counts\n",
    "# #     .groupby(LINEAGE_LEVEL, as_index=False)\n",
    "# #     .head(1)\n",
    "# # )\n",
    "\n",
    "# # STEP += 1\n",
    "# # rep_arch.to_csv(\n",
    "# #     OUTDIR / f\"[STEP:{STEP}]representative_architectures.csv\",\n",
    "# #     index=False\n",
    "# # )\n",
    "\n",
    "# # logging.info(f\"Selected {len(rep_arch)} representative architectures\")\n",
    "\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # # Step 7: Recover representative contigs\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # logging.info(\"Recovering representative contigs\")\n",
    "\n",
    "# # rep_keys = rep_arch.merge(\n",
    "# #     arch_df,\n",
    "# #     on=[LINEAGE_LEVEL, \"arch_token_canonical\"],\n",
    "# #     how=\"left\"\n",
    "# # )\n",
    "\n",
    "\n",
    "# # STEP += 1\n",
    "# # rep_keys.to_csv(\n",
    "# #     OUTDIR / f\"[STEP:{STEP}]representative_contigs.csv\",\n",
    "# #     index=False\n",
    "# # )\n",
    "\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # # Step 8: Recover gene-level rows for plotting\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # logging.info(\"Extracting gene-level rows for plotting\")\n",
    "\n",
    "# # plot_df = df.merge(\n",
    "# #     rep_keys[[\"genome_id_x\", \"contig\", \"center_protein\"]],\n",
    "# #     on=[\"genome_id_x\", \"contig\", \"center_protein\"],\n",
    "# #     how=\"inner\"\n",
    "# # )\n",
    "\n",
    "# # plot_df = plot_df.sort_values(\n",
    "# #     [LINEAGE_LEVEL, \"genome_id_x\", \"contig\", \"relative_pos\"]\n",
    "# # )\n",
    "\n",
    "# # STEP += 1\n",
    "\n",
    "# # plot_df.to_csv(\n",
    "# #     OUTDIR / f\"[STEP:{STEP}]plot_ready_architectures.csv\",\n",
    "# #     index=False\n",
    "# # )\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Summary\n",
    "# # ------------------------------------------------------------------------------\n",
    "# logging.info(\"Architecture analysis complete\")\n",
    "# logging.info(f\"Results written to: {OUTDIR.resolve()}\")\n",
    "\n",
    "# logging.info(\"Files generated:\")\n",
    "# for f in sorted(OUTDIR.iterdir()):\n",
    "#     logging.info(f\"  - {f.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4276bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Without Subtuple matching \n",
    "\n",
    "\n",
    "# \"\"#!/usr/bin/env python3\n",
    "# \"\"\"\n",
    "# Architecture analysis and reduction script (orientation-invariant)\n",
    "# =================================================================\n",
    "\n",
    "# Input:\n",
    "#   - Annotated neighborhood CSV with taxonomy and architecture labels\n",
    "\n",
    "# Output:\n",
    "#   - Contig-level trimmed & canonical architectures\n",
    "#   - Lineage-level architecture counts (inverse-collapsed)\n",
    "#   - Representative contigs per lineage\n",
    "#   - Gene-level dataframe for plotting\n",
    "\n",
    "# Key features:\n",
    "#   - Flank trimming (k=2)\n",
    "#   - Orientation-invariant (inverse) collapsing\n",
    "#   - Counts incorporate reversed architectures\n",
    "# \"\"\"\n",
    "\n",
    "# import pandas as pd\n",
    "# import logging\n",
    "# from pathlib import Path\n",
    "# from datetime import datetime\n",
    "\n",
    "# INPUT_CSV = out_csv # Output from previous step with taxonomy [should be [step:8]escrt_neighborhoods_with_taxonomy_{rightnow}.csv]\n",
    "# OUTDIR = Path(os.path.join(MAIN_OUTDIR, f\"architecture_results_{rightnow}\"))\n",
    "\n",
    "\n",
    "# OUTDIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# STEP += 100\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Helper functions\n",
    "# # ------------------------------------------------------------------------------\n",
    "# def trim_architecture(tokens, k=2):\n",
    "#     \"\"\"\n",
    "#     Trim architecture by keeping at most k 'other' tokens\n",
    "#     at each flank while retaining internal structure.\n",
    "#     \"\"\"\n",
    "#     tokens = list(tokens)\n",
    "\n",
    "#     # Trim left\n",
    "#     left = 0\n",
    "#     while left < len(tokens) and tokens[left] == \"other\":\n",
    "#         left += 1\n",
    "#     left = max(0, left - k)\n",
    "\n",
    "#     # Trim right\n",
    "#     right = len(tokens)\n",
    "#     while right > 0 and tokens[right - 1] == \"other\":\n",
    "#         right -= 1\n",
    "#     right = min(len(tokens), right + k)\n",
    "\n",
    "#     return tuple(tokens[left:right])\n",
    "\n",
    "\n",
    "# def canonicalize_architecture(tokens):\n",
    "#     \"\"\"\n",
    "#     Make architecture orientation-invariant by collapsing\n",
    "#     forward and reverse into a single canonical form.\n",
    "#     \"\"\"\n",
    "#     tokens = tuple(tokens)\n",
    "#     rev = tokens[::-1]\n",
    "#     return min(tokens, rev)\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Step 1: Load data\n",
    "# # ------------------------------------------------------------------------------\n",
    "# logging.info(\"Loading annotated neighborhood table\")\n",
    "# df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "\n",
    "# df['neighbor_architecture'] = df['neighbor_architecture'].str.strip()\n",
    "# required_cols = {\n",
    "#     \"genome_id_x\", \"contig\", \"center_protein\",\n",
    "#     \"relative_pos\", \"neighbor_architecture\",\n",
    "#     LINEAGE_LEVEL\n",
    "# }\n",
    "\n",
    "# missing = required_cols - set(df.columns)\n",
    "# if missing:\n",
    "#     raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# logging.info(f\"Loaded {len(df)} gene-level rows\")\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Step 2: Encode architecture tokens\n",
    "# # ------------------------------------------------------------------------------\n",
    "# logging.info(\"Encoding architecture tokens\")\n",
    "\n",
    "# df[\"arch_token\"] = (\n",
    "#     df[\"neighbor_architecture\"]\n",
    "#     .fillna(\"other\")\n",
    "# )\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Step 3: Build contig-level architectures\n",
    "# # ------------------------------------------------------------------------------\n",
    "# logging.info(\"Constructing contig-level architectures\")\n",
    "\n",
    "# arch_df = (\n",
    "#     df\n",
    "#     .sort_values(\"relative_pos\")\n",
    "#     .groupby(\n",
    "#         [\"genome_id_x\", \"contig\", \"center_protein\", LINEAGE_LEVEL],\n",
    "#         as_index=False\n",
    "#     )\n",
    "#     .agg(\n",
    "#         arch_token=(\"arch_token\", lambda x: tuple(x)),\n",
    "#         n_genes=(\"arch_token\", \"count\")\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# logging.info(f\"Identified {len(arch_df)} contig-level architectures\")\n",
    "\n",
    "# STEP += 1\n",
    "# arch_df.to_csv(OUTDIR / f\"[STEP:{STEP}]contig_architectures_raw.csv\", index=False)\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Step 4: Trim flanks + inverse collapse (CORE STEP)\n",
    "# # ------------------------------------------------------------------------------\n",
    "# logging.info(\n",
    "#     f\"Trimming architectures (k={FLANK_K}) and collapsing inverses\"\n",
    "# )\n",
    "\n",
    "# arch_df[\"arch_token_trimmed\"] = arch_df[\"arch_token\"].apply(\n",
    "#     lambda x: trim_architecture(x, k=FLANK_K)\n",
    "# )\n",
    "\n",
    "# arch_df[\"arch_token_canonical\"] = arch_df[\"arch_token_trimmed\"].apply(\n",
    "#     canonicalize_architecture\n",
    "# )\n",
    "\n",
    "# arch_df[\"trimmed_len\"] = arch_df[\"arch_token_trimmed\"].apply(len)\n",
    "\n",
    "\n",
    "# STEP += 1\n",
    "# arch_df.to_csv(\n",
    "#     OUTDIR / f\"[STEP:{STEP}]contig_architectures_trimmed_canonical.csv\",\n",
    "#     index=False\n",
    "# )\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Step 5: Count architectures by lineage (INVERSE-AWARE)\n",
    "# # ------------------------------------------------------------------------------\n",
    "# logging.info(\n",
    "#     f\"Counting architectures per {LINEAGE_LEVEL} (inverse-aware)\"\n",
    "# )\n",
    "\n",
    "# arch_counts = (\n",
    "#     arch_df\n",
    "#     .groupby([LINEAGE_LEVEL, \"arch_token_canonical\"], as_index=False)\n",
    "#     .size()\n",
    "#     .rename(columns={\"size\": \"count\"})\n",
    "#     .sort_values([LINEAGE_LEVEL, \"count\"], ascending=[True, False])\n",
    "# )\n",
    "\n",
    "# STEP += 1\n",
    "\n",
    "# arch_counts.to_csv(\n",
    "#     OUTDIR / f\"[STEP:{STEP}]architecture_frequencies_inverse_collapsed.csv\",\n",
    "#     index=False\n",
    "# )\n",
    "\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # # Step 6: Select representative architecture per lineage\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # logging.info(\"Selecting representative architecture per lineage\")\n",
    "\n",
    "# # rep_arch = (\n",
    "# #     arch_counts\n",
    "# #     .groupby(LINEAGE_LEVEL, as_index=False)\n",
    "# #     .head(1)\n",
    "# # )\n",
    "\n",
    "# # STEP += 1\n",
    "# # rep_arch.to_csv(\n",
    "# #     OUTDIR / f\"[STEP:{STEP}]representative_architectures.csv\",\n",
    "# #     index=False\n",
    "# # )\n",
    "\n",
    "# # logging.info(f\"Selected {len(rep_arch)} representative architectures\")\n",
    "\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # # Step 7: Recover representative contigs\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # logging.info(\"Recovering representative contigs\")\n",
    "\n",
    "# # rep_keys = rep_arch.merge(\n",
    "# #     arch_df,\n",
    "# #     on=[LINEAGE_LEVEL, \"arch_token_canonical\"],\n",
    "# #     how=\"left\"\n",
    "# # )\n",
    "\n",
    "\n",
    "# # STEP += 1\n",
    "# # rep_keys.to_csv(\n",
    "# #     OUTDIR / f\"[STEP:{STEP}]representative_contigs.csv\",\n",
    "# #     index=False\n",
    "# # )\n",
    "\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # # Step 8: Recover gene-level rows for plotting\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # logging.info(\"Extracting gene-level rows for plotting\")\n",
    "\n",
    "# # plot_df = df.merge(\n",
    "# #     rep_keys[[\"genome_id_x\", \"contig\", \"center_protein\"]],\n",
    "# #     on=[\"genome_id_x\", \"contig\", \"center_protein\"],\n",
    "# #     how=\"inner\"\n",
    "# # )\n",
    "\n",
    "# # plot_df = plot_df.sort_values(\n",
    "# #     [LINEAGE_LEVEL, \"genome_id_x\", \"contig\", \"relative_pos\"]\n",
    "# # )\n",
    "\n",
    "# # STEP += 1\n",
    "\n",
    "# # plot_df.to_csv(\n",
    "# #     OUTDIR / f\"[STEP:{STEP}]plot_ready_architectures.csv\",\n",
    "# #     index=False\n",
    "# # )\n",
    "\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # # Summary\n",
    "# # # ------------------------------------------------------------------------------\n",
    "# # logging.info(\"Architecture analysis complete\")\n",
    "# # logging.info(f\"Results written to: {OUTDIR.resolve()}\")\n",
    "\n",
    "# # logging.info(\"Files generated:\")\n",
    "# # for f in sorted(OUTDIR.iterdir()):\n",
    "# #     logging.info(f\"  - {f.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d477882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:08:43,273 [INFO] ================================================================================\n",
      "2026-01-21 11:08:43,274 [INFO] NOTEBOOK JSON SNAPSHOT (END OF RUN)\n",
      "2026-01-21 11:08:43,274 [INFO] ================================================================================\n",
      "2026-01-21 11:08:43,275 [INFO] {\n",
      "2026-01-21 11:08:43,275 [INFO]   \"cells\": [\n",
      "2026-01-21 11:08:43,276 [INFO]     {\n",
      "2026-01-21 11:08:43,276 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:43,276 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:43,277 [INFO]       \"id\": \"99fd6d19\",\n",
      "2026-01-21 11:08:43,277 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:43,278 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:43,278 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:43,278 [INFO]         \"# Configuration\\n\",\n",
      "2026-01-21 11:08:43,279 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,279 [INFO]         \"import logging\\n\",\n",
      "2026-01-21 11:08:43,280 [INFO]         \"import sys\\n\",\n",
      "2026-01-21 11:08:43,280 [INFO]         \"import os\\n\",\n",
      "2026-01-21 11:08:43,280 [INFO]         \"import pandas as pd\\n\",\n",
      "2026-01-21 11:08:43,281 [INFO]         \"from datetime import datetime\\n\",\n",
      "2026-01-21 11:08:43,281 [INFO]         \"from pathlib import Path\\n\",\n",
      "2026-01-21 11:08:43,282 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,282 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,282 [INFO]         \"rightnow = datetime.now().strftime(\\\"%Y-%m-%d-%H-%M-%S\\\")\\n\",\n",
      "2026-01-21 11:08:43,283 [INFO]         \"LINEAGE_LEVEL = \\\"family\\\"\\n\",\n",
      "2026-01-21 11:08:43,283 [INFO]         \"HMM_FILE = \\\"ascogs_escrt_system_20260116_121403.tsv\\\"\\n\",\n",
      "2026-01-21 11:08:43,284 [INFO]         \"FLANK_K = 0               # number of 'other' tokens allowed at each flank\\n\",\n",
      "2026-01-21 11:08:43,284 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,284 [INFO]         \"NOTEBOOK_PATH = Path.cwd() / \\\"ESCRT_system_synteny.ipynb\\\"\\n\",\n",
      "2026-01-21 11:08:43,285 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,285 [INFO]         \"WINDOW = 5\\n\",\n",
      "2026-01-21 11:08:43,286 [INFO]         \"CORE_TARGETS = (\\\"vps\\\", \\\"escrt\\\", \\\"katanin\\\", \\\"eap\\\", \\\"flad\\\")\\n\",\n",
      "2026-01-21 11:08:43,286 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,287 [INFO]         \"MAIN_OUTDIR = os.path.join(os.getcwd(), f\\\"ESCRT_synteny_pipeline_output_{LINEAGE_LEVEL}_{rightnow}\\\")\\n\",\n",
      "2026-01-21 11:08:43,288 [INFO]         \"os.makedirs(MAIN_OUTDIR, exist_ok=True)\\n\",\n",
      "2026-01-21 11:08:43,288 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,288 [INFO]         \"def setup_logging(log_file=None):\\n\",\n",
      "2026-01-21 11:08:43,289 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,290 [INFO]         \"    Configure logging for the pipeline.\\n\",\n",
      "2026-01-21 11:08:43,291 [INFO]         \"    Logs to stdout and optionally to a file.\\n\",\n",
      "2026-01-21 11:08:43,291 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,292 [INFO]         \"    handlers = [logging.StreamHandler(sys.stdout)]\\n\",\n",
      "2026-01-21 11:08:43,292 [INFO]         \"    if log_file:\\n\",\n",
      "2026-01-21 11:08:43,292 [INFO]         \"        handlers.append(logging.FileHandler(log_file))\\n\",\n",
      "2026-01-21 11:08:43,293 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,293 [INFO]         \"    logging.basicConfig(\\n\",\n",
      "2026-01-21 11:08:43,294 [INFO]         \"        level=logging.INFO,\\n\",\n",
      "2026-01-21 11:08:43,294 [INFO]         \"        format=\\\"%(asctime)s [%(levelname)s] %(message)s\\\",\\n\",\n",
      "2026-01-21 11:08:43,294 [INFO]         \"        handlers=handlers,\\n\",\n",
      "2026-01-21 11:08:43,295 [INFO]         \"        force=True  # Force reconfiguration if already set\\n\",\n",
      "2026-01-21 11:08:43,295 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,296 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,296 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,297 [INFO]         \"STEP = 0\\n\",\n",
      "2026-01-21 11:08:43,297 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,297 [INFO]         \"setup_logging(os.path.join(MAIN_OUTDIR, f\\\"ESCRT_synteny_pipeline{rightnow}.log\\\"))\\n\"\n",
      "2026-01-21 11:08:43,298 [INFO]       ]\n",
      "2026-01-21 11:08:43,298 [INFO]     },\n",
      "2026-01-21 11:08:43,298 [INFO]     {\n",
      "2026-01-21 11:08:43,299 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:43,299 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:43,300 [INFO]       \"id\": \"25546ebc\",\n",
      "2026-01-21 11:08:43,300 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:43,301 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:43,301 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:43,301 [INFO]         \"# Merge HMM hits with protein metadata\\n\",\n",
      "2026-01-21 11:08:43,302 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,302 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,302 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,303 [INFO]         \"# Input files\\n\",\n",
      "2026-01-21 11:08:43,303 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,304 [INFO]         \"hits_file = \\\"/home/anirudh/synteny/hmms/ESCRT_results/hits/ESCRT_hits_final.csv\\\"\\n\",\n",
      "2026-01-21 11:08:43,304 [INFO]         \"proteins_file = \\\"/home/anirudh/synteny/proteins_genomes_cp90_con5.csv\\\"\\n\",\n",
      "2026-01-21 11:08:43,305 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,305 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,305 [INFO]         \"# Output file naming\\n\",\n",
      "2026-01-21 11:08:43,306 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,306 [INFO]         \"hits_file_name = os.path.basename(hits_file).split(\\\".\\\")[0]\\n\",\n",
      "2026-01-21 11:08:43,307 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:43,307 [INFO]         \"merge_file_name = os.path.join(MAIN_OUTDIR, f\\\"[STEP:{STEP}]{hits_file_name}_merged_{rightnow}.csv\\\")\\n\",\n",
      "2026-01-21 11:08:43,308 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,308 [INFO]         \"logging.info(\\\"HMM hits file: %s\\\", hits_file)\\n\",\n",
      "2026-01-21 11:08:43,309 [INFO]         \"logging.info(\\\"Protein metadata file: %s\\\", proteins_file)\\n\",\n",
      "2026-01-21 11:08:43,309 [INFO]         \"logging.info(\\\"Merged output file: %s\\\", merge_file_name)\\n\",\n",
      "2026-01-21 11:08:43,310 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,310 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,310 [INFO]         \"# Load HMM hits\\n\",\n",
      "2026-01-21 11:08:43,311 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,311 [INFO]         \"try:\\n\",\n",
      "2026-01-21 11:08:43,311 [INFO]         \"    hits = pd.read_csv(hits_file)\\n\",\n",
      "2026-01-21 11:08:43,312 [INFO]         \"except Exception as e:\\n\",\n",
      "2026-01-21 11:08:43,312 [INFO]         \"    logging.error(\\\"Failed to load HMM hits file: %s\\\", e)\\n\",\n",
      "2026-01-21 11:08:43,313 [INFO]         \"    raise\\n\",\n",
      "2026-01-21 11:08:43,313 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,313 [INFO]         \"hits.columns = hits.columns.str.strip()\\n\",\n",
      "2026-01-21 11:08:43,314 [INFO]         \"logging.info(\\\"HMM hits columns: %s\\\", list(hits.columns))\\n\",\n",
      "2026-01-21 11:08:43,314 [INFO]         \"logging.info(\\\"HMM hits rows: %d\\\", len(hits))\\n\",\n",
      "2026-01-21 11:08:43,314 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,315 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,316 [INFO]         \"# Load protein metadata\\n\",\n",
      "2026-01-21 11:08:43,316 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,317 [INFO]         \"try:\\n\",\n",
      "2026-01-21 11:08:43,317 [INFO]         \"    proteins = pd.read_csv(proteins_file)\\n\",\n",
      "2026-01-21 11:08:43,317 [INFO]         \"except Exception as e:\\n\",\n",
      "2026-01-21 11:08:43,318 [INFO]         \"    logging.error(\\\"Failed to load protein metadata file: %s\\\", e)\\n\",\n",
      "2026-01-21 11:08:43,318 [INFO]         \"    raise\\n\",\n",
      "2026-01-21 11:08:43,318 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,319 [INFO]         \"proteins.columns = proteins.columns.str.strip()\\n\",\n",
      "2026-01-21 11:08:43,319 [INFO]         \"logging.info(\\\"Protein metadata columns: %s\\\", list(proteins.columns))\\n\",\n",
      "2026-01-21 11:08:43,320 [INFO]         \"logging.info(\\\"Protein metadata rows: %d\\\", len(proteins))\\n\",\n",
      "2026-01-21 11:08:43,320 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,320 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,321 [INFO]         \"# Sanity checks before merge\\n\",\n",
      "2026-01-21 11:08:43,321 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,322 [INFO]         \"required_hits_cols = {\\\"target\\\"}\\n\",\n",
      "2026-01-21 11:08:43,322 [INFO]         \"required_prot_cols = {\\\"cds_id\\\"}\\n\",\n",
      "2026-01-21 11:08:43,323 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,323 [INFO]         \"missing_hits = required_hits_cols - set(hits.columns)\\n\",\n",
      "2026-01-21 11:08:43,323 [INFO]         \"missing_prots = required_prot_cols - set(proteins.columns)\\n\",\n",
      "2026-01-21 11:08:43,324 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,324 [INFO]         \"if missing_hits:\\n\",\n",
      "2026-01-21 11:08:43,325 [INFO]         \"    logging.error(\\\"Missing required columns in HMM hits file: %s\\\", missing_hits)\\n\",\n",
      "2026-01-21 11:08:43,325 [INFO]         \"    raise ValueError(f\\\"Missing columns in hits file: {missing_hits}\\\")\\n\",\n",
      "2026-01-21 11:08:43,325 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,326 [INFO]         \"if missing_prots:\\n\",\n",
      "2026-01-21 11:08:43,326 [INFO]         \"    logging.error(\\\"Missing required columns in protein metadata file: %s\\\", missing_prots)\\n\",\n",
      "2026-01-21 11:08:43,326 [INFO]         \"    raise ValueError(f\\\"Missing columns in proteins file: {missing_prots}\\\")\\n\",\n",
      "2026-01-21 11:08:43,327 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,327 [INFO]         \"logging.info(\\\"Input sanity checks passed\\\")\\n\",\n",
      "2026-01-21 11:08:43,327 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,328 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,328 [INFO]         \"# Merge HMM hits with protein metadata\\n\",\n",
      "2026-01-21 11:08:43,328 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,329 [INFO]         \"logging.info(\\\"Merging HMM hits with protein metadata\\\")\\n\",\n",
      "2026-01-21 11:08:43,330 [INFO]         \"logging.info(\\\"Rows before merge: hits=%d, proteins=%d\\\", len(hits), len(proteins))\\n\",\n",
      "2026-01-21 11:08:43,330 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,331 [INFO]         \"merged = pd.merge(\\n\",\n",
      "2026-01-21 11:08:43,331 [INFO]         \"    hits,\\n\",\n",
      "2026-01-21 11:08:43,332 [INFO]         \"    proteins,\\n\",\n",
      "2026-01-21 11:08:43,332 [INFO]         \"    left_on=\\\"target\\\",\\n\",\n",
      "2026-01-21 11:08:43,332 [INFO]         \"    right_on=\\\"cds_id\\\",\\n\",\n",
      "2026-01-21 11:08:43,333 [INFO]         \"    how=\\\"inner\\\"\\n\",\n",
      "2026-01-21 11:08:43,333 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:43,334 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,334 [INFO]         \"logging.info(\\\"Rows after merge: %d\\\", len(merged))\\n\",\n",
      "2026-01-21 11:08:43,334 [INFO]         \"logging.info(\\\"Unique targets merged: %d\\\", merged[\\\"target\\\"].nunique())\\n\",\n",
      "2026-01-21 11:08:43,335 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,335 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,336 [INFO]         \"# Write output\\n\",\n",
      "2026-01-21 11:08:43,336 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,336 [INFO]         \"try:\\n\",\n",
      "2026-01-21 11:08:43,337 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,337 [INFO]         \"    merged.to_csv(merge_file_name, index=False)\\n\",\n",
      "2026-01-21 11:08:43,338 [INFO]         \"except Exception as e:\\n\",\n",
      "2026-01-21 11:08:43,338 [INFO]         \"    logging.error(\\\"Failed to write merged output file %s: %s\\\", merge_file_name, e)\\n\",\n",
      "2026-01-21 11:08:43,338 [INFO]         \"    raise\\n\",\n",
      "2026-01-21 11:08:43,339 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,339 [INFO]         \"logging.info(\\\"Merged output written to: %s\\\", merge_file_name)\\n\"\n",
      "2026-01-21 11:08:43,340 [INFO]       ]\n",
      "2026-01-21 11:08:43,340 [INFO]     },\n",
      "2026-01-21 11:08:43,341 [INFO]     {\n",
      "2026-01-21 11:08:43,341 [INFO]       \"cell_type\": \"markdown\",\n",
      "2026-01-21 11:08:43,342 [INFO]       \"id\": \"5357cf73\",\n",
      "2026-01-21 11:08:43,342 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:43,342 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:43,342 [INFO]         \"Merge with the ascogs definition\"\n",
      "2026-01-21 11:08:43,343 [INFO]       ]\n",
      "2026-01-21 11:08:43,343 [INFO]     },\n",
      "2026-01-21 11:08:43,343 [INFO]     {\n",
      "2026-01-21 11:08:43,344 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:43,344 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:43,344 [INFO]       \"id\": \"53f1d3d2\",\n",
      "2026-01-21 11:08:43,345 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:43,346 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:43,346 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:43,347 [INFO]         \"# Merge HMM hits with AsCOG annotations\\n\",\n",
      "2026-01-21 11:08:43,347 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,348 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,348 [INFO]         \"# Load AsCOG annotation table\\n\",\n",
      "2026-01-21 11:08:43,349 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,349 [INFO]         \"ascogs_tsv = f\\\"/home/anirudh/synteny/hmms/Sources/{HMM_FILE}\\\"\\n\",\n",
      "2026-01-21 11:08:43,349 [INFO]         \"logging.info(\\\"Loading AsCOGs from: %s\\\", ascogs_tsv)\\n\",\n",
      "2026-01-21 11:08:43,350 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,351 [INFO]         \"try:\\n\",\n",
      "2026-01-21 11:08:43,351 [INFO]         \"    ascogs = pd.read_csv(ascogs_tsv, sep=\\\"\\\\t\\\")\\n\",\n",
      "2026-01-21 11:08:43,352 [INFO]         \"except Exception as e:\\n\",\n",
      "2026-01-21 11:08:43,352 [INFO]         \"    logging.error(\\\"Failed to load AsCOGs file: %s\\\", e)\\n\",\n",
      "2026-01-21 11:08:43,353 [INFO]         \"    raise\\n\",\n",
      "2026-01-21 11:08:43,353 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,353 [INFO]         \"ascogs.columns = ascogs.columns.str.strip()\\n\",\n",
      "2026-01-21 11:08:43,354 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,354 [INFO]         \"logging.info(\\\"AsCOGs columns: %s\\\", list(ascogs.columns))\\n\",\n",
      "2026-01-21 11:08:43,355 [INFO]         \"logging.info(\\\"AsCOGs rows: %d\\\", len(ascogs))\\n\",\n",
      "2026-01-21 11:08:43,355 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,356 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,356 [INFO]         \"# Sanity checks\\n\",\n",
      "2026-01-21 11:08:43,356 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,357 [INFO]         \"required_cols = {\\\"ascog_id\\\"}\\n\",\n",
      "2026-01-21 11:08:43,357 [INFO]         \"missing = required_cols - set(ascogs.columns)\\n\",\n",
      "2026-01-21 11:08:43,357 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,358 [INFO]         \"if missing:\\n\",\n",
      "2026-01-21 11:08:43,358 [INFO]         \"    logging.error(\\\"Missing required columns in AsCOGs file: %s\\\", missing)\\n\",\n",
      "2026-01-21 11:08:43,358 [INFO]         \"    raise ValueError(f\\\"Missing required columns: {missing}\\\")\\n\",\n",
      "2026-01-21 11:08:43,359 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,359 [INFO]         \"logging.info(\\\"AsCOGs sanity check passed\\\")\\n\",\n",
      "2026-01-21 11:08:43,360 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,361 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,361 [INFO]         \"# Merge HMM hits with AsCOGs\\n\",\n",
      "2026-01-21 11:08:43,361 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,362 [INFO]         \"logging.info(\\\"Merging HMM hits with AsCOG annotations\\\")\\n\",\n",
      "2026-01-21 11:08:43,362 [INFO]         \"logging.info(\\\"HMM hits rows before merge: %d\\\", len(merged))\\n\",\n",
      "2026-01-21 11:08:43,363 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,363 [INFO]         \"merged_ascogs = pd.merge(\\n\",\n",
      "2026-01-21 11:08:43,363 [INFO]         \"    merged,\\n\",\n",
      "2026-01-21 11:08:43,364 [INFO]         \"    ascogs,\\n\",\n",
      "2026-01-21 11:08:43,364 [INFO]         \"    left_on=\\\"query\\\",\\n\",\n",
      "2026-01-21 11:08:43,365 [INFO]         \"    right_on=\\\"ascog_id\\\",\\n\",\n",
      "2026-01-21 11:08:43,365 [INFO]         \"    how=\\\"left\\\"\\n\",\n",
      "2026-01-21 11:08:43,366 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:43,366 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,366 [INFO]         \"logging.info(\\\"Rows after AsCOG merge: %d\\\", len(merged_ascogs))\\n\",\n",
      "2026-01-21 11:08:43,367 [INFO]         \"logging.info(\\\"Unique AsCOGs matched: %d\\\", merged_ascogs[\\\"ascog_id\\\"].nunique())\\n\",\n",
      "2026-01-21 11:08:43,367 [INFO]         \"logging.info(\\\"Unique proteins matched: %d\\\", merged_ascogs[\\\"target\\\"].nunique())\\n\",\n",
      "2026-01-21 11:08:43,367 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,368 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,368 [INFO]         \"# Write output\\n\",\n",
      "2026-01-21 11:08:43,369 [INFO]         \"# ----------------------------\\n\",\n",
      "2026-01-21 11:08:43,369 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:43,369 [INFO]         \"final_output_file = os.path.join(MAIN_OUTDIR, f\\\"[STEP:{STEP}]ESCRT_hits_final_merged_{rightnow}_ascog.csv\\\")\\n\",\n",
      "2026-01-21 11:08:43,370 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,370 [INFO]         \"merged_ascogs = merged_ascogs[[\\\"target\\\", \\\"tacc\\\", \\\"tlen\\\", \\\"query\\\", \\\"qacc\\\", \\\"qlen\\\", \\\"c_evalue\\\", \\\"i_evalue\\\", \\\"dom_score\\\",  \\\"hmm_from\\\", \\\"hmm_to\\\", \\\"ali_from\\\", \\\"ali_to\\\", \\\"env_from\\\", \\\"env_to\\\", \\\"acc\\\", \\\"Name\\\", \\\"Completeness\\\", \\\"Contamination\\\", \\\"Contig_N50\\\", \\\"Total_Contigs\\\", \\\"organism_name\\\", \\\"cds_id\\\", \\\"header\\\", \\\"gene\\\", \\\"description_y\\\"]]\\n\",\n",
      "2026-01-21 11:08:43,371 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,371 [INFO]         \"try:\\n\",\n",
      "2026-01-21 11:08:43,372 [INFO]         \"    merged_ascogs.to_csv(final_output_file, index=False)\\n\",\n",
      "2026-01-21 11:08:43,372 [INFO]         \"except Exception as e:\\n\",\n",
      "2026-01-21 11:08:43,372 [INFO]         \"    logging.error(\\\"Failed to write output file %s: %s\\\", final_output_file, e)\\n\",\n",
      "2026-01-21 11:08:43,373 [INFO]         \"    raise\\n\",\n",
      "2026-01-21 11:08:43,373 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,374 [INFO]         \"logging.info(\\\"Final merged file written to: %s\\\", final_output_file)\\n\"\n",
      "2026-01-21 11:08:43,374 [INFO]       ]\n",
      "2026-01-21 11:08:43,374 [INFO]     },\n",
      "2026-01-21 11:08:43,375 [INFO]     {\n",
      "2026-01-21 11:08:43,375 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:43,376 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:43,376 [INFO]       \"id\": \"626cee5d\",\n",
      "2026-01-21 11:08:43,376 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:43,377 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:43,377 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:43,378 [INFO]         \"# Select best hits based on e-value and coverage\\n\",\n",
      "2026-01-21 11:08:43,378 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,378 [INFO]         \"merged_ascogs[\\\"coverage\\\"] = (\\n\",\n",
      "2026-01-21 11:08:43,379 [INFO]         \"    (merged_ascogs[\\\"hmm_to\\\"] - merged_ascogs[\\\"hmm_from\\\"] + 1)\\n\",\n",
      "2026-01-21 11:08:43,379 [INFO]         \"    / merged_ascogs[\\\"qlen\\\"]\\n\",\n",
      "2026-01-21 11:08:43,380 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:43,380 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,381 [INFO]         \"merged_ascogs = (\\n\",\n",
      "2026-01-21 11:08:43,381 [INFO]         \"    merged_ascogs\\n\",\n",
      "2026-01-21 11:08:43,381 [INFO]         \"    .sort_values(\\n\",\n",
      "2026-01-21 11:08:43,382 [INFO]         \"        by=[\\\"target\\\", \\\"query\\\", \\\"i_evalue\\\", \\\"coverage\\\", \\\"dom_score\\\"],\\n\",\n",
      "2026-01-21 11:08:43,382 [INFO]         \"        ascending=[True, True, True, False, False]\\n\",\n",
      "2026-01-21 11:08:43,383 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,383 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:43,384 [INFO]         \"best_hits = (\\n\",\n",
      "2026-01-21 11:08:43,384 [INFO]         \"    merged_ascogs\\n\",\n",
      "2026-01-21 11:08:43,384 [INFO]         \"    .drop_duplicates(subset=[\\\"target\\\", \\\"query\\\"], keep=\\\"first\\\")\\n\",\n",
      "2026-01-21 11:08:43,385 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:43,385 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,386 [INFO]         \"best_hits = best_hits[(best_hits[\\\"i_evalue\\\"] <= 1e-5) & (best_hits[\\\"coverage\\\"] >= 0.65)]\\n\",\n",
      "2026-01-21 11:08:43,386 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,386 [INFO]         \"best_hits = best_hits[[\\\"target\\\",\\\"query\\\",\\\"gene\\\",\\\"dom_score\\\",\\\"i_evalue\\\",\\\"coverage\\\",\\\"description_y\\\",\\\"tacc\\\",\\\"tlen\\\",\\\"qacc\\\",\\\"qlen\\\",\\\"c_evalue\\\",\\\"hmm_from\\\",\\\"hmm_to\\\",\\\"ali_from\\\",\\\"ali_to\\\",\\\"env_from\\\",\\\"env_to\\\",\\\"acc\\\",\\\"Name\\\",\\\"Completeness\\\",\\\"Contamination\\\",\\\"Contig_N50\\\",\\\"Total_Contigs\\\",\\\"organism_name\\\"]]\\n\",\n",
      "2026-01-21 11:08:43,387 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,387 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:43,388 [INFO]         \"best_hits_file = os.path.join(MAIN_OUTDIR, f\\\"[STEP:{STEP}]ESCRT_hits_final_merged_{rightnow}_ascog_best_hits.csv\\\")\\n\",\n",
      "2026-01-21 11:08:43,388 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,389 [INFO]         \"best_hits.to_csv(best_hits_file, index=False)\\n\",\n",
      "2026-01-21 11:08:43,389 [INFO]         \"logging.info(\\\"Best hits file written to: %s\\\", best_hits_file)\\n\"\n",
      "2026-01-21 11:08:43,390 [INFO]       ]\n",
      "2026-01-21 11:08:43,390 [INFO]     },\n",
      "2026-01-21 11:08:43,390 [INFO]     {\n",
      "2026-01-21 11:08:43,390 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:43,391 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:43,391 [INFO]       \"id\": \"b722f80f\",\n",
      "2026-01-21 11:08:43,392 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:43,392 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:43,392 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:43,393 [INFO]         \"# Compute protein counts with AsCOG hits\\n\",\n",
      "2026-01-21 11:08:43,393 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,394 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,394 [INFO]         \"protein_counts = (\\n\",\n",
      "2026-01-21 11:08:43,395 [INFO]         \"    best_hits\\n\",\n",
      "2026-01-21 11:08:43,395 [INFO]         \"    .dropna(subset=[\\\"gene\\\", \\\"query\\\"])\\n\",\n",
      "2026-01-21 11:08:43,396 [INFO]         \"    .assign(\\n\",\n",
      "2026-01-21 11:08:43,396 [INFO]         \"        gene=lambda df: df[\\\"gene\\\"].str.strip(),\\n\",\n",
      "2026-01-21 11:08:43,396 [INFO]         \"        ascog_id=lambda df: df[\\\"query\\\"].str.strip()\\n\",\n",
      "2026-01-21 11:08:43,397 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,397 [INFO]         \"    .groupby(\\\"target\\\")\\n\",\n",
      "2026-01-21 11:08:43,397 [INFO]         \"    .agg(\\n\",\n",
      "2026-01-21 11:08:43,398 [INFO]         \"        ascog_hits=(\\\"gene\\\", lambda x: list(x.unique())),\\n\",\n",
      "2026-01-21 11:08:43,398 [INFO]         \"        ascog_ids=(\\\"query\\\", lambda x: list(x.unique()))\\n\",\n",
      "2026-01-21 11:08:43,399 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,399 [INFO]         \"    .reset_index()\\n\",\n",
      "2026-01-21 11:08:43,400 [INFO]         \"    .assign(\\n\",\n",
      "2026-01-21 11:08:43,400 [INFO]         \"        ascog_count=lambda df: df[\\\"ascog_hits\\\"].apply(len)\\n\",\n",
      "2026-01-21 11:08:43,400 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,401 [INFO]         \"    .sort_values(by = [\\\"ascog_count\\\"], ascending=[False])\\n\",\n",
      "2026-01-21 11:08:43,401 [INFO]         \"    .assign(\\n\",\n",
      "2026-01-21 11:08:43,402 [INFO]         \"        arch_str=lambda d: d[\\\"ascog_hits\\\"].apply(lambda x: \\\"+\\\".join(sorted(x)))\\n\",\n",
      "2026-01-21 11:08:43,402 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,403 [INFO]         \"    .sort_values(\\n\",\n",
      "2026-01-21 11:08:43,403 [INFO]         \"        by=[\\\"ascog_count\\\", \\\"arch_str\\\"],\\n\",\n",
      "2026-01-21 11:08:43,404 [INFO]         \"        ascending=[False, True]\\n\",\n",
      "2026-01-21 11:08:43,404 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,404 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:43,405 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,405 [INFO]         \"logging.info(\\\"Computed protein counts with AsCOG hits\\\")\\n\",\n",
      "2026-01-21 11:08:43,406 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,406 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:43,406 [INFO]         \"protein_counts_file = os.path.join(MAIN_OUTDIR, f\\\"[STEP:{STEP}]protein_ascog_counts_{rightnow}.csv\\\")\\n\",\n",
      "2026-01-21 11:08:43,407 [INFO]         \"try:\\n\",\n",
      "2026-01-21 11:08:43,407 [INFO]         \"    protein_counts.to_csv(protein_counts_file, index=False)\\n\",\n",
      "2026-01-21 11:08:43,408 [INFO]         \"except Exception as e:\\n\",\n",
      "2026-01-21 11:08:43,408 [INFO]         \"    logging.error(\\\"Failed to write protein counts file %s: %s\\\", protein_counts_file, e)\\n\",\n",
      "2026-01-21 11:08:43,409 [INFO]         \"    raise ValueError(f\\\"Failed to write protein counts file: {e}\\\")\"\n",
      "2026-01-21 11:08:43,409 [INFO]       ]\n",
      "2026-01-21 11:08:43,409 [INFO]     },\n",
      "2026-01-21 11:08:43,411 [INFO]     {\n",
      "2026-01-21 11:08:43,411 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:43,411 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:43,411 [INFO]       \"id\": \"e59d2985\",\n",
      "2026-01-21 11:08:43,412 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:43,413 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:43,413 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:43,413 [INFO]         \"# Infer architectures based on rules\\n\",\n",
      "2026-01-21 11:08:43,414 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,414 [INFO]         \"# Order matters: first match wins\\n\",\n",
      "2026-01-21 11:08:43,414 [INFO]         \"ARCH_RULES = [\\n\",\n",
      "2026-01-21 11:08:43,415 [INFO]         \"    # Vps23 canonical\\n\",\n",
      "2026-01-21 11:08:43,415 [INFO]         \"    ({\\\"CC-Vps23\\\", \\\"PH-Vps23\\\", \\\"Vps23\\\"}, \\\"CC-PH-Vps23\\\"),\\n\",\n",
      "2026-01-21 11:08:43,415 [INFO]         \"    ({\\\"CC-Vps23\\\", \\\"PH-Vps23\\\"}, \\\"CC-PH-Vps23\\\"),\\n\",\n",
      "2026-01-21 11:08:43,416 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,416 [INFO]         \"    # E2\\u2013Vps23 fusion\\n\",\n",
      "2026-01-21 11:08:43,417 [INFO]         \"    ({\\\"E2-Vps23\\\", \\\"E2\\\", \\\"Vps23\\\"}, \\\"E2-Vps23\\\"),\\n\",\n",
      "2026-01-21 11:08:43,417 [INFO]         \"    ({\\\"E2-Vps23\\\", \\\"E2\\\"}, \\\"E2-Vps23\\\"),\\n\",\n",
      "2026-01-21 11:08:43,418 [INFO]         \"    ({\\\"E2-Vps23\\\", \\\"Vps23\\\"}, \\\"E2-Vps23\\\"),\\n\",\n",
      "2026-01-21 11:08:43,418 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,419 [INFO]         \"    # ESCRT-I\\u2013linked E2\\n\",\n",
      "2026-01-21 11:08:43,419 [INFO]         \"    ({\\\"Vps28\\\", \\\"E2-Vps23\\\", \\\"E2\\\"}, \\\"E2-ESCRT-I\\\"),\\n\",\n",
      "2026-01-21 11:08:43,419 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,420 [INFO]         \"    # ESCRT-II Vps22-Vps36 fusion\\n\",\n",
      "2026-01-21 11:08:43,421 [INFO]         \"    ({\\\"CC-Vps23\\\", \\\"EAP30\\\"}, \\\"Vps23-EAP30\\\"),\\n\",\n",
      "2026-01-21 11:08:43,421 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,421 [INFO]         \"    # MPN-E3_doms\\n\",\n",
      "2026-01-21 11:08:43,422 [INFO]         \"    ({\\\"MPN\\\", \\\"E3-dom\\\"}, \\\"MPN-E3-dom\\\"),\\n\",\n",
      "2026-01-21 11:08:43,422 [INFO]         \"]\\n\",\n",
      "2026-01-21 11:08:43,423 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,423 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,423 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,424 [INFO]         \"import pandas as pd\\n\",\n",
      "2026-01-21 11:08:43,424 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,425 [INFO]         \"def infer_architecture(group: pd.DataFrame) -> pd.Series:\\n\",\n",
      "2026-01-21 11:08:43,425 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,426 [INFO]         \"    Infer a single architecture for one protein (target)\\n\",\n",
      "2026-01-21 11:08:43,426 [INFO]         \"    using explicit rules, else fallback to best i-Evalue hit.\\n\",\n",
      "2026-01-21 11:08:43,426 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,427 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,427 [INFO]         \"    # Clean gene names\\n\",\n",
      "2026-01-21 11:08:43,428 [INFO]         \"    genes = set(\\n\",\n",
      "2026-01-21 11:08:43,428 [INFO]         \"        group[\\\"gene\\\"]\\n\",\n",
      "2026-01-21 11:08:43,429 [INFO]         \"        .dropna()\\n\",\n",
      "2026-01-21 11:08:43,429 [INFO]         \"        .astype(str)\\n\",\n",
      "2026-01-21 11:08:43,429 [INFO]         \"        .str.strip()\\n\",\n",
      "2026-01-21 11:08:43,430 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,430 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,431 [INFO]         \"    # 1. Apply rule-based architecture inference\\n\",\n",
      "2026-01-21 11:08:43,431 [INFO]         \"    for rule_genes, architecture in ARCH_RULES:\\n\",\n",
      "2026-01-21 11:08:43,431 [INFO]         \"        if rule_genes.issubset(genes):\\n\",\n",
      "2026-01-21 11:08:43,432 [INFO]         \"            return pd.Series({\\n\",\n",
      "2026-01-21 11:08:43,432 [INFO]         \"                \\\"architecture\\\": architecture,\\n\",\n",
      "2026-01-21 11:08:43,433 [INFO]         \"                \\\"architecture_method\\\": \\\"rule\\\",\\n\",\n",
      "2026-01-21 11:08:43,433 [INFO]         \"                \\\"architecture_components\\\": \\\",\\\".join(sorted(rule_genes))\\n\",\n",
      "2026-01-21 11:08:43,433 [INFO]         \"            })\\n\",\n",
      "2026-01-21 11:08:43,434 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,434 [INFO]         \"    # 2. Fallback: best single hit by independent E-value\\n\",\n",
      "2026-01-21 11:08:43,434 [INFO]         \"    best_hit = (\\n\",\n",
      "2026-01-21 11:08:43,435 [INFO]         \"        group\\n\",\n",
      "2026-01-21 11:08:43,435 [INFO]         \"        .dropna(subset=[\\\"i_evalue\\\"])\\n\",\n",
      "2026-01-21 11:08:43,436 [INFO]         \"        .sort_values(\\\"i_evalue\\\", ascending=True)\\n\",\n",
      "2026-01-21 11:08:43,436 [INFO]         \"        .iloc[0]\\n\",\n",
      "2026-01-21 11:08:43,436 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,437 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,437 [INFO]         \"    return pd.Series({\\n\",\n",
      "2026-01-21 11:08:43,438 [INFO]         \"        \\\"architecture\\\": best_hit[\\\"gene\\\"],\\n\",\n",
      "2026-01-21 11:08:43,438 [INFO]         \"        \\\"architecture_method\\\": \\\"best_i_evalue\\\",\\n\",\n",
      "2026-01-21 11:08:43,439 [INFO]         \"        \\\"architecture_components\\\": best_hit[\\\"gene\\\"]\\n\",\n",
      "2026-01-21 11:08:43,439 [INFO]         \"    })\\n\",\n",
      "2026-01-21 11:08:43,439 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,442 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,443 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,443 [INFO]         \"architecture_df = (\\n\",\n",
      "2026-01-21 11:08:43,444 [INFO]         \"    best_hits\\n\",\n",
      "2026-01-21 11:08:43,445 [INFO]         \"    .dropna(subset=[\\\"target\\\", \\\"gene\\\", \\\"i_evalue\\\"])\\n\",\n",
      "2026-01-21 11:08:43,446 [INFO]         \"    .groupby(\\\"target\\\", group_keys=False)\\n\",\n",
      "2026-01-21 11:08:43,446 [INFO]         \"    .apply(infer_architecture)\\n\",\n",
      "2026-01-21 11:08:43,447 [INFO]         \"    .reset_index()\\n\",\n",
      "2026-01-21 11:08:43,447 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:43,448 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,448 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,449 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,450 [INFO]         \"df_with_arch = best_hits.merge(\\n\",\n",
      "2026-01-21 11:08:43,450 [INFO]         \"    architecture_df,\\n\",\n",
      "2026-01-21 11:08:43,451 [INFO]         \"    on=\\\"target\\\",\\n\",\n",
      "2026-01-21 11:08:43,452 [INFO]         \"    how=\\\"left\\\"\\n\",\n",
      "2026-01-21 11:08:43,453 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:43,454 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,454 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,455 [INFO]         \"df_with_arch = df_with_arch[[\\\"target\\\",\\\"Name\\\",\\\"Completeness\\\",\\\"Contamination\\\",\\\"Contig_N50\\\",\\\"Total_Contigs\\\",\\\"organism_name\\\",\\\"architecture\\\",\\\"architecture_method\\\",\\\"architecture_components\\\"]]\\n\",\n",
      "2026-01-21 11:08:43,455 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,456 [INFO]         \"df_with_arch.drop_duplicates(inplace=True)\\n\",\n",
      "2026-01-21 11:08:43,457 [INFO]         \"logging.info(\\\"Inferred architectures for proteins\\\")\\n\",\n",
      "2026-01-21 11:08:43,457 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,458 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:43,458 [INFO]         \"df_with_arch_file = os.path.join(MAIN_OUTDIR, f\\\"[STEP:{STEP}]ESCRT_hits_with_architectures_{rightnow}.csv\\\")\\n\",\n",
      "2026-01-21 11:08:43,459 [INFO]         \"try:\\n\",\n",
      "2026-01-21 11:08:43,460 [INFO]         \"    df_with_arch.to_csv(df_with_arch_file, index=False)\\n\",\n",
      "2026-01-21 11:08:43,461 [INFO]         \"except Exception as e: \\n\",\n",
      "2026-01-21 11:08:43,461 [INFO]         \"    logging.error(\\\"Failed to write architecture output file %s: %s\\\", df_with_arch_file, e)\\n\",\n",
      "2026-01-21 11:08:43,462 [INFO]         \"    raise ValueError(f\\\"Failed to write architecture output file: {e}\\\")\"\n",
      "2026-01-21 11:08:43,462 [INFO]       ]\n",
      "2026-01-21 11:08:43,463 [INFO]     },\n",
      "2026-01-21 11:08:43,463 [INFO]     {\n",
      "2026-01-21 11:08:43,463 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:43,464 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:43,464 [INFO]       \"id\": \"0982af20\",\n",
      "2026-01-21 11:08:43,464 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:43,465 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:43,465 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:43,465 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,466 [INFO]         \"# # ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,466 [INFO]         \"# # Parse Prodigal GFF and assign gene order PER CONTIG\\n\",\n",
      "2026-01-21 11:08:43,466 [INFO]         \"# # ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,467 [INFO]         \"# def parse_prodigal_gff(gff_path, genome_id):\\n\",\n",
      "2026-01-21 11:08:43,467 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,468 [INFO]         \"#     Parse a Prodigal GFF3 file and extract CDS gene order per contig.\\n\",\n",
      "2026-01-21 11:08:43,468 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,469 [INFO]         \"#     Gene order is defined by appearance order in the GFF,\\n\",\n",
      "2026-01-21 11:08:43,469 [INFO]         \"#     which corresponds to genomic order for Prodigal output.\\n\",\n",
      "2026-01-21 11:08:43,470 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,470 [INFO]         \"#     Args:\\n\",\n",
      "2026-01-21 11:08:43,471 [INFO]         \"#         gff_path: Path to the GFF file\\n\",\n",
      "2026-01-21 11:08:43,472 [INFO]         \"#         genome_id: Identifier for the genome\\n\",\n",
      "2026-01-21 11:08:43,472 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:43,473 [INFO]         \"#     Returns:\\n\",\n",
      "2026-01-21 11:08:43,473 [INFO]         \"#         DataFrame with columns: genome_id, contig, gene_index, \\n\",\n",
      "2026-01-21 11:08:43,474 [INFO]         \"#                                 protein_id, start, end, strand\\n\",\n",
      "2026-01-21 11:08:43,474 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,474 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,475 [INFO]         \"#     rows = []\\n\",\n",
      "2026-01-21 11:08:43,476 [INFO]         \"#     gene_counter = {}  # separate gene index per contig\\n\",\n",
      "2026-01-21 11:08:43,476 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,476 [INFO]         \"#     logging.info(f\\\"Parsing GFF: {gff_path.name}\\\")\\n\",\n",
      "2026-01-21 11:08:43,477 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,477 [INFO]         \"#     with open(gff_path) as f:\\n\",\n",
      "2026-01-21 11:08:43,478 [INFO]         \"#         for line in f:\\n\",\n",
      "2026-01-21 11:08:43,478 [INFO]         \"#             # Skip comment lines\\n\",\n",
      "2026-01-21 11:08:43,478 [INFO]         \"#             if line.startswith(\\\"#\\\"):\\n\",\n",
      "2026-01-21 11:08:43,479 [INFO]         \"#                 continue\\n\",\n",
      "2026-01-21 11:08:43,479 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,480 [INFO]         \"#             parts = line.rstrip().split(\\\"\\\\t\\\")\\n\",\n",
      "2026-01-21 11:08:43,480 [INFO]         \"#             if len(parts) != 9:\\n\",\n",
      "2026-01-21 11:08:43,481 [INFO]         \"#                 continue\\n\",\n",
      "2026-01-21 11:08:43,481 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,482 [INFO]         \"#             contig, source, feature, start, end, score, strand, phase, attrs = parts\\n\",\n",
      "2026-01-21 11:08:43,482 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,483 [INFO]         \"#             # Only process CDS features\\n\",\n",
      "2026-01-21 11:08:43,483 [INFO]         \"#             if feature != \\\"CDS\\\":\\n\",\n",
      "2026-01-21 11:08:43,484 [INFO]         \"#                 continue\\n\",\n",
      "2026-01-21 11:08:43,484 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,484 [INFO]         \"#             # Parse attributes to extract protein ID\\n\",\n",
      "2026-01-21 11:08:43,485 [INFO]         \"#             attr_dict = {}\\n\",\n",
      "2026-01-21 11:08:43,485 [INFO]         \"#             for item in attrs.split(\\\";\\\"):\\n\",\n",
      "2026-01-21 11:08:43,486 [INFO]         \"#                 if \\\"=\\\" in item:\\n\",\n",
      "2026-01-21 11:08:43,486 [INFO]         \"#                     k, v = item.split(\\\"=\\\", 1)\\n\",\n",
      "2026-01-21 11:08:43,487 [INFO]         \"#                     attr_dict[k] = v\\n\",\n",
      "2026-01-21 11:08:43,487 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,488 [INFO]         \"#             protein_id = attr_dict.get(\\\"ID\\\")\\n\",\n",
      "2026-01-21 11:08:43,488 [INFO]         \"#             if protein_id is None:\\n\",\n",
      "2026-01-21 11:08:43,488 [INFO]         \"#                 continue\\n\",\n",
      "2026-01-21 11:08:43,489 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,489 [INFO]         \"#             # Increment gene index PER CONTIG (not genome-wide)\\n\",\n",
      "2026-01-21 11:08:43,489 [INFO]         \"#             gene_counter.setdefault(contig, 0)\\n\",\n",
      "2026-01-21 11:08:43,490 [INFO]         \"#             gene_counter[contig] += 1\\n\",\n",
      "2026-01-21 11:08:43,490 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,491 [INFO]         \"#             rows.append({\\n\",\n",
      "2026-01-21 11:08:43,491 [INFO]         \"#                 \\\"genome_id\\\": genome_id,\\n\",\n",
      "2026-01-21 11:08:43,491 [INFO]         \"#                 \\\"contig\\\": contig,\\n\",\n",
      "2026-01-21 11:08:43,492 [INFO]         \"#                 \\\"gene_index\\\": gene_counter[contig],\\n\",\n",
      "2026-01-21 11:08:43,492 [INFO]         \"#                 \\\"protein_id\\\": protein_id,\\n\",\n",
      "2026-01-21 11:08:43,493 [INFO]         \"#                 \\\"start\\\": int(start),\\n\",\n",
      "2026-01-21 11:08:43,493 [INFO]         \"#                 \\\"end\\\": int(end),\\n\",\n",
      "2026-01-21 11:08:43,493 [INFO]         \"#                 \\\"strand\\\": strand\\n\",\n",
      "2026-01-21 11:08:43,493 [INFO]         \"#             })\\n\",\n",
      "2026-01-21 11:08:43,494 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,494 [INFO]         \"#     logging.info(f\\\"  \\u2192 Parsed {len(rows)} CDS features across {len(gene_counter)} contigs\\\")\\n\",\n",
      "2026-01-21 11:08:43,495 [INFO]         \"#     return pd.DataFrame(rows)\\n\",\n",
      "2026-01-21 11:08:43,495 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,495 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,496 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,496 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,496 [INFO]         \"# # ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,497 [INFO]         \"# # Load only the GFFs required by the hits table\\n\",\n",
      "2026-01-21 11:08:43,497 [INFO]         \"# # ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,498 [INFO]         \"# def load_gffs_from_hits(hits_df, gff_dir):\\n\",\n",
      "2026-01-21 11:08:43,499 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,499 [INFO]         \"#     Parse GFF files only for genomes present in the hits dataframe.\\n\",\n",
      "2026-01-21 11:08:43,499 [INFO]         \"#     GFF filenames are inferred as: <genome_file>_genomic/<genome_file>_genomic.gff\\n\",\n",
      "2026-01-21 11:08:43,500 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,501 [INFO]         \"#     Args:\\n\",\n",
      "2026-01-21 11:08:43,501 [INFO]         \"#         hits_df: DataFrame containing hits with 'genome_file' column\\n\",\n",
      "2026-01-21 11:08:43,501 [INFO]         \"#         gff_dir: Directory containing GFF files\\n\",\n",
      "2026-01-21 11:08:43,502 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:43,502 [INFO]         \"#     Returns:\\n\",\n",
      "2026-01-21 11:08:43,503 [INFO]         \"#         Combined DataFrame of all parsed GFF files\\n\",\n",
      "2026-01-21 11:08:43,503 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,503 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,504 [INFO]         \"#     all_gff_rows = []\\n\",\n",
      "2026-01-21 11:08:43,504 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,504 [INFO]         \"#     unique_genomes = hits_df[\\\"Name\\\"].unique()\\n\",\n",
      "2026-01-21 11:08:43,505 [INFO]         \"#     logging.info(f\\\"Loading GFFs for {len(unique_genomes)} unique genomes\\\")\\n\",\n",
      "2026-01-21 11:08:43,505 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,506 [INFO]         \"#     for genome_id in unique_genomes:\\n\",\n",
      "2026-01-21 11:08:43,506 [INFO]         \"#         gff_path = gff_dir / f\\\"{genome_id}_genomic\\\" / f\\\"{genome_id}_genomic.gff\\\"\\n\",\n",
      "2026-01-21 11:08:43,507 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,507 [INFO]         \"#         if not gff_path.exists():\\n\",\n",
      "2026-01-21 11:08:43,507 [INFO]         \"#             logging.warning(f\\\"Missing GFF: {gff_path}\\\")\\n\",\n",
      "2026-01-21 11:08:43,508 [INFO]         \"#             continue\\n\",\n",
      "2026-01-21 11:08:43,508 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,508 [INFO]         \"#         gff_df = parse_prodigal_gff(gff_path, genome_id)\\n\",\n",
      "2026-01-21 11:08:43,509 [INFO]         \"#         all_gff_rows.append(gff_df)\\n\",\n",
      "2026-01-21 11:08:43,509 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,510 [INFO]         \"#     if not all_gff_rows:\\n\",\n",
      "2026-01-21 11:08:43,510 [INFO]         \"#         logging.error(\\\"No GFF files were successfully loaded.\\\")\\n\",\n",
      "2026-01-21 11:08:43,511 [INFO]         \"#         sys.exit(1)\\n\",\n",
      "2026-01-21 11:08:43,511 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,511 [INFO]         \"#     combined_gff = pd.concat(all_gff_rows, ignore_index=True)\\n\",\n",
      "2026-01-21 11:08:43,512 [INFO]         \"#     logging.info(f\\\"Total CDS features loaded: {len(combined_gff)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,513 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,513 [INFO]         \"#     return combined_gff\\n\",\n",
      "2026-01-21 11:08:43,513 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,514 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,514 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,515 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,515 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,516 [INFO]         \"# def extract_neighborhoods(anchor_df, gff_df, window=5):\\n\",\n",
      "2026-01-21 11:08:43,516 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,516 [INFO]         \"#     Extract \\u00b1window gene neighborhoods around ESCRT-related anchor genes only.\\n\",\n",
      "2026-01-21 11:08:43,517 [INFO]         \"#     Anchors are filtered by architecture name containing:\\n\",\n",
      "2026-01-21 11:08:43,517 [INFO]         \"#     vps, escrt, or katanin (case-insensitive).\\n\",\n",
      "2026-01-21 11:08:43,517 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,517 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,518 [INFO]         \"#     blocks = []\\n\",\n",
      "2026-01-21 11:08:43,518 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,519 [INFO]         \"#     # keywords defining ESCRT relevance\\n\",\n",
      "2026-01-21 11:08:43,519 [INFO]         \"#     keywords = (\\\"vps\\\", \\\"escrt\\\", \\\"katanin\\\", \\\"eap\\\", \\\"flad\\\", \\\"zn-ph\\\")\\n\",\n",
      "2026-01-21 11:08:43,520 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,520 [INFO]         \"#     logging.info(f\\\"Starting neighborhood extraction (\\u00b1{window} genes)\\\")\\n\",\n",
      "2026-01-21 11:08:43,521 [INFO]         \"#     logging.info(f\\\"Initial anchors: {len(anchor_df)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,521 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,522 [INFO]         \"#     # Filter anchors by architecture name\\n\",\n",
      "2026-01-21 11:08:43,522 [INFO]         \"#     filtered_anchors = anchor_df[\\n\",\n",
      "2026-01-21 11:08:43,522 [INFO]         \"#         anchor_df[\\\"architecture\\\"]\\n\",\n",
      "2026-01-21 11:08:43,523 [INFO]         \"#         .astype(str)\\n\",\n",
      "2026-01-21 11:08:43,523 [INFO]         \"#         .str.lower()\\n\",\n",
      "2026-01-21 11:08:43,524 [INFO]         \"#         .str.contains(\\\"|\\\".join(keywords))\\n\",\n",
      "2026-01-21 11:08:43,524 [INFO]         \"#     ]\\n\",\n",
      "2026-01-21 11:08:43,524 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,525 [INFO]         \"#     filtered_anchors.to_csv(os.path.join(MAIN_OUTDIR, f\\\"[STEP:{STEP}.5]filtered_anchors_ESCRT_{rightnow}.csv\\\"), index=False)\\n\",\n",
      "2026-01-21 11:08:43,525 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,526 [INFO]         \"#     logging.info(\\n\",\n",
      "2026-01-21 11:08:43,526 [INFO]         \"#         f\\\"Anchors after ESCRT filter: {len(filtered_anchors)} \\\"\\n\",\n",
      "2026-01-21 11:08:43,527 [INFO]         \"#         f\\\"(skipped {len(anchor_df) - len(filtered_anchors)})\\\"\\n\",\n",
      "2026-01-21 11:08:43,527 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:43,527 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,528 [INFO]         \"#     for _, row in filtered_anchors.iterrows():\\n\",\n",
      "2026-01-21 11:08:43,528 [INFO]         \"#         genome = row[\\\"genome_id\\\"]\\n\",\n",
      "2026-01-21 11:08:43,529 [INFO]         \"#         contig = row[\\\"contig\\\"]\\n\",\n",
      "2026-01-21 11:08:43,529 [INFO]         \"#         center = row[\\\"gene_index\\\"]\\n\",\n",
      "2026-01-21 11:08:43,529 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,529 [INFO]         \"#         if blocks and center in blocks[-1]['gene_index']:\\n\",\n",
      "2026-01-21 11:08:43,530 [INFO]         \"#             continue\\n\",\n",
      "2026-01-21 11:08:43,531 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,531 [INFO]         \"#         block = gff_df[\\n\",\n",
      "2026-01-21 11:08:43,532 [INFO]         \"#             (gff_df[\\\"genome_id\\\"] == genome) &\\n\",\n",
      "2026-01-21 11:08:43,532 [INFO]         \"#             (gff_df[\\\"contig\\\"] == contig) &\\n\",\n",
      "2026-01-21 11:08:43,533 [INFO]         \"#             (gff_df[\\\"gene_index\\\"].between(center - window, center + window))\\n\",\n",
      "2026-01-21 11:08:43,533 [INFO]         \"#         ].copy()\\n\",\n",
      "2026-01-21 11:08:43,533 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,534 [INFO]         \"#         if block.empty:\\n\",\n",
      "2026-01-21 11:08:43,534 [INFO]         \"#             continue\\n\",\n",
      "2026-01-21 11:08:43,535 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,535 [INFO]         \"#         block[\\\"center_protein\\\"] = row[\\\"protein_id\\\"]\\n\",\n",
      "2026-01-21 11:08:43,535 [INFO]         \"#         block[\\\"center_gene\\\"] = row[\\\"architecture\\\"]\\n\",\n",
      "2026-01-21 11:08:43,536 [INFO]         \"#         block[\\\"relative_pos\\\"] = block[\\\"gene_index\\\"] - center\\n\",\n",
      "2026-01-21 11:08:43,536 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,536 [INFO]         \"#         blocks.append(block)\\n\",\n",
      "2026-01-21 11:08:43,537 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,537 [INFO]         \"#     if not blocks:\\n\",\n",
      "2026-01-21 11:08:43,538 [INFO]         \"#         logging.error(\\\"No neighborhood blocks extracted after ESCRT filtering!\\\")\\n\",\n",
      "2026-01-21 11:08:43,538 [INFO]         \"#         sys.exit(1)\\n\",\n",
      "2026-01-21 11:08:43,538 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,539 [INFO]         \"#     combined_neighborhoods = pd.concat(blocks, ignore_index=True)\\n\",\n",
      "2026-01-21 11:08:43,539 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,539 [INFO]         \"#     logging.info(\\n\",\n",
      "2026-01-21 11:08:43,540 [INFO]         \"#         f\\\"Extracted {len(combined_neighborhoods)} genes \\\"\\n\",\n",
      "2026-01-21 11:08:43,540 [INFO]         \"#         f\\\"from {len(blocks)} ESCRT-related neighborhoods\\\"\\n\",\n",
      "2026-01-21 11:08:43,540 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:43,541 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,541 [INFO]         \"#     return combined_neighborhoods\\n\",\n",
      "2026-01-21 11:08:43,541 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,542 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,542 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,543 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,543 [INFO]         \"# def build_windows(anchor_df, window):\\n\",\n",
      "2026-01-21 11:08:43,543 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,544 [INFO]         \"#     Build genomic windows (start, end) around anchor genes.\\n\",\n",
      "2026-01-21 11:08:43,545 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,545 [INFO]         \"#     windows = []\\n\",\n",
      "2026-01-21 11:08:43,546 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,547 [INFO]         \"#     for _, row in anchor_df.iterrows():\\n\",\n",
      "2026-01-21 11:08:43,547 [INFO]         \"#         windows.append({\\n\",\n",
      "2026-01-21 11:08:43,547 [INFO]         \"#             \\\"genome_id\\\": row[\\\"genome_id\\\"],\\n\",\n",
      "2026-01-21 11:08:43,548 [INFO]         \"#             \\\"contig\\\": row[\\\"contig\\\"],\\n\",\n",
      "2026-01-21 11:08:43,548 [INFO]         \"#             \\\"winstart\\\": row[\\\"gene_index\\\"] - window,\\n\",\n",
      "2026-01-21 11:08:43,549 [INFO]         \"#             \\\"winend\\\": row[\\\"gene_index\\\"] + window,\\n\",\n",
      "2026-01-21 11:08:43,549 [INFO]         \"#             \\\"wincenter\\\": row[\\\"gene_index\\\"],\\n\",\n",
      "2026-01-21 11:08:43,549 [INFO]         \"#             \\\"protein_id\\\": row[\\\"protein_id\\\"],\\n\",\n",
      "2026-01-21 11:08:43,550 [INFO]         \"#             \\\"architecture\\\": row[\\\"architecture\\\"],\\n\",\n",
      "2026-01-21 11:08:43,550 [INFO]         \"#         })\\n\",\n",
      "2026-01-21 11:08:43,551 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,551 [INFO]         \"#     return pd.DataFrame(windows)\\n\",\n",
      "2026-01-21 11:08:43,551 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,552 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,552 [INFO]         \"# def merge_windows(windows_df):\\n\",\n",
      "2026-01-21 11:08:43,553 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,553 [INFO]         \"#     Merge overlapping windows per genome/contig.\\n\",\n",
      "2026-01-21 11:08:43,553 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,553 [INFO]         \"#     merged = []\\n\",\n",
      "2026-01-21 11:08:43,554 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,554 [INFO]         \"#     for (genome, contig), grp in windows_df.groupby([\\\"genome_id\\\", \\\"contig\\\"]):\\n\",\n",
      "2026-01-21 11:08:43,555 [INFO]         \"#         grp = grp.sort_values(\\\"winstart\\\")\\n\",\n",
      "2026-01-21 11:08:43,555 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,556 [INFO]         \"#         cur_start = None\\n\",\n",
      "2026-01-21 11:08:43,556 [INFO]         \"#         cur_end = None\\n\",\n",
      "2026-01-21 11:08:43,557 [INFO]         \"#         cur_centers = []\\n\",\n",
      "2026-01-21 11:08:43,557 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,557 [INFO]         \"#         for _, row in grp.iterrows():\\n\",\n",
      "2026-01-21 11:08:43,558 [INFO]         \"#             if cur_start is None:\\n\",\n",
      "2026-01-21 11:08:43,558 [INFO]         \"#                 cur_start = row[\\\"winstart\\\"]\\n\",\n",
      "2026-01-21 11:08:43,558 [INFO]         \"#                 cur_end = row[\\\"winend\\\"]\\n\",\n",
      "2026-01-21 11:08:43,559 [INFO]         \"#                 cur_centers = [row]\\n\",\n",
      "2026-01-21 11:08:43,559 [INFO]         \"#                 continue\\n\",\n",
      "2026-01-21 11:08:43,560 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,560 [INFO]         \"#             if row[\\\"winstart\\\"] <= cur_end + 1:\\n\",\n",
      "2026-01-21 11:08:43,561 [INFO]         \"#                 # overlap \\u2192 extend\\n\",\n",
      "2026-01-21 11:08:43,561 [INFO]         \"#                 cur_end = max(cur_end, row[\\\"winend\\\"])\\n\",\n",
      "2026-01-21 11:08:43,561 [INFO]         \"#                 cur_centers.append(row)\\n\",\n",
      "2026-01-21 11:08:43,562 [INFO]         \"#             else:\\n\",\n",
      "2026-01-21 11:08:43,562 [INFO]         \"#                 merged.append({\\n\",\n",
      "2026-01-21 11:08:43,562 [INFO]         \"#                     \\\"genome_id\\\": genome,\\n\",\n",
      "2026-01-21 11:08:43,563 [INFO]         \"#                     \\\"contig\\\": contig,\\n\",\n",
      "2026-01-21 11:08:43,564 [INFO]         \"#                     \\\"winstart\\\": cur_start,\\n\",\n",
      "2026-01-21 11:08:43,564 [INFO]         \"#                     \\\"winend\\\": cur_end,\\n\",\n",
      "2026-01-21 11:08:43,565 [INFO]         \"#                     \\\"anchors\\\": cur_centers\\n\",\n",
      "2026-01-21 11:08:43,566 [INFO]         \"#                 })\\n\",\n",
      "2026-01-21 11:08:43,566 [INFO]         \"#                 cur_start = row[\\\"winstart\\\"]\\n\",\n",
      "2026-01-21 11:08:43,566 [INFO]         \"#                 cur_end = row[\\\"winend\\\"]\\n\",\n",
      "2026-01-21 11:08:43,567 [INFO]         \"#                 cur_centers = [row]\\n\",\n",
      "2026-01-21 11:08:43,567 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,567 [INFO]         \"#         merged.append({\\n\",\n",
      "2026-01-21 11:08:43,568 [INFO]         \"#             \\\"genome_id\\\": genome,\\n\",\n",
      "2026-01-21 11:08:43,568 [INFO]         \"#             \\\"contig\\\": contig,\\n\",\n",
      "2026-01-21 11:08:43,569 [INFO]         \"#             \\\"winstart\\\": cur_start,\\n\",\n",
      "2026-01-21 11:08:43,569 [INFO]         \"#             \\\"winend\\\": cur_end,\\n\",\n",
      "2026-01-21 11:08:43,569 [INFO]         \"#             \\\"anchors\\\": cur_centers\\n\",\n",
      "2026-01-21 11:08:43,570 [INFO]         \"#         })\\n\",\n",
      "2026-01-21 11:08:43,570 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,571 [INFO]         \"#     return merged\\n\",\n",
      "2026-01-21 11:08:43,572 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,573 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,574 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,575 [INFO]         \"# def extract_merged_neighborhoods(merged_windows, gff_df):\\n\",\n",
      "2026-01-21 11:08:43,575 [INFO]         \"#     blocks = []\\n\",\n",
      "2026-01-21 11:08:43,575 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,576 [INFO]         \"#     for win in merged_windows:\\n\",\n",
      "2026-01-21 11:08:43,576 [INFO]         \"#         block = gff_df[\\n\",\n",
      "2026-01-21 11:08:43,577 [INFO]         \"#             (gff_df[\\\"genome_id\\\"] == win[\\\"genome_id\\\"]) &\\n\",\n",
      "2026-01-21 11:08:43,577 [INFO]         \"#             (gff_df[\\\"contig\\\"] == win[\\\"contig\\\"]) &\\n\",\n",
      "2026-01-21 11:08:43,577 [INFO]         \"#             (gff_df[\\\"gene_index\\\"].between(win[\\\"winstart\\\"], win[\\\"winend\\\"]))\\n\",\n",
      "2026-01-21 11:08:43,578 [INFO]         \"#         ].copy()\\n\",\n",
      "2026-01-21 11:08:43,578 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,578 [INFO]         \"#         if block.empty:\\n\",\n",
      "2026-01-21 11:08:43,579 [INFO]         \"#             continue\\n\",\n",
      "2026-01-21 11:08:43,579 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,579 [INFO]         \"#         # pick a representative anchor (central-most)\\n\",\n",
      "2026-01-21 11:08:43,580 [INFO]         \"#         centers = [a[\\\"wincenter\\\"] for a in win[\\\"anchors\\\"]]\\n\",\n",
      "2026-01-21 11:08:43,580 [INFO]         \"#         rep_center = min(centers, key=lambda x: abs(x - (win[\\\"winstart\\\"] + win[\\\"winend\\\"]) / 2))\\n\",\n",
      "2026-01-21 11:08:43,580 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,581 [INFO]         \"#         block[\\\"relative_pos\\\"] = block[\\\"gene_index\\\"] - rep_center\\n\",\n",
      "2026-01-21 11:08:43,581 [INFO]         \"#         block[\\\"center_protein\\\"] = win[\\\"anchors\\\"][0][\\\"protein_id\\\"]\\n\",\n",
      "2026-01-21 11:08:43,582 [INFO]         \"#         block[\\\"center_gene\\\"] = win[\\\"anchors\\\"][0][\\\"architecture\\\"]\\n\",\n",
      "2026-01-21 11:08:43,583 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,583 [INFO]         \"#         blocks.append(block)\\n\",\n",
      "2026-01-21 11:08:43,583 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,584 [INFO]         \"#     return pd.concat(blocks, ignore_index=True)\\n\",\n",
      "2026-01-21 11:08:43,584 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,584 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,585 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,585 [INFO]         \"# def extract_neighborhoods(anchor_df, gff_df, window=5):\\n\",\n",
      "2026-01-21 11:08:43,586 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,586 [INFO]         \"#     keywords = (\\\"vps\\\", \\\"escrt\\\", \\\"katanin\\\", \\\"eap\\\", \\\"flad\\\", \\\"zn-ph\\\")\\n\",\n",
      "2026-01-21 11:08:43,587 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,587 [INFO]         \"#     logging.info(f\\\"Starting neighborhood extraction (\\u00b1{window} genes)\\\")\\n\",\n",
      "2026-01-21 11:08:43,587 [INFO]         \"#     logging.info(f\\\"Initial anchors: {len(anchor_df)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,588 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,588 [INFO]         \"#     filtered_anchors = anchor_df[\\n\",\n",
      "2026-01-21 11:08:43,589 [INFO]         \"#         anchor_df[\\\"architecture\\\"]\\n\",\n",
      "2026-01-21 11:08:43,589 [INFO]         \"#         .astype(str)\\n\",\n",
      "2026-01-21 11:08:43,590 [INFO]         \"#         .str.lower()\\n\",\n",
      "2026-01-21 11:08:43,590 [INFO]         \"#         .str.contains(\\\"|\\\".join(keywords))\\n\",\n",
      "2026-01-21 11:08:43,590 [INFO]         \"#     ]\\n\",\n",
      "2026-01-21 11:08:43,590 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,591 [INFO]         \"#     logging.info(f\\\"Anchors after ESCRT filter: {len(filtered_anchors)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,591 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,592 [INFO]         \"#     if filtered_anchors.empty:\\n\",\n",
      "2026-01-21 11:08:43,592 [INFO]         \"#         logging.error(\\\"No ESCRT-related anchors found\\\")\\n\",\n",
      "2026-01-21 11:08:43,593 [INFO]         \"#         sys.exit(1)\\n\",\n",
      "2026-01-21 11:08:43,593 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,594 [INFO]         \"#     windows_df = build_windows(filtered_anchors, window)\\n\",\n",
      "2026-01-21 11:08:43,594 [INFO]         \"#     merged_windows = merge_windows(windows_df)\\n\",\n",
      "2026-01-21 11:08:43,595 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,595 [INFO]         \"#     logging.info(\\n\",\n",
      "2026-01-21 11:08:43,596 [INFO]         \"#         f\\\"Merged {len(windows_df)} anchor windows into \\\"\\n\",\n",
      "2026-01-21 11:08:43,596 [INFO]         \"#         f\\\"{len(merged_windows)} non-overlapping regions\\\"\\n\",\n",
      "2026-01-21 11:08:43,597 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:43,597 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,597 [INFO]         \"#     combined_neighborhoods = extract_merged_neighborhoods(\\n\",\n",
      "2026-01-21 11:08:43,598 [INFO]         \"#         merged_windows, gff_df\\n\",\n",
      "2026-01-21 11:08:43,598 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:43,598 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,599 [INFO]         \"#     logging.info(\\n\",\n",
      "2026-01-21 11:08:43,599 [INFO]         \"#         f\\\"Extracted {len(combined_neighborhoods)} genes \\\"\\n\",\n",
      "2026-01-21 11:08:43,600 [INFO]         \"#         f\\\"from {len(merged_windows)} merged neighborhoods\\\"\\n\",\n",
      "2026-01-21 11:08:43,600 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:43,600 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,601 [INFO]         \"#     return combined_neighborhoods\\n\",\n",
      "2026-01-21 11:08:43,601 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,602 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,602 [INFO]         \"# # ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,603 [INFO]         \"# # Load GTDB taxonomy\\n\",\n",
      "2026-01-21 11:08:43,603 [INFO]         \"# # ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,604 [INFO]         \"# def load_gtdb_taxonomy(gtdb_tsv):\\n\",\n",
      "2026-01-21 11:08:43,604 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,604 [INFO]         \"#     Load GTDB taxonomy file and split into rank-specific columns.\\n\",\n",
      "2026-01-21 11:08:43,605 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,605 [INFO]         \"#     GTDB format: genome_id\\\\td__Domain;p__Phylum;c__Class;o__Order;f__Family;g__Genus;s__Species\\n\",\n",
      "2026-01-21 11:08:43,606 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,606 [INFO]         \"#     Args:\\n\",\n",
      "2026-01-21 11:08:43,606 [INFO]         \"#         gtdb_tsv: Path to GTDB taxonomy TSV file\\n\",\n",
      "2026-01-21 11:08:43,607 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:43,607 [INFO]         \"#     Returns:\\n\",\n",
      "2026-01-21 11:08:43,608 [INFO]         \"#         DataFrame with columns: genome_id, domain, phylum, class, order, family, genus, species\\n\",\n",
      "2026-01-21 11:08:43,608 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,608 [INFO]         \"#     logging.info(f\\\"Loading GTDB taxonomy from: {gtdb_tsv}\\\")\\n\",\n",
      "2026-01-21 11:08:43,609 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,609 [INFO]         \"#     # Read the taxonomy file\\n\",\n",
      "2026-01-21 11:08:43,610 [INFO]         \"#     tax_df = pd.read_csv(\\n\",\n",
      "2026-01-21 11:08:43,610 [INFO]         \"#         gtdb_tsv,\\n\",\n",
      "2026-01-21 11:08:43,610 [INFO]         \"#         sep=\\\"\\\\t\\\",\\n\",\n",
      "2026-01-21 11:08:43,611 [INFO]         \"#         header=None,\\n\",\n",
      "2026-01-21 11:08:43,611 [INFO]         \"#         names=[\\\"genome_id\\\", \\\"taxonomy\\\"],\\n\",\n",
      "2026-01-21 11:08:43,612 [INFO]         \"#         dtype=str\\n\",\n",
      "2026-01-21 11:08:43,612 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:43,613 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,613 [INFO]         \"#     tax_df[\\\"genome_id_base\\\"] = tax_df[\\\"genome_id\\\"].str.split(\\\"_\\\", n=1).str[1]\\n\",\n",
      "2026-01-21 11:08:43,613 [INFO]         \"#     logging.info(f\\\"Loaded taxonomy for {len(tax_df)} genomes\\\")\\n\",\n",
      "2026-01-21 11:08:43,614 [INFO]         \"#     logging.info(f\\\"Sample taxonomy entry: {tax_df['taxonomy'].iloc[0]}\\\")\\n\",\n",
      "2026-01-21 11:08:43,614 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,614 [INFO]         \"#     # Split taxonomy string by semicolons\\n\",\n",
      "2026-01-21 11:08:43,615 [INFO]         \"#     tax_split = tax_df[\\\"taxonomy\\\"].str.split(\\\";\\\", expand=True)\\n\",\n",
      "2026-01-21 11:08:43,615 [INFO]         \"#     logging.info(f\\\"Taxonomy split into {tax_split.shape[1]} columns\\\")\\n\",\n",
      "2026-01-21 11:08:43,615 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,616 [INFO]         \"#     # Map column indices to taxonomic ranks\\n\",\n",
      "2026-01-21 11:08:43,616 [INFO]         \"#     rank_map = {\\n\",\n",
      "2026-01-21 11:08:43,616 [INFO]         \"#         0: \\\"domain\\\",\\n\",\n",
      "2026-01-21 11:08:43,617 [INFO]         \"#         1: \\\"phylum\\\",\\n\",\n",
      "2026-01-21 11:08:43,617 [INFO]         \"#         2: \\\"class\\\",\\n\",\n",
      "2026-01-21 11:08:43,618 [INFO]         \"#         3: \\\"order\\\",\\n\",\n",
      "2026-01-21 11:08:43,619 [INFO]         \"#         4: \\\"family\\\",\\n\",\n",
      "2026-01-21 11:08:43,619 [INFO]         \"#         5: \\\"genus\\\",\\n\",\n",
      "2026-01-21 11:08:43,620 [INFO]         \"#         6: \\\"species\\\"\\n\",\n",
      "2026-01-21 11:08:43,620 [INFO]         \"#     }\\n\",\n",
      "2026-01-21 11:08:43,621 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,621 [INFO]         \"#     # Extract each rank and remove the prefix (e.g., \\\"d__\\\", \\\"p__\\\")\\n\",\n",
      "2026-01-21 11:08:43,621 [INFO]         \"#     for idx, rank in rank_map.items():\\n\",\n",
      "2026-01-21 11:08:43,622 [INFO]         \"#         if idx < tax_split.shape[1]:\\n\",\n",
      "2026-01-21 11:08:43,622 [INFO]         \"#             # Remove the rank prefix using regex (e.g., \\\"p__\\\" from \\\"p__Crenarchaeota\\\")\\n\",\n",
      "2026-01-21 11:08:43,622 [INFO]         \"#             tax_df[rank] = tax_split[idx].str.replace(r\\\"^[a-z]__\\\", \\\"\\\", regex=True)\\n\",\n",
      "2026-01-21 11:08:43,623 [INFO]         \"#             logging.info(f\\\"Extracted {rank}: {tax_df[rank].notna().sum()} non-null values\\\")\\n\",\n",
      "2026-01-21 11:08:43,623 [INFO]         \"#         else:\\n\",\n",
      "2026-01-21 11:08:43,624 [INFO]         \"#             tax_df[rank] = pd.NA\\n\",\n",
      "2026-01-21 11:08:43,624 [INFO]         \"#             logging.warning(f\\\"Column {idx} for rank '{rank}' not found in taxonomy data\\\")\\n\",\n",
      "2026-01-21 11:08:43,625 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,625 [INFO]         \"#     # Drop the original concatenated taxonomy string\\n\",\n",
      "2026-01-21 11:08:43,625 [INFO]         \"#     tax_df.drop(columns=[\\\"taxonomy\\\"], inplace=True)\\n\",\n",
      "2026-01-21 11:08:43,626 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,626 [INFO]         \"#     # Log sample of parsed taxonomy\\n\",\n",
      "2026-01-21 11:08:43,627 [INFO]         \"#     logging.info(f\\\"Sample parsed taxonomy:\\\")\\n\",\n",
      "2026-01-21 11:08:43,627 [INFO]         \"#     logging.info(tax_df[[\\\"genome_id\\\", \\\"domain\\\", \\\"phylum\\\", \\\"class\\\"]].head().to_string())\\n\",\n",
      "2026-01-21 11:08:43,627 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,628 [INFO]         \"#     return tax_df\\n\",\n",
      "2026-01-21 11:08:43,628 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,629 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,629 [INFO]         \"# # ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,629 [INFO]         \"# # Merge taxonomy into neighborhood data\\n\",\n",
      "2026-01-21 11:08:43,630 [INFO]         \"# # ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,630 [INFO]         \"# def merge_taxonomy(escrt_csv, gtdb_tsv, out_csv):\\n\",\n",
      "2026-01-21 11:08:43,631 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,631 [INFO]         \"#     Merge GTDB taxonomy into ESCRT neighborhood dataframe.\\n\",\n",
      "2026-01-21 11:08:43,631 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,632 [INFO]         \"#     Args:\\n\",\n",
      "2026-01-21 11:08:43,632 [INFO]         \"#         escrt_csv: Path to ESCRT neighborhoods CSV\\n\",\n",
      "2026-01-21 11:08:43,632 [INFO]         \"#         gtdb_tsv: Path to GTDB taxonomy TSV\\n\",\n",
      "2026-01-21 11:08:43,633 [INFO]         \"#         out_csv: Output path for merged CSV\\n\",\n",
      "2026-01-21 11:08:43,633 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:43,634 [INFO]         \"#     Returns:\\n\",\n",
      "2026-01-21 11:08:43,634 [INFO]         \"#         Merged DataFrame with taxonomy columns added\\n\",\n",
      "2026-01-21 11:08:43,635 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,635 [INFO]         \"#     logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,636 [INFO]         \"#     logging.info(\\\"STARTING TAXONOMY MERGE\\\")\\n\",\n",
      "2026-01-21 11:08:43,636 [INFO]         \"#     logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,637 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,637 [INFO]         \"#     # Load neighborhood data\\n\",\n",
      "2026-01-21 11:08:43,637 [INFO]         \"#     logging.info(f\\\"Loading neighborhood data from: {escrt_csv}\\\")\\n\",\n",
      "2026-01-21 11:08:43,638 [INFO]         \"#     escrt_df = pd.read_csv(escrt_csv)\\n\",\n",
      "2026-01-21 11:08:43,638 [INFO]         \"#     escrt_df['genome_id_base'] = (\\n\",\n",
      "2026-01-21 11:08:43,638 [INFO]         \"#     escrt_df['genome_id']\\n\",\n",
      "2026-01-21 11:08:43,639 [INFO]         \"#     .str.split(\\\"_\\\", n=2)\\n\",\n",
      "2026-01-21 11:08:43,639 [INFO]         \"#     .str[0:2]\\n\",\n",
      "2026-01-21 11:08:43,639 [INFO]         \"#     .str.join(\\\"_\\\")\\n\",\n",
      "2026-01-21 11:08:43,640 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:43,640 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,640 [INFO]         \"#     logging.info(f\\\"Neighborhood data: {len(escrt_df)} rows, {len(escrt_df['genome_id'].unique())} unique genomes\\\")\\n\",\n",
      "2026-01-21 11:08:43,640 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,641 [INFO]         \"#     # Load taxonomy data\\n\",\n",
      "2026-01-21 11:08:43,641 [INFO]         \"#     tax_df = load_gtdb_taxonomy(gtdb_tsv)\\n\",\n",
      "2026-01-21 11:08:43,642 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,642 [INFO]         \"#     # Check for overlap between datasets\\n\",\n",
      "2026-01-21 11:08:43,642 [INFO]         \"#     escrt_genomes = set(escrt_df[\\\"genome_id_base\\\"].unique())\\n\",\n",
      "2026-01-21 11:08:43,643 [INFO]         \"#     tax_genomes = set(tax_df[\\\"genome_id_base\\\"].unique())\\n\",\n",
      "2026-01-21 11:08:43,643 [INFO]         \"#     overlap = escrt_genomes.intersection(tax_genomes)\\n\",\n",
      "2026-01-21 11:08:43,644 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,645 [INFO]         \"#     logging.info(f\\\"Genome ID overlap check:\\\")\\n\",\n",
      "2026-01-21 11:08:43,645 [INFO]         \"#     logging.info(f\\\"  Genomes in neighborhood data: {len(escrt_genomes)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,645 [INFO]         \"#     logging.info(f\\\"  Genomes in taxonomy data: {len(tax_genomes)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,646 [INFO]         \"#     logging.info(f\\\"  Overlapping genomes: {len(overlap)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,646 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,647 [INFO]         \"#     if len(overlap) == 0:\\n\",\n",
      "2026-01-21 11:08:43,647 [INFO]         \"#         logging.error(\\\"NO OVERLAP between genome IDs!\\\")\\n\",\n",
      "2026-01-21 11:08:43,647 [INFO]         \"#         logging.error(f\\\"Sample neighborhood genome IDs: {list(escrt_genomes)[:5]}\\\")\\n\",\n",
      "2026-01-21 11:08:43,648 [INFO]         \"#         logging.error(f\\\"Sample taxonomy genome IDs: {list(tax_genomes)[:5]}\\\")\\n\",\n",
      "2026-01-21 11:08:43,648 [INFO]         \"#         logging.error(\\\"Check if genome_id formats match between files!\\\")\\n\",\n",
      "2026-01-21 11:08:43,648 [INFO]         \"#         sys.exit(1)\\n\",\n",
      "2026-01-21 11:08:43,649 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,649 [INFO]         \"#     if len(overlap) < len(escrt_genomes):\\n\",\n",
      "2026-01-21 11:08:43,650 [INFO]         \"#         missing = len(escrt_genomes) - len(overlap)\\n\",\n",
      "2026-01-21 11:08:43,650 [INFO]         \"#         logging.warning(f\\\"{missing} genomes from neighborhood data not found in taxonomy!\\\")\\n\",\n",
      "2026-01-21 11:08:43,650 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,651 [INFO]         \"#     # Perform the merge\\n\",\n",
      "2026-01-21 11:08:43,651 [INFO]         \"#     logging.info(\\\"Performing left join on genome_id...\\\")\\n\",\n",
      "2026-01-21 11:08:43,651 [INFO]         \"#     merged = escrt_df.merge(\\n\",\n",
      "2026-01-21 11:08:43,652 [INFO]         \"#         tax_df,\\n\",\n",
      "2026-01-21 11:08:43,652 [INFO]         \"#         on=\\\"genome_id_base\\\",\\n\",\n",
      "2026-01-21 11:08:43,653 [INFO]         \"#         how=\\\"left\\\"\\n\",\n",
      "2026-01-21 11:08:43,653 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:43,654 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,654 [INFO]         \"#     # Validate merge results\\n\",\n",
      "2026-01-21 11:08:43,655 [INFO]         \"#     logging.info(f\\\"Merge complete: {len(merged)} rows\\\")\\n\",\n",
      "2026-01-21 11:08:43,655 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,655 [INFO]         \"#     # Check how many rows got taxonomy data\\n\",\n",
      "2026-01-21 11:08:43,656 [INFO]         \"#     tax_columns = [\\\"domain\\\", \\\"phylum\\\", \\\"class\\\", \\\"order\\\", \\\"family\\\", \\\"genus\\\", \\\"species\\\"]\\n\",\n",
      "2026-01-21 11:08:43,656 [INFO]         \"#     for col in tax_columns:\\n\",\n",
      "2026-01-21 11:08:43,657 [INFO]         \"#         non_null = merged[col].notna().sum()\\n\",\n",
      "2026-01-21 11:08:43,657 [INFO]         \"#         pct = (non_null / len(merged)) * 100\\n\",\n",
      "2026-01-21 11:08:43,657 [INFO]         \"#         logging.info(f\\\"  {col}: {non_null} non-null ({pct:.1f}%)\\\")\\n\",\n",
      "2026-01-21 11:08:43,658 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,658 [INFO]         \"#     # Save to CSV\\n\",\n",
      "2026-01-21 11:08:43,658 [INFO]         \"#     logging.info(f\\\"Saving merged data to: {out_csv}\\\")\\n\",\n",
      "2026-01-21 11:08:43,659 [INFO]         \"#     merged.to_csv(out_csv, index=False)\\n\",\n",
      "2026-01-21 11:08:43,659 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,660 [INFO]         \"#     # Show sample of merged data\\n\",\n",
      "2026-01-21 11:08:43,660 [INFO]         \"#     logging.info(\\\"Sample of merged data with taxonomy:\\\")\\n\",\n",
      "2026-01-21 11:08:43,661 [INFO]         \"#     sample_cols = [\\\"genome_id\\\", \\\"protein_id\\\", \\\"domain\\\", \\\"phylum\\\", \\\"class\\\", \\\"order\\\"]\\n\",\n",
      "2026-01-21 11:08:43,661 [INFO]         \"#     available_cols = [col for col in sample_cols if col in merged.columns]\\n\",\n",
      "2026-01-21 11:08:43,661 [INFO]         \"#     logging.info(merged[available_cols].head(10).to_string())\\n\",\n",
      "2026-01-21 11:08:43,662 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,662 [INFO]         \"#     logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,663 [INFO]         \"#     logging.info(\\\"TAXONOMY MERGE COMPLETE\\\")\\n\",\n",
      "2026-01-21 11:08:43,663 [INFO]         \"#     logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,663 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,663 [INFO]         \"#     return merged\\n\",\n",
      "2026-01-21 11:08:43,664 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,665 [INFO]         \"\\n\"\n",
      "2026-01-21 11:08:43,665 [INFO]       ]\n",
      "2026-01-21 11:08:43,665 [INFO]     },\n",
      "2026-01-21 11:08:43,666 [INFO]     {\n",
      "2026-01-21 11:08:43,666 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:43,667 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:43,667 [INFO]       \"id\": \"109ab58b\",\n",
      "2026-01-21 11:08:43,668 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:43,668 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:43,668 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:43,669 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,669 [INFO]         \"# ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,670 [INFO]         \"# Parse Prodigal GFF and assign gene order PER CONTIG\\n\",\n",
      "2026-01-21 11:08:43,670 [INFO]         \"# ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,670 [INFO]         \"def parse_prodigal_gff(gff_path, genome_id):\\n\",\n",
      "2026-01-21 11:08:43,671 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,671 [INFO]         \"    Parse a Prodigal GFF3 file and extract CDS gene order per contig.\\n\",\n",
      "2026-01-21 11:08:43,672 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,672 [INFO]         \"    Gene order is defined by appearance order in the GFF,\\n\",\n",
      "2026-01-21 11:08:43,672 [INFO]         \"    which corresponds to genomic order for Prodigal output.\\n\",\n",
      "2026-01-21 11:08:43,673 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,673 [INFO]         \"    Args:\\n\",\n",
      "2026-01-21 11:08:43,674 [INFO]         \"        gff_path: Path to the GFF file\\n\",\n",
      "2026-01-21 11:08:43,674 [INFO]         \"        genome_id: Identifier for the genome\\n\",\n",
      "2026-01-21 11:08:43,674 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:43,675 [INFO]         \"    Returns:\\n\",\n",
      "2026-01-21 11:08:43,675 [INFO]         \"        DataFrame with columns: genome_id, contig, gene_index, \\n\",\n",
      "2026-01-21 11:08:43,676 [INFO]         \"                                protein_id, start, end, strand\\n\",\n",
      "2026-01-21 11:08:43,676 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,676 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,677 [INFO]         \"    rows = []\\n\",\n",
      "2026-01-21 11:08:43,677 [INFO]         \"    gene_counter = {}  # separate gene index per contig\\n\",\n",
      "2026-01-21 11:08:43,677 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,678 [INFO]         \"    logging.info(f\\\"Parsing GFF: {gff_path.name}\\\")\\n\",\n",
      "2026-01-21 11:08:43,678 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,679 [INFO]         \"    with open(gff_path) as f:\\n\",\n",
      "2026-01-21 11:08:43,679 [INFO]         \"        for line in f:\\n\",\n",
      "2026-01-21 11:08:43,680 [INFO]         \"            # Skip comment lines\\n\",\n",
      "2026-01-21 11:08:43,680 [INFO]         \"            if line.startswith(\\\"#\\\"):\\n\",\n",
      "2026-01-21 11:08:43,680 [INFO]         \"                continue\\n\",\n",
      "2026-01-21 11:08:43,681 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,681 [INFO]         \"            parts = line.rstrip().split(\\\"\\\\t\\\")\\n\",\n",
      "2026-01-21 11:08:43,682 [INFO]         \"            if len(parts) != 9:\\n\",\n",
      "2026-01-21 11:08:43,682 [INFO]         \"                continue\\n\",\n",
      "2026-01-21 11:08:43,683 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,683 [INFO]         \"            contig, source, feature, start, end, score, strand, phase, attrs = parts\\n\",\n",
      "2026-01-21 11:08:43,683 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,683 [INFO]         \"            # Only process CDS features\\n\",\n",
      "2026-01-21 11:08:43,684 [INFO]         \"            if feature != \\\"CDS\\\":\\n\",\n",
      "2026-01-21 11:08:43,684 [INFO]         \"                continue\\n\",\n",
      "2026-01-21 11:08:43,684 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,685 [INFO]         \"            # Parse attributes to extract protein ID\\n\",\n",
      "2026-01-21 11:08:43,685 [INFO]         \"            attr_dict = {}\\n\",\n",
      "2026-01-21 11:08:43,686 [INFO]         \"            for item in attrs.split(\\\";\\\"):\\n\",\n",
      "2026-01-21 11:08:43,686 [INFO]         \"                if \\\"=\\\" in item:\\n\",\n",
      "2026-01-21 11:08:43,687 [INFO]         \"                    k, v = item.split(\\\"=\\\", 1)\\n\",\n",
      "2026-01-21 11:08:43,687 [INFO]         \"                    attr_dict[k] = v\\n\",\n",
      "2026-01-21 11:08:43,687 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,688 [INFO]         \"            protein_id = attr_dict.get(\\\"ID\\\")\\n\",\n",
      "2026-01-21 11:08:43,688 [INFO]         \"            if protein_id is None:\\n\",\n",
      "2026-01-21 11:08:43,689 [INFO]         \"                continue\\n\",\n",
      "2026-01-21 11:08:43,689 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,690 [INFO]         \"            # Increment gene index PER CONTIG (not genome-wide)\\n\",\n",
      "2026-01-21 11:08:43,690 [INFO]         \"            gene_counter.setdefault(contig, 0)\\n\",\n",
      "2026-01-21 11:08:43,690 [INFO]         \"            gene_counter[contig] += 1\\n\",\n",
      "2026-01-21 11:08:43,691 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,691 [INFO]         \"            rows.append({\\n\",\n",
      "2026-01-21 11:08:43,692 [INFO]         \"                \\\"genome_id\\\": genome_id,\\n\",\n",
      "2026-01-21 11:08:43,692 [INFO]         \"                \\\"contig\\\": contig,\\n\",\n",
      "2026-01-21 11:08:43,692 [INFO]         \"                \\\"gene_index\\\": gene_counter[contig],\\n\",\n",
      "2026-01-21 11:08:43,693 [INFO]         \"                \\\"protein_id\\\": protein_id,\\n\",\n",
      "2026-01-21 11:08:43,693 [INFO]         \"                \\\"start\\\": int(start),\\n\",\n",
      "2026-01-21 11:08:43,693 [INFO]         \"                \\\"end\\\": int(end),\\n\",\n",
      "2026-01-21 11:08:43,694 [INFO]         \"                \\\"strand\\\": strand\\n\",\n",
      "2026-01-21 11:08:43,694 [INFO]         \"            })\\n\",\n",
      "2026-01-21 11:08:43,694 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,695 [INFO]         \"    logging.info(f\\\"  \\u2192 Parsed {len(rows)} CDS features across {len(gene_counter)} contigs\\\")\\n\",\n",
      "2026-01-21 11:08:43,695 [INFO]         \"    return pd.DataFrame(rows)\\n\",\n",
      "2026-01-21 11:08:43,696 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,697 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,697 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,698 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,699 [INFO]         \"# ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,699 [INFO]         \"# Load only the GFFs required by the hits table\\n\",\n",
      "2026-01-21 11:08:43,699 [INFO]         \"# ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,699 [INFO]         \"def load_gffs_from_hits(hits_df, gff_dir):\\n\",\n",
      "2026-01-21 11:08:43,700 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,700 [INFO]         \"    Parse GFF files only for genomes present in the hits dataframe.\\n\",\n",
      "2026-01-21 11:08:43,701 [INFO]         \"    GFF filenames are inferred as: <genome_file>_genomic/<genome_file>_genomic.gff\\n\",\n",
      "2026-01-21 11:08:43,701 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,702 [INFO]         \"    Args:\\n\",\n",
      "2026-01-21 11:08:43,702 [INFO]         \"        hits_df: DataFrame containing hits with 'genome_file' column\\n\",\n",
      "2026-01-21 11:08:43,703 [INFO]         \"        gff_dir: Directory containing GFF files\\n\",\n",
      "2026-01-21 11:08:43,703 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:43,704 [INFO]         \"    Returns:\\n\",\n",
      "2026-01-21 11:08:43,704 [INFO]         \"        Combined DataFrame of all parsed GFF files\\n\",\n",
      "2026-01-21 11:08:43,705 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,705 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,706 [INFO]         \"    all_gff_rows = []\\n\",\n",
      "2026-01-21 11:08:43,706 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,707 [INFO]         \"    unique_genomes = hits_df[\\\"Name\\\"].unique()\\n\",\n",
      "2026-01-21 11:08:43,707 [INFO]         \"    logging.info(f\\\"Loading GFFs for {len(unique_genomes)} unique genomes\\\")\\n\",\n",
      "2026-01-21 11:08:43,708 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,710 [INFO]         \"    for genome_id in unique_genomes:\\n\",\n",
      "2026-01-21 11:08:43,712 [INFO]         \"        gff_path = gff_dir / f\\\"{genome_id}_genomic\\\" / f\\\"{genome_id}_genomic.gff\\\"\\n\",\n",
      "2026-01-21 11:08:43,713 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,714 [INFO]         \"        if not gff_path.exists():\\n\",\n",
      "2026-01-21 11:08:43,714 [INFO]         \"            logging.warning(f\\\"Missing GFF: {gff_path}\\\")\\n\",\n",
      "2026-01-21 11:08:43,715 [INFO]         \"            continue\\n\",\n",
      "2026-01-21 11:08:43,716 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,717 [INFO]         \"        gff_df = parse_prodigal_gff(gff_path, genome_id)\\n\",\n",
      "2026-01-21 11:08:43,718 [INFO]         \"        all_gff_rows.append(gff_df)\\n\",\n",
      "2026-01-21 11:08:43,718 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,719 [INFO]         \"    if not all_gff_rows:\\n\",\n",
      "2026-01-21 11:08:43,719 [INFO]         \"        logging.error(\\\"No GFF files were successfully loaded.\\\")\\n\",\n",
      "2026-01-21 11:08:43,720 [INFO]         \"        sys.exit(1)\\n\",\n",
      "2026-01-21 11:08:43,721 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,721 [INFO]         \"    combined_gff = pd.concat(all_gff_rows, ignore_index=True)\\n\",\n",
      "2026-01-21 11:08:43,722 [INFO]         \"    logging.info(f\\\"Total CDS features loaded: {len(combined_gff)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,723 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,723 [INFO]         \"    return combined_gff\\n\",\n",
      "2026-01-21 11:08:43,723 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,724 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,724 [INFO]         \"def build_windows(anchor_df, window):\\n\",\n",
      "2026-01-21 11:08:43,725 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,725 [INFO]         \"    Build genomic windows (start, end) around anchor genes.\\n\",\n",
      "2026-01-21 11:08:43,725 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,726 [INFO]         \"    windows = []\\n\",\n",
      "2026-01-21 11:08:43,726 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,726 [INFO]         \"    for _, row in anchor_df.iterrows():\\n\",\n",
      "2026-01-21 11:08:43,727 [INFO]         \"        windows.append({\\n\",\n",
      "2026-01-21 11:08:43,727 [INFO]         \"            \\\"genome_id\\\": row[\\\"genome_id\\\"],\\n\",\n",
      "2026-01-21 11:08:43,727 [INFO]         \"            \\\"contig\\\": row[\\\"contig\\\"],\\n\",\n",
      "2026-01-21 11:08:43,728 [INFO]         \"            \\\"winstart\\\": row[\\\"gene_index\\\"] - window,\\n\",\n",
      "2026-01-21 11:08:43,729 [INFO]         \"            \\\"winend\\\": row[\\\"gene_index\\\"] + window,\\n\",\n",
      "2026-01-21 11:08:43,730 [INFO]         \"            \\\"wincenter\\\": row[\\\"gene_index\\\"],\\n\",\n",
      "2026-01-21 11:08:43,730 [INFO]         \"            \\\"protein_id\\\": row[\\\"protein_id\\\"],\\n\",\n",
      "2026-01-21 11:08:43,731 [INFO]         \"            \\\"architecture\\\": row[\\\"architecture\\\"],\\n\",\n",
      "2026-01-21 11:08:43,732 [INFO]         \"        })\\n\",\n",
      "2026-01-21 11:08:43,732 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,733 [INFO]         \"    return pd.DataFrame(windows)\\n\",\n",
      "2026-01-21 11:08:43,733 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,733 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,734 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,734 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,734 [INFO]         \"def merge_windows(windows_df):\\n\",\n",
      "2026-01-21 11:08:43,735 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,735 [INFO]         \"    Merge overlapping windows per genome/contig.\\n\",\n",
      "2026-01-21 11:08:43,735 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,736 [INFO]         \"    merged = []\\n\",\n",
      "2026-01-21 11:08:43,736 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,736 [INFO]         \"    for (genome, contig), grp in windows_df.groupby([\\\"genome_id\\\", \\\"contig\\\"]):\\n\",\n",
      "2026-01-21 11:08:43,736 [INFO]         \"        grp = grp.sort_values(\\\"winstart\\\")\\n\",\n",
      "2026-01-21 11:08:43,737 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,738 [INFO]         \"        cur_start = None\\n\",\n",
      "2026-01-21 11:08:43,738 [INFO]         \"        cur_end = None\\n\",\n",
      "2026-01-21 11:08:43,739 [INFO]         \"        cur_centers = []\\n\",\n",
      "2026-01-21 11:08:43,739 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,739 [INFO]         \"        for _, row in grp.iterrows():\\n\",\n",
      "2026-01-21 11:08:43,740 [INFO]         \"            if cur_start is None:\\n\",\n",
      "2026-01-21 11:08:43,740 [INFO]         \"                cur_start = row[\\\"winstart\\\"]\\n\",\n",
      "2026-01-21 11:08:43,741 [INFO]         \"                cur_end = row[\\\"winend\\\"]\\n\",\n",
      "2026-01-21 11:08:43,741 [INFO]         \"                cur_centers = [row]\\n\",\n",
      "2026-01-21 11:08:43,742 [INFO]         \"                continue\\n\",\n",
      "2026-01-21 11:08:43,742 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,742 [INFO]         \"            if row[\\\"winstart\\\"] <= cur_end + 1:\\n\",\n",
      "2026-01-21 11:08:43,743 [INFO]         \"                # overlap \\u2192 extend\\n\",\n",
      "2026-01-21 11:08:43,743 [INFO]         \"                cur_end = max(cur_end, row[\\\"winend\\\"])\\n\",\n",
      "2026-01-21 11:08:43,744 [INFO]         \"                cur_centers.append(row)\\n\",\n",
      "2026-01-21 11:08:43,744 [INFO]         \"            else:\\n\",\n",
      "2026-01-21 11:08:43,745 [INFO]         \"                merged.append({\\n\",\n",
      "2026-01-21 11:08:43,745 [INFO]         \"                    \\\"genome_id\\\": genome,\\n\",\n",
      "2026-01-21 11:08:43,745 [INFO]         \"                    \\\"contig\\\": contig,\\n\",\n",
      "2026-01-21 11:08:43,746 [INFO]         \"                    \\\"winstart\\\": cur_start,\\n\",\n",
      "2026-01-21 11:08:43,746 [INFO]         \"                    \\\"winend\\\": cur_end,\\n\",\n",
      "2026-01-21 11:08:43,747 [INFO]         \"                    \\\"anchors\\\": cur_centers\\n\",\n",
      "2026-01-21 11:08:43,747 [INFO]         \"                })\\n\",\n",
      "2026-01-21 11:08:43,748 [INFO]         \"                cur_start = row[\\\"winstart\\\"]\\n\",\n",
      "2026-01-21 11:08:43,748 [INFO]         \"                cur_end = row[\\\"winend\\\"]\\n\",\n",
      "2026-01-21 11:08:43,748 [INFO]         \"                cur_centers = [row]\\n\",\n",
      "2026-01-21 11:08:43,749 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,749 [INFO]         \"        merged.append({\\n\",\n",
      "2026-01-21 11:08:43,750 [INFO]         \"            \\\"genome_id\\\": genome,\\n\",\n",
      "2026-01-21 11:08:43,750 [INFO]         \"            \\\"contig\\\": contig,\\n\",\n",
      "2026-01-21 11:08:43,751 [INFO]         \"            \\\"winstart\\\": cur_start,\\n\",\n",
      "2026-01-21 11:08:43,751 [INFO]         \"            \\\"winend\\\": cur_end,\\n\",\n",
      "2026-01-21 11:08:43,751 [INFO]         \"            \\\"anchors\\\": cur_centers\\n\",\n",
      "2026-01-21 11:08:43,752 [INFO]         \"        })\\n\",\n",
      "2026-01-21 11:08:43,752 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,753 [INFO]         \"    return merged\\n\",\n",
      "2026-01-21 11:08:43,753 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,753 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,754 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,754 [INFO]         \"def extract_merged_neighborhoods(merged_windows, gff_df):\\n\",\n",
      "2026-01-21 11:08:43,754 [INFO]         \"    blocks = []\\n\",\n",
      "2026-01-21 11:08:43,755 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,755 [INFO]         \"    for win in merged_windows:\\n\",\n",
      "2026-01-21 11:08:43,756 [INFO]         \"        block = gff_df[\\n\",\n",
      "2026-01-21 11:08:43,757 [INFO]         \"            (gff_df[\\\"genome_id\\\"] == win[\\\"genome_id\\\"]) &\\n\",\n",
      "2026-01-21 11:08:43,757 [INFO]         \"            (gff_df[\\\"contig\\\"] == win[\\\"contig\\\"]) &\\n\",\n",
      "2026-01-21 11:08:43,757 [INFO]         \"            (gff_df[\\\"gene_index\\\"].between(win[\\\"winstart\\\"], win[\\\"winend\\\"]))\\n\",\n",
      "2026-01-21 11:08:43,758 [INFO]         \"        ].copy()\\n\",\n",
      "2026-01-21 11:08:43,758 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,759 [INFO]         \"        if block.empty:\\n\",\n",
      "2026-01-21 11:08:43,759 [INFO]         \"            continue\\n\",\n",
      "2026-01-21 11:08:43,759 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,760 [INFO]         \"        # pick a representative anchor (central-most)\\n\",\n",
      "2026-01-21 11:08:43,760 [INFO]         \"        centers = [a[\\\"wincenter\\\"] for a in win[\\\"anchors\\\"]]\\n\",\n",
      "2026-01-21 11:08:43,761 [INFO]         \"        rep_center = min(centers, key=lambda x: abs(x - (win[\\\"winstart\\\"] + win[\\\"winend\\\"]) / 2))\\n\",\n",
      "2026-01-21 11:08:43,761 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,761 [INFO]         \"        block[\\\"relative_pos\\\"] = block[\\\"gene_index\\\"] - rep_center\\n\",\n",
      "2026-01-21 11:08:43,762 [INFO]         \"        block[\\\"center_protein\\\"] = win[\\\"anchors\\\"][0][\\\"protein_id\\\"]\\n\",\n",
      "2026-01-21 11:08:43,762 [INFO]         \"        block[\\\"center_gene\\\"] = win[\\\"anchors\\\"][0][\\\"architecture\\\"]\\n\",\n",
      "2026-01-21 11:08:43,763 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,763 [INFO]         \"        blocks.append(block)\\n\",\n",
      "2026-01-21 11:08:43,764 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,764 [INFO]         \"    return pd.concat(blocks, ignore_index=True)\\n\",\n",
      "2026-01-21 11:08:43,764 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,765 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,765 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,765 [INFO]         \"def extract_neighborhoods(anchor_df, gff_df, window=5):\\n\",\n",
      "2026-01-21 11:08:43,766 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,766 [INFO]         \"    keywords = (\\\"vps\\\", \\\"escrt\\\", \\\"katanin\\\", \\\"eap\\\", \\\"flad\\\", \\\"zn-ph\\\")\\n\",\n",
      "2026-01-21 11:08:43,767 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,767 [INFO]         \"    logging.info(f\\\"Starting neighborhood extraction (\\u00b1{window} genes)\\\")\\n\",\n",
      "2026-01-21 11:08:43,768 [INFO]         \"    logging.info(f\\\"Initial anchors: {len(anchor_df)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,768 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,768 [INFO]         \"    filtered_anchors = anchor_df[\\n\",\n",
      "2026-01-21 11:08:43,769 [INFO]         \"        anchor_df[\\\"architecture\\\"]\\n\",\n",
      "2026-01-21 11:08:43,769 [INFO]         \"        .astype(str)\\n\",\n",
      "2026-01-21 11:08:43,770 [INFO]         \"        .str.lower()\\n\",\n",
      "2026-01-21 11:08:43,770 [INFO]         \"        .str.contains(\\\"|\\\".join(keywords))\\n\",\n",
      "2026-01-21 11:08:43,771 [INFO]         \"    ]\\n\",\n",
      "2026-01-21 11:08:43,771 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,771 [INFO]         \"    logging.info(f\\\"Anchors after ESCRT filter: {len(filtered_anchors)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,772 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,772 [INFO]         \"    if filtered_anchors.empty:\\n\",\n",
      "2026-01-21 11:08:43,773 [INFO]         \"        logging.error(\\\"No ESCRT-related anchors found\\\")\\n\",\n",
      "2026-01-21 11:08:43,773 [INFO]         \"        sys.exit(1)\\n\",\n",
      "2026-01-21 11:08:43,774 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,774 [INFO]         \"    windows_df = build_windows(filtered_anchors, window)\\n\",\n",
      "2026-01-21 11:08:43,774 [INFO]         \"    merged_windows = merge_windows(windows_df)\\n\",\n",
      "2026-01-21 11:08:43,775 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,775 [INFO]         \"    logging.info(\\n\",\n",
      "2026-01-21 11:08:43,775 [INFO]         \"        f\\\"Merged {len(windows_df)} anchor windows into \\\"\\n\",\n",
      "2026-01-21 11:08:43,776 [INFO]         \"        f\\\"{len(merged_windows)} non-overlapping regions\\\"\\n\",\n",
      "2026-01-21 11:08:43,776 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,777 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,777 [INFO]         \"    combined_neighborhoods = extract_merged_neighborhoods(\\n\",\n",
      "2026-01-21 11:08:43,778 [INFO]         \"        merged_windows, gff_df\\n\",\n",
      "2026-01-21 11:08:43,778 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,778 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,779 [INFO]         \"    logging.info(\\n\",\n",
      "2026-01-21 11:08:43,779 [INFO]         \"        f\\\"Extracted {len(combined_neighborhoods)} genes \\\"\\n\",\n",
      "2026-01-21 11:08:43,780 [INFO]         \"        f\\\"from {len(merged_windows)} merged neighborhoods\\\"\\n\",\n",
      "2026-01-21 11:08:43,780 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,780 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,781 [INFO]         \"    return combined_neighborhoods\\n\",\n",
      "2026-01-21 11:08:43,781 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,782 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,782 [INFO]         \"# ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,782 [INFO]         \"# Load GTDB taxonomy\\n\",\n",
      "2026-01-21 11:08:43,783 [INFO]         \"# ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,783 [INFO]         \"def load_gtdb_taxonomy(gtdb_tsv):\\n\",\n",
      "2026-01-21 11:08:43,783 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,783 [INFO]         \"    Load GTDB taxonomy file and split into rank-specific columns.\\n\",\n",
      "2026-01-21 11:08:43,784 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,785 [INFO]         \"    GTDB format: genome_id\\\\td__Domain;p__Phylum;c__Class;o__Order;f__Family;g__Genus;s__Species\\n\",\n",
      "2026-01-21 11:08:43,785 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,785 [INFO]         \"    Args:\\n\",\n",
      "2026-01-21 11:08:43,786 [INFO]         \"        gtdb_tsv: Path to GTDB taxonomy TSV file\\n\",\n",
      "2026-01-21 11:08:43,786 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:43,786 [INFO]         \"    Returns:\\n\",\n",
      "2026-01-21 11:08:43,787 [INFO]         \"        DataFrame with columns: genome_id, domain, phylum, class, order, family, genus, species\\n\",\n",
      "2026-01-21 11:08:43,788 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,788 [INFO]         \"    logging.info(f\\\"Loading GTDB taxonomy from: {gtdb_tsv}\\\")\\n\",\n",
      "2026-01-21 11:08:43,789 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,789 [INFO]         \"    # Read the taxonomy file\\n\",\n",
      "2026-01-21 11:08:43,790 [INFO]         \"    tax_df = pd.read_csv(\\n\",\n",
      "2026-01-21 11:08:43,790 [INFO]         \"        gtdb_tsv,\\n\",\n",
      "2026-01-21 11:08:43,791 [INFO]         \"        sep=\\\"\\\\t\\\",\\n\",\n",
      "2026-01-21 11:08:43,791 [INFO]         \"        header=None,\\n\",\n",
      "2026-01-21 11:08:43,791 [INFO]         \"        names=[\\\"genome_id\\\", \\\"taxonomy\\\"],\\n\",\n",
      "2026-01-21 11:08:43,792 [INFO]         \"        dtype=str\\n\",\n",
      "2026-01-21 11:08:43,792 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,792 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,793 [INFO]         \"    tax_df[\\\"genome_id_base\\\"] = tax_df[\\\"genome_id\\\"].str.split(\\\"_\\\", n=1).str[1]\\n\",\n",
      "2026-01-21 11:08:43,793 [INFO]         \"    logging.info(f\\\"Loaded taxonomy for {len(tax_df)} genomes\\\")\\n\",\n",
      "2026-01-21 11:08:43,793 [INFO]         \"    logging.info(f\\\"Sample taxonomy entry: {tax_df['taxonomy'].iloc[0]}\\\")\\n\",\n",
      "2026-01-21 11:08:43,794 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,795 [INFO]         \"    # Split taxonomy string by semicolons\\n\",\n",
      "2026-01-21 11:08:43,795 [INFO]         \"    tax_split = tax_df[\\\"taxonomy\\\"].str.split(\\\";\\\", expand=True)\\n\",\n",
      "2026-01-21 11:08:43,795 [INFO]         \"    logging.info(f\\\"Taxonomy split into {tax_split.shape[1]} columns\\\")\\n\",\n",
      "2026-01-21 11:08:43,796 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,796 [INFO]         \"    # Map column indices to taxonomic ranks\\n\",\n",
      "2026-01-21 11:08:43,797 [INFO]         \"    rank_map = {\\n\",\n",
      "2026-01-21 11:08:43,797 [INFO]         \"        0: \\\"domain\\\",\\n\",\n",
      "2026-01-21 11:08:43,798 [INFO]         \"        1: \\\"phylum\\\",\\n\",\n",
      "2026-01-21 11:08:43,798 [INFO]         \"        2: \\\"class\\\",\\n\",\n",
      "2026-01-21 11:08:43,799 [INFO]         \"        3: \\\"order\\\",\\n\",\n",
      "2026-01-21 11:08:43,799 [INFO]         \"        4: \\\"family\\\",\\n\",\n",
      "2026-01-21 11:08:43,799 [INFO]         \"        5: \\\"genus\\\",\\n\",\n",
      "2026-01-21 11:08:43,800 [INFO]         \"        6: \\\"species\\\"\\n\",\n",
      "2026-01-21 11:08:43,800 [INFO]         \"    }\\n\",\n",
      "2026-01-21 11:08:43,800 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,801 [INFO]         \"    # Extract each rank and remove the prefix (e.g., \\\"d__\\\", \\\"p__\\\")\\n\",\n",
      "2026-01-21 11:08:43,801 [INFO]         \"    for idx, rank in rank_map.items():\\n\",\n",
      "2026-01-21 11:08:43,802 [INFO]         \"        if idx < tax_split.shape[1]:\\n\",\n",
      "2026-01-21 11:08:43,802 [INFO]         \"            # Remove the rank prefix using regex (e.g., \\\"p__\\\" from \\\"p__Crenarchaeota\\\")\\n\",\n",
      "2026-01-21 11:08:43,803 [INFO]         \"            tax_df[rank] = tax_split[idx].str.replace(r\\\"^[a-z]__\\\", \\\"\\\", regex=True)\\n\",\n",
      "2026-01-21 11:08:43,803 [INFO]         \"            logging.info(f\\\"Extracted {rank}: {tax_df[rank].notna().sum()} non-null values\\\")\\n\",\n",
      "2026-01-21 11:08:43,804 [INFO]         \"        else:\\n\",\n",
      "2026-01-21 11:08:43,804 [INFO]         \"            tax_df[rank] = pd.NA\\n\",\n",
      "2026-01-21 11:08:43,805 [INFO]         \"            logging.warning(f\\\"Column {idx} for rank '{rank}' not found in taxonomy data\\\")\\n\",\n",
      "2026-01-21 11:08:43,805 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,805 [INFO]         \"    # Drop the original concatenated taxonomy string\\n\",\n",
      "2026-01-21 11:08:43,806 [INFO]         \"    tax_df.drop(columns=[\\\"taxonomy\\\"], inplace=True)\\n\",\n",
      "2026-01-21 11:08:43,806 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,807 [INFO]         \"    # Log sample of parsed taxonomy\\n\",\n",
      "2026-01-21 11:08:43,807 [INFO]         \"    logging.info(f\\\"Sample parsed taxonomy:\\\")\\n\",\n",
      "2026-01-21 11:08:43,807 [INFO]         \"    logging.info(tax_df[[\\\"genome_id\\\", \\\"domain\\\", \\\"phylum\\\", \\\"class\\\"]].head().to_string())\\n\",\n",
      "2026-01-21 11:08:43,808 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,808 [INFO]         \"    return tax_df\\n\",\n",
      "2026-01-21 11:08:43,808 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,809 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,809 [INFO]         \"# ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,810 [INFO]         \"# Merge taxonomy into neighborhood data\\n\",\n",
      "2026-01-21 11:08:43,810 [INFO]         \"# ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,810 [INFO]         \"def merge_taxonomy(escrt_csv, gtdb_tsv, out_csv):\\n\",\n",
      "2026-01-21 11:08:43,811 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,811 [INFO]         \"    Merge GTDB taxonomy into ESCRT neighborhood dataframe.\\n\",\n",
      "2026-01-21 11:08:43,811 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,812 [INFO]         \"    Args:\\n\",\n",
      "2026-01-21 11:08:43,813 [INFO]         \"        escrt_csv: Path to ESCRT neighborhoods CSV\\n\",\n",
      "2026-01-21 11:08:43,813 [INFO]         \"        gtdb_tsv: Path to GTDB taxonomy TSV\\n\",\n",
      "2026-01-21 11:08:43,814 [INFO]         \"        out_csv: Output path for merged CSV\\n\",\n",
      "2026-01-21 11:08:43,814 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:43,815 [INFO]         \"    Returns:\\n\",\n",
      "2026-01-21 11:08:43,815 [INFO]         \"        Merged DataFrame with taxonomy columns added\\n\",\n",
      "2026-01-21 11:08:43,815 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,816 [INFO]         \"    logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,816 [INFO]         \"    logging.info(\\\"STARTING TAXONOMY MERGE\\\")\\n\",\n",
      "2026-01-21 11:08:43,816 [INFO]         \"    logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,817 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,817 [INFO]         \"    # Load neighborhood data\\n\",\n",
      "2026-01-21 11:08:43,818 [INFO]         \"    logging.info(f\\\"Loading neighborhood data from: {escrt_csv}\\\")\\n\",\n",
      "2026-01-21 11:08:43,818 [INFO]         \"    escrt_df = pd.read_csv(escrt_csv)\\n\",\n",
      "2026-01-21 11:08:43,818 [INFO]         \"    escrt_df['genome_id_base'] = (\\n\",\n",
      "2026-01-21 11:08:43,819 [INFO]         \"    escrt_df['genome_id']\\n\",\n",
      "2026-01-21 11:08:43,819 [INFO]         \"    .str.split(\\\"_\\\", n=2)\\n\",\n",
      "2026-01-21 11:08:43,819 [INFO]         \"    .str[0:2]\\n\",\n",
      "2026-01-21 11:08:43,820 [INFO]         \"    .str.join(\\\"_\\\")\\n\",\n",
      "2026-01-21 11:08:43,820 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:43,820 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,821 [INFO]         \"    logging.info(f\\\"Neighborhood data: {len(escrt_df)} rows, {len(escrt_df['genome_id'].unique())} unique genomes\\\")\\n\",\n",
      "2026-01-21 11:08:43,822 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,823 [INFO]         \"    # Load taxonomy data\\n\",\n",
      "2026-01-21 11:08:43,823 [INFO]         \"    tax_df = load_gtdb_taxonomy(gtdb_tsv)\\n\",\n",
      "2026-01-21 11:08:43,823 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,824 [INFO]         \"    # Check for overlap between datasets\\n\",\n",
      "2026-01-21 11:08:43,824 [INFO]         \"    escrt_genomes = set(escrt_df[\\\"genome_id_base\\\"].unique())\\n\",\n",
      "2026-01-21 11:08:43,824 [INFO]         \"    tax_genomes = set(tax_df[\\\"genome_id_base\\\"].unique())\\n\",\n",
      "2026-01-21 11:08:43,825 [INFO]         \"    overlap = escrt_genomes.intersection(tax_genomes)\\n\",\n",
      "2026-01-21 11:08:43,825 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,825 [INFO]         \"    logging.info(f\\\"Genome ID overlap check:\\\")\\n\",\n",
      "2026-01-21 11:08:43,826 [INFO]         \"    logging.info(f\\\"  Genomes in neighborhood data: {len(escrt_genomes)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,826 [INFO]         \"    logging.info(f\\\"  Genomes in taxonomy data: {len(tax_genomes)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,827 [INFO]         \"    logging.info(f\\\"  Overlapping genomes: {len(overlap)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,828 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,828 [INFO]         \"    if len(overlap) == 0:\\n\",\n",
      "2026-01-21 11:08:43,828 [INFO]         \"        logging.error(\\\"NO OVERLAP between genome IDs!\\\")\\n\",\n",
      "2026-01-21 11:08:43,829 [INFO]         \"        logging.error(f\\\"Sample neighborhood genome IDs: {list(escrt_genomes)[:5]}\\\")\\n\",\n",
      "2026-01-21 11:08:43,829 [INFO]         \"        logging.error(f\\\"Sample taxonomy genome IDs: {list(tax_genomes)[:5]}\\\")\\n\",\n",
      "2026-01-21 11:08:43,829 [INFO]         \"        logging.error(\\\"Check if genome_id formats match between files!\\\")\\n\",\n",
      "2026-01-21 11:08:43,830 [INFO]         \"        sys.exit(1)\\n\",\n",
      "2026-01-21 11:08:43,830 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,831 [INFO]         \"    if len(overlap) < len(escrt_genomes):\\n\",\n",
      "2026-01-21 11:08:43,831 [INFO]         \"        missing = len(escrt_genomes) - len(overlap)\\n\",\n",
      "2026-01-21 11:08:43,831 [INFO]         \"        logging.warning(f\\\"{missing} genomes from neighborhood data not found in taxonomy!\\\")\\n\",\n",
      "2026-01-21 11:08:43,832 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,832 [INFO]         \"    # Perform the merge\\n\",\n",
      "2026-01-21 11:08:43,833 [INFO]         \"    logging.info(\\\"Performing left join on genome_id...\\\")\\n\",\n",
      "2026-01-21 11:08:43,833 [INFO]         \"    merged = escrt_df.merge(\\n\",\n",
      "2026-01-21 11:08:43,833 [INFO]         \"        tax_df,\\n\",\n",
      "2026-01-21 11:08:43,834 [INFO]         \"        on=\\\"genome_id_base\\\",\\n\",\n",
      "2026-01-21 11:08:43,834 [INFO]         \"        how=\\\"left\\\"\\n\",\n",
      "2026-01-21 11:08:43,835 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,835 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,835 [INFO]         \"    # Validate merge results\\n\",\n",
      "2026-01-21 11:08:43,836 [INFO]         \"    logging.info(f\\\"Merge complete: {len(merged)} rows\\\")\\n\",\n",
      "2026-01-21 11:08:43,836 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,836 [INFO]         \"    # Check how many rows got taxonomy data\\n\",\n",
      "2026-01-21 11:08:43,837 [INFO]         \"    tax_columns = [\\\"domain\\\", \\\"phylum\\\", \\\"class\\\", \\\"order\\\", \\\"family\\\", \\\"genus\\\", \\\"species\\\"]\\n\",\n",
      "2026-01-21 11:08:43,837 [INFO]         \"    for col in tax_columns:\\n\",\n",
      "2026-01-21 11:08:43,838 [INFO]         \"        non_null = merged[col].notna().sum()\\n\",\n",
      "2026-01-21 11:08:43,838 [INFO]         \"        pct = (non_null / len(merged)) * 100\\n\",\n",
      "2026-01-21 11:08:43,838 [INFO]         \"        logging.info(f\\\"  {col}: {non_null} non-null ({pct:.1f}%)\\\")\\n\",\n",
      "2026-01-21 11:08:43,839 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,839 [INFO]         \"    # Save to CSV\\n\",\n",
      "2026-01-21 11:08:43,839 [INFO]         \"    logging.info(f\\\"Saving merged data to: {out_csv}\\\")\\n\",\n",
      "2026-01-21 11:08:43,840 [INFO]         \"    merged.to_csv(out_csv, index=False)\\n\",\n",
      "2026-01-21 11:08:43,840 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,841 [INFO]         \"    # Show sample of merged data\\n\",\n",
      "2026-01-21 11:08:43,841 [INFO]         \"    logging.info(\\\"Sample of merged data with taxonomy:\\\")\\n\",\n",
      "2026-01-21 11:08:43,842 [INFO]         \"    sample_cols = [\\\"genome_id\\\", \\\"protein_id\\\", \\\"domain\\\", \\\"phylum\\\", \\\"class\\\", \\\"order\\\"]\\n\",\n",
      "2026-01-21 11:08:43,842 [INFO]         \"    available_cols = [col for col in sample_cols if col in merged.columns]\\n\",\n",
      "2026-01-21 11:08:43,843 [INFO]         \"    logging.info(merged[available_cols].head(10).to_string())\\n\",\n",
      "2026-01-21 11:08:43,843 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,844 [INFO]         \"    logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,844 [INFO]         \"    logging.info(\\\"TAXONOMY MERGE COMPLETE\\\")\\n\",\n",
      "2026-01-21 11:08:43,845 [INFO]         \"    logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,845 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,845 [INFO]         \"    return merged\\n\",\n",
      "2026-01-21 11:08:43,846 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,846 [INFO]         \"\\n\"\n",
      "2026-01-21 11:08:43,846 [INFO]       ]\n",
      "2026-01-21 11:08:43,847 [INFO]     },\n",
      "2026-01-21 11:08:43,847 [INFO]     {\n",
      "2026-01-21 11:08:43,848 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:43,848 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:43,849 [INFO]       \"id\": \"d774e625\",\n",
      "2026-01-21 11:08:43,849 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:43,851 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:43,852 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:43,852 [INFO]         \"from pathlib import Path\\n\",\n",
      "2026-01-21 11:08:43,853 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,853 [INFO]         \"# ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,853 [INFO]         \"# Main pipeline\\n\",\n",
      "2026-01-21 11:08:43,854 [INFO]         \"# ------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,854 [INFO]         \"def run_synteny_pipeline(\\n\",\n",
      "2026-01-21 11:08:43,854 [INFO]         \"    hits_df,\\n\",\n",
      "2026-01-21 11:08:43,855 [INFO]         \"    gff_dir,\\n\",\n",
      "2026-01-21 11:08:43,855 [INFO]         \"    window=5,\\n\",\n",
      "2026-01-21 11:08:43,855 [INFO]         \"    min_coverage=0.65,\\n\",\n",
      "2026-01-21 11:08:43,856 [INFO]         \"    max_i_evalue=1e-5,\\n\",\n",
      "2026-01-21 11:08:43,857 [INFO]         \"):\\n\",\n",
      "2026-01-21 11:08:43,857 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,858 [INFO]         \"    logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,858 [INFO]         \"    logging.info(\\\"STARTING SYNTENY PIPELINE\\\")\\n\",\n",
      "2026-01-21 11:08:43,858 [INFO]         \"    logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,859 [INFO]         \"    logging.info(f\\\"Hits DataFrame: {hits_df}\\\")\\n\",\n",
      "2026-01-21 11:08:43,860 [INFO]         \"    logging.info(f\\\"GFF directory: {gff_dir}\\\")\\n\",\n",
      "2026-01-21 11:08:43,860 [INFO]         \"    logging.info(f\\\"Window size: \\u00b1{window} genes\\\")\\n\",\n",
      "2026-01-21 11:08:43,860 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,861 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,861 [INFO]         \"    gff_dir = Path(gff_dir)\\n\",\n",
      "2026-01-21 11:08:43,861 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,861 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,862 [INFO]         \"    # --------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,862 [INFO]         \"    # Load GFFs\\n\",\n",
      "2026-01-21 11:08:43,862 [INFO]         \"    # --------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,863 [INFO]         \"    logging.info(\\\"\\\\n[STEP 1] Loading GFF files...\\\")\\n\",\n",
      "2026-01-21 11:08:43,863 [INFO]         \"    gff_df = load_gffs_from_hits(hits_df, gff_dir)\\n\",\n",
      "2026-01-21 11:08:43,864 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,865 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,865 [INFO]         \"    gff_df.to_csv(os.path.join(MAIN_OUTDIR, f\\\"[STEP:{STEP}.5]gff_dataframe_{rightnow}.csv\\\"), index=False)\\n\",\n",
      "2026-01-21 11:08:43,866 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,866 [INFO]         \"    # --------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,866 [INFO]         \"    # Map anchor hits to gene order\\n\",\n",
      "2026-01-21 11:08:43,867 [INFO]         \"    # --------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,867 [INFO]         \"    logging.info(\\\"\\\\n[STEP 2] Mapping hits to gene order...\\\")\\n\",\n",
      "2026-01-21 11:08:43,868 [INFO]         \"    anchor_df = hits_df.merge(\\n\",\n",
      "2026-01-21 11:08:43,868 [INFO]         \"        gff_df,\\n\",\n",
      "2026-01-21 11:08:43,868 [INFO]         \"        left_on=\\\"target\\\",\\n\",\n",
      "2026-01-21 11:08:43,869 [INFO]         \"        right_on=\\\"protein_id\\\",\\n\",\n",
      "2026-01-21 11:08:43,869 [INFO]         \"        how=\\\"inner\\\"\\n\",\n",
      "2026-01-21 11:08:43,869 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,870 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,871 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,871 [INFO]         \"    if anchor_df.empty:\\n\",\n",
      "2026-01-21 11:08:43,871 [INFO]         \"        logging.error(\\\"No hits could be mapped to GFFs (protein ID mismatch?)\\\")\\n\",\n",
      "2026-01-21 11:08:43,871 [INFO]         \"        sys.exit(1)\\n\",\n",
      "2026-01-21 11:08:43,872 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,872 [INFO]         \"    protein_to_arch = (\\n\",\n",
      "2026-01-21 11:08:43,873 [INFO]         \"    anchor_df\\n\",\n",
      "2026-01-21 11:08:43,873 [INFO]         \"    .drop_duplicates(\\\"protein_id\\\")\\n\",\n",
      "2026-01-21 11:08:43,874 [INFO]         \"    .set_index(\\\"protein_id\\\")[\\\"architecture\\\"]\\n\",\n",
      "2026-01-21 11:08:43,874 [INFO]         \"    .to_dict()\\n\",\n",
      "2026-01-21 11:08:43,875 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,875 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,875 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,876 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,876 [INFO]         \"    # --------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,877 [INFO]         \"    # Extract neighborhoods\\n\",\n",
      "2026-01-21 11:08:43,877 [INFO]         \"    # --------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,877 [INFO]         \"    logging.info(\\\"\\\\n[STEP 3] Extracting gene neighborhoods...\\\")\\n\",\n",
      "2026-01-21 11:08:43,878 [INFO]         \"    neigh_df = extract_neighborhoods(anchor_df, gff_df, window=window)\\n\",\n",
      "2026-01-21 11:08:43,878 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,879 [INFO]         \"    # --------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,879 [INFO]         \"    # Annotate EACH neighbor with its own query identity\\n\",\n",
      "2026-01-21 11:08:43,879 [INFO]         \"    # --------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,880 [INFO]         \"    logging.info(\\\"\\\\n[STEP 4] Annotating neighbors with query IDs...\\\")\\n\",\n",
      "2026-01-21 11:08:43,880 [INFO]         \"    neigh_df[\\\"neighbor_architecture\\\"] = neigh_df[\\\"protein_id\\\"].map(protein_to_arch)\\n\",\n",
      "2026-01-21 11:08:43,881 [INFO]         \"    neigh_df[\\\"is_target_family\\\"] = neigh_df[\\\"neighbor_architecture\\\"].notna()\\n\",\n",
      "2026-01-21 11:08:43,881 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,882 [INFO]         \"    # Debug: Check neighbor_query values\\n\",\n",
      "2026-01-21 11:08:43,882 [INFO]         \"    logging.info(f\\\"Total genes in neighborhoods: {len(neigh_df)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,882 [INFO]         \"    logging.info(f\\\"Genes with neighbor_query annotation: {neigh_df['neighbor_architecture'].notna().sum()}\\\")\\n\",\n",
      "2026-01-21 11:08:43,883 [INFO]         \"    logging.info(f\\\"Sample neighbor_query values: {neigh_df['neighbor_architecture'].dropna().unique()[:10].tolist()}\\\")\\n\",\n",
      "2026-01-21 11:08:43,883 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,884 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,884 [INFO]         \"    # --------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,884 [INFO]         \"    # Merge center gene annotations - WITH DEBUGGING\\n\",\n",
      "2026-01-21 11:08:43,885 [INFO]         \"    # --------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,885 [INFO]         \"    logging.info(\\\"\\\\n[STEP 5] Merging center gene AsCOG annotations...\\\")\\n\",\n",
      "2026-01-21 11:08:43,886 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,886 [INFO]         \"    # Strip whitespace from center_gene\\n\",\n",
      "2026-01-21 11:08:43,886 [INFO]         \"    neigh_df[\\\"center_gene\\\"] = neigh_df[\\\"center_gene\\\"].str.strip()\\n\",\n",
      "2026-01-21 11:08:43,887 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,887 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,888 [INFO]         \"    logging.info(\\n\",\n",
      "2026-01-21 11:08:43,888 [INFO]         \"        f\\\"\\\\nAnnotated neighborhoods: {len(neigh_df)} total genes\\\"\\n\",\n",
      "2026-01-21 11:08:43,888 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,889 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,889 [INFO]         \"    logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,890 [INFO]         \"    logging.info(\\\"SYNTENY PIPELINE COMPLETED SUCCESSFULLY\\\")\\n\",\n",
      "2026-01-21 11:08:43,890 [INFO]         \"    logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,891 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,891 [INFO]         \"    return neigh_df, anchor_df\\n\",\n",
      "2026-01-21 11:08:43,892 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,892 [INFO]         \"\\n\"\n",
      "2026-01-21 11:08:43,893 [INFO]       ]\n",
      "2026-01-21 11:08:43,893 [INFO]     },\n",
      "2026-01-21 11:08:43,893 [INFO]     {\n",
      "2026-01-21 11:08:43,894 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:43,894 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:43,895 [INFO]       \"id\": \"5f56369a\",\n",
      "2026-01-21 11:08:43,895 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:43,896 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:43,896 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:43,896 [INFO]         \"# Run the main synteny pipeline\\n\",\n",
      "2026-01-21 11:08:43,897 [INFO]         \"neigh_df, anchor_df = run_synteny_pipeline(\\n\",\n",
      "2026-01-21 11:08:43,897 [INFO]         \"    hits_df = df_with_arch,\\n\",\n",
      "2026-01-21 11:08:43,897 [INFO]         \"    gff_dir=\\\"/home/anirudh/genomes/selected_genomes/prokka_results\\\",\\n\",\n",
      "2026-01-21 11:08:43,898 [INFO]         \"    window=5,\\n\",\n",
      "2026-01-21 11:08:43,898 [INFO]         \"    min_coverage=0.65,\\n\",\n",
      "2026-01-21 11:08:43,898 [INFO]         \"    max_i_evalue=1e-5,\\n\",\n",
      "2026-01-21 11:08:43,899 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:43,899 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,900 [INFO]         \"# Quick sanity checks\\n\",\n",
      "2026-01-21 11:08:43,900 [INFO]         \"logging.info(\\\"\\\\n\\\" + \\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,900 [INFO]         \"logging.info(\\\"PIPELINE OUTPUT SUMMARY\\\")\\n\",\n",
      "2026-01-21 11:08:43,901 [INFO]         \"logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,902 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,902 [INFO]         \"logging.info(\\\"\\\\nAnchor gene Architecture distribution:\\\")\\n\",\n",
      "2026-01-21 11:08:43,902 [INFO]         \"logging.info(anchor_df[\\\"architecture\\\"].value_counts().to_string())\\n\",\n",
      "2026-01-21 11:08:43,903 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,903 [INFO]         \"logging.info(\\\"\\\\nFirst few neighborhood entries:\\\")\\n\",\n",
      "2026-01-21 11:08:43,904 [INFO]         \"logging.info(neigh_df.head().to_string())\\n\",\n",
      "2026-01-21 11:08:43,904 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,904 [INFO]         \"logging.info(\\\"\\\\nGenome distribution:\\\")\\n\",\n",
      "2026-01-21 11:08:43,905 [INFO]         \"logging.info(neigh_df['genome_id'].value_counts().to_string())\\n\",\n",
      "2026-01-21 11:08:43,905 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,906 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,906 [INFO]         \"# Save intermediate results\\n\",\n",
      "2026-01-21 11:08:43,906 [INFO]         \"logging.info(\\\"\\\\nSaving neighborhood data...\\\")\\n\",\n",
      "2026-01-21 11:08:43,907 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:43,907 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,907 [INFO]         \"escrt_nieghborhoods_file = os.path.join(MAIN_OUTDIR, f\\\"[STEP:{STEP}]escrt_neighborhoods_{rightnow}.csv\\\")\\n\",\n",
      "2026-01-21 11:08:43,907 [INFO]         \"neigh_df.to_csv(escrt_nieghborhoods_file, index=False)\\n\",\n",
      "2026-01-21 11:08:43,908 [INFO]         \"logging.info(f\\\"Saved: [STEP:{STEP}]escrt_neighborhoods_{rightnow}.csv\\\")\\n\",\n",
      "2026-01-21 11:08:43,908 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,908 [INFO]         \"logging.info(\\\"Saving anchor hits...\\\")\\n\",\n",
      "2026-01-21 11:08:43,909 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:43,909 [INFO]         \"anchor_df.to_csv(os.path.join(MAIN_OUTDIR, f\\\"[STEP:{STEP}]escrt_anchor_hits_{rightnow}.csv\\\"), index=False)\\n\",\n",
      "2026-01-21 11:08:43,910 [INFO]         \"logging.info(f\\\"Saved: [STEP:{STEP}]escrt_anchor_hits_{rightnow}.csv\\\")\\n\",\n",
      "2026-01-21 11:08:43,911 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,912 [INFO]         \"# Merge with taxonomy\\n\",\n",
      "2026-01-21 11:08:43,912 [INFO]         \"logging.info(\\\"\\\\n\\\" + \\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,912 [INFO]         \"logging.info(\\\"ADDING TAXONOMY INFORMATION\\\")\\n\",\n",
      "2026-01-21 11:08:43,913 [INFO]         \"logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,913 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,913 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:43,914 [INFO]         \"out_csv = os.path.join(MAIN_OUTDIR, f\\\"[STEP:{STEP}]escrt_neighborhoods_with_taxonomy_{rightnow}.csv\\\")\\n\",\n",
      "2026-01-21 11:08:43,914 [INFO]         \"df = merge_taxonomy(\\n\",\n",
      "2026-01-21 11:08:43,915 [INFO]         \"    escrt_nieghborhoods_file, \\n\",\n",
      "2026-01-21 11:08:43,915 [INFO]         \"    \\\"/home/anirudh/synteny/ar53_taxonomy_r226.tsv\\\", \\n\",\n",
      "2026-01-21 11:08:43,916 [INFO]         \"    out_csv\\n\",\n",
      "2026-01-21 11:08:43,916 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:43,916 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,917 [INFO]         \"# Show taxonomic diversity in results   \\n\",\n",
      "2026-01-21 11:08:43,917 [INFO]         \"logging.info(\\\"\\\\nTaxonomic diversity in results:\\\")\\n\",\n",
      "2026-01-21 11:08:43,918 [INFO]         \"logging.info(f\\\"Unique phyla: {df['phylum'].nunique()}\\\")\\n\",\n",
      "2026-01-21 11:08:43,918 [INFO]         \"logging.info(f\\\"Unique classes: {df['class'].nunique()}\\\") \\n\",\n",
      "2026-01-21 11:08:43,918 [INFO]         \"logging.info(f\\\"Unique orders: {df['order'].nunique()}\\\")\\n\",\n",
      "2026-01-21 11:08:43,919 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,919 [INFO]         \"logging.info(\\\"\\\\nSample genomes with taxonomy:\\\")\\n\",\n",
      "2026-01-21 11:08:43,920 [INFO]         \"logging.info(df[[\\\"genome_id_base\\\", \\\"phylum\\\", \\\"class\\\", \\\"order\\\"]].drop_duplicates().head(10).to_string())\\n\",\n",
      "2026-01-21 11:08:43,920 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,921 [INFO]         \"logging.info(\\\"\\\\n\\\" + \\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,921 [INFO]         \"logging.info(\\\"ALL PROCESSING COMPLETE\\\")\\n\",\n",
      "2026-01-21 11:08:43,921 [INFO]         \"logging.info(\\\"=\\\" * 70)\"\n",
      "2026-01-21 11:08:43,922 [INFO]       ]\n",
      "2026-01-21 11:08:43,922 [INFO]     },\n",
      "2026-01-21 11:08:43,923 [INFO]     {\n",
      "2026-01-21 11:08:43,923 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:43,924 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:43,924 [INFO]       \"id\": \"bc91f487\",\n",
      "2026-01-21 11:08:43,925 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:43,925 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:43,926 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:43,926 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,926 [INFO]         \"# DIAGNOSTIC: Check which architectures would be filtered by keywords\\n\",\n",
      "2026-01-21 11:08:43,927 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,927 [INFO]         \"keywords = (\\\"vps\\\", \\\"escrt\\\", \\\"katanin\\\", \\\"eap\\\", \\\"flad\\\")\\n\",\n",
      "2026-01-21 11:08:43,928 [INFO]         \"keyword_pattern = \\\"|\\\".join(keywords)\\n\",\n",
      "2026-01-21 11:08:43,928 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,928 [INFO]         \"# Create a boolean mask for architectures matching keywords\\n\",\n",
      "2026-01-21 11:08:43,929 [INFO]         \"matches_keywords = (\\n\",\n",
      "2026-01-21 11:08:43,929 [INFO]         \"    df_with_arch[\\\"architecture\\\"]\\n\",\n",
      "2026-01-21 11:08:43,929 [INFO]         \"    .astype(str)\\n\",\n",
      "2026-01-21 11:08:43,930 [INFO]         \"    .str.lower()\\n\",\n",
      "2026-01-21 11:08:43,930 [INFO]         \"    .str.contains(keyword_pattern)\\n\",\n",
      "2026-01-21 11:08:43,931 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:43,931 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,931 [INFO]         \"# Count what would be kept vs discarded\\n\",\n",
      "2026-01-21 11:08:43,932 [INFO]         \"kept_count = matches_keywords.sum()\\n\",\n",
      "2026-01-21 11:08:43,933 [INFO]         \"discarded_count = (~matches_keywords).sum()\\n\",\n",
      "2026-01-21 11:08:43,933 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,933 [INFO]         \"logging.info(\\\"\\\\n\\\" + \\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,934 [INFO]         \"logging.info(\\\"ARCHITECTURE FILTERING DIAGNOSTIC\\\")\\n\",\n",
      "2026-01-21 11:08:43,934 [INFO]         \"logging.info(\\\"=\\\" * 70)\\n\",\n",
      "2026-01-21 11:08:43,934 [INFO]         \"logging.info(f\\\"Total proteins with valid HMM hits (i_evalue \\u2264 1e-5, coverage \\u2265 0.65): {len(df_with_arch)}\\\")\\n\",\n",
      "2026-01-21 11:08:43,935 [INFO]         \"logging.info(f\\\"Proteins with architectures matching keywords: {kept_count}\\\")\\n\",\n",
      "2026-01-21 11:08:43,935 [INFO]         \"logging.info(f\\\"Proteins with architectures NOT matching keywords: {discarded_count}\\\")\\n\",\n",
      "2026-01-21 11:08:43,936 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,936 [INFO]         \"if discarded_count > 0:\\n\",\n",
      "2026-01-21 11:08:43,937 [INFO]         \"    logging.warning(f\\\"\\\\n\\u26a0\\ufe0f  WARNING: {discarded_count} proteins will be EXCLUDED from neighborhoods:\\\")\\n\",\n",
      "2026-01-21 11:08:43,937 [INFO]         \"    excluded = df_with_arch[~matches_keywords][[\\\"target\\\", \\\"architecture\\\"]].drop_duplicates()\\n\",\n",
      "2026-01-21 11:08:43,937 [INFO]         \"    logging.warning(excluded.head(20).to_string())\\n\",\n",
      "2026-01-21 11:08:43,938 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,938 [INFO]         \"    # Count distribution of excluded architectures\\n\",\n",
      "2026-01-21 11:08:43,939 [INFO]         \"    logging.warning(\\\"\\\\nDistribution of excluded architectures:\\\")\\n\",\n",
      "2026-01-21 11:08:43,939 [INFO]         \"    arch_counts = df_with_arch[~matches_keywords][\\\"architecture\\\"].value_counts()\\n\",\n",
      "2026-01-21 11:08:43,939 [INFO]         \"    logging.warning(arch_counts.head(20).to_string())\\n\",\n",
      "2026-01-21 11:08:43,940 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:43,940 [INFO]         \"    # Save for review\\n\",\n",
      "2026-01-21 11:08:43,941 [INFO]         \"    excluded_file = os.path.join(MAIN_OUTDIR, f\\\"[DIAGNOSTIC]excluded_proteins_by_keyword_filter_{rightnow}.csv\\\")\\n\",\n",
      "2026-01-21 11:08:43,941 [INFO]         \"    df_with_arch[~matches_keywords][[\\\"target\\\", \\\"architecture\\\", \\\"architecture_method\\\"]].drop_duplicates().sort_values(by = ['architecture'], ascending=False).to_csv(excluded_file, index=False)\\n\",\n",
      "2026-01-21 11:08:43,942 [INFO]         \"    logging.warning(f\\\"\\\\nSaved excluded proteins to: {excluded_file}\\\")\\n\",\n",
      "2026-01-21 11:08:43,942 [INFO]         \"else:\\n\",\n",
      "2026-01-21 11:08:43,942 [INFO]         \"    logging.info(\\\"\\u2713 All proteins with valid hits match keyword filter - no data loss\\\")\\n\",\n",
      "2026-01-21 11:08:43,943 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,943 [INFO]         \"logging.info(\\\"=\\\" * 70)\"\n",
      "2026-01-21 11:08:43,943 [INFO]       ]\n",
      "2026-01-21 11:08:43,944 [INFO]     },\n",
      "2026-01-21 11:08:43,945 [INFO]     {\n",
      "2026-01-21 11:08:43,945 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:43,945 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:43,946 [INFO]       \"id\": \"2328c7a0\",\n",
      "2026-01-21 11:08:43,946 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:43,946 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:43,947 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:43,947 [INFO]         \"# Architecture Analysis\\n\",\n",
      "2026-01-21 11:08:43,948 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,948 [INFO]         \"#!/usr/bin/env python3\\n\",\n",
      "2026-01-21 11:08:43,949 [INFO]         \"\\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,949 [INFO]         \"Architecture analysis and reduction script (orientation-invariant)\\n\",\n",
      "2026-01-21 11:08:43,949 [INFO]         \"=================================================================\\n\",\n",
      "2026-01-21 11:08:43,950 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,950 [INFO]         \"Input:\\n\",\n",
      "2026-01-21 11:08:43,950 [INFO]         \"  - Annotated neighborhood CSV with taxonomy and architecture labels\\n\",\n",
      "2026-01-21 11:08:43,951 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,951 [INFO]         \"Output:\\n\",\n",
      "2026-01-21 11:08:43,951 [INFO]         \"  - Contig-level trimmed & canonical architectures\\n\",\n",
      "2026-01-21 11:08:43,952 [INFO]         \"  - Lineage-level architecture counts (inverse + subtuple collapsed)\\n\",\n",
      "2026-01-21 11:08:43,952 [INFO]         \"  - Representative contigs per lineage\\n\",\n",
      "2026-01-21 11:08:43,952 [INFO]         \"  - Gene-level dataframe for plotting\\n\",\n",
      "2026-01-21 11:08:43,953 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,953 [INFO]         \"Key features:\\n\",\n",
      "2026-01-21 11:08:43,954 [INFO]         \"  - Flank trimming (k=2)\\n\",\n",
      "2026-01-21 11:08:43,954 [INFO]         \"  - Orientation-invariant (inverse) collapsing\\n\",\n",
      "2026-01-21 11:08:43,954 [INFO]         \"  - Counts incorporate reversed architectures\\n\",\n",
      "2026-01-21 11:08:43,955 [INFO]         \"  - Subtuple matching for architecture equivalence\\n\",\n",
      "2026-01-21 11:08:43,955 [INFO]         \"\\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,956 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,957 [INFO]         \"import pandas as pd\\n\",\n",
      "2026-01-21 11:08:43,957 [INFO]         \"import logging\\n\",\n",
      "2026-01-21 11:08:43,958 [INFO]         \"import os\\n\",\n",
      "2026-01-21 11:08:43,958 [INFO]         \"from pathlib import Path\\n\",\n",
      "2026-01-21 11:08:43,958 [INFO]         \"from datetime import datetime\\n\",\n",
      "2026-01-21 11:08:43,959 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,959 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,959 [INFO]         \"# CONFIG\\n\",\n",
      "2026-01-21 11:08:43,960 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,960 [INFO]         \"INPUT_CSV = out_csv # Output from previous step with taxonomy [should be [step:8]escrt_neighborhoods_with_taxonomy_{rightnow}.csv]\\n\",\n",
      "2026-01-21 11:08:43,961 [INFO]         \"OUTDIR = Path(os.path.join(MAIN_OUTDIR, f\\\"architecture_results_{rightnow}\\\"))\\n\",\n",
      "2026-01-21 11:08:43,961 [INFO]         \"OUTDIR.mkdir(exist_ok=True)\\n\",\n",
      "2026-01-21 11:08:43,961 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,962 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,962 [INFO]         \"# Helper functions\\n\",\n",
      "2026-01-21 11:08:43,963 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,964 [INFO]         \"def trim_architecture(tokens, k=2):\\n\",\n",
      "2026-01-21 11:08:43,964 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,964 [INFO]         \"    Trim architecture by keeping at most k 'other' tokens\\n\",\n",
      "2026-01-21 11:08:43,965 [INFO]         \"    at each flank while retaining internal structure.\\n\",\n",
      "2026-01-21 11:08:43,965 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,966 [INFO]         \"    tokens = list(tokens)\\n\",\n",
      "2026-01-21 11:08:43,967 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,967 [INFO]         \"    left = 0\\n\",\n",
      "2026-01-21 11:08:43,967 [INFO]         \"    while left < len(tokens) and tokens[left] == \\\"other\\\":\\n\",\n",
      "2026-01-21 11:08:43,968 [INFO]         \"        left += 1\\n\",\n",
      "2026-01-21 11:08:43,969 [INFO]         \"    left = max(0, left - k)\\n\",\n",
      "2026-01-21 11:08:43,970 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,970 [INFO]         \"    right = len(tokens)\\n\",\n",
      "2026-01-21 11:08:43,971 [INFO]         \"    while right > 0 and tokens[right - 1] == \\\"other\\\":\\n\",\n",
      "2026-01-21 11:08:43,972 [INFO]         \"        right -= 1\\n\",\n",
      "2026-01-21 11:08:43,972 [INFO]         \"    right = min(len(tokens), right + k)\\n\",\n",
      "2026-01-21 11:08:43,973 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,973 [INFO]         \"    return tuple(tokens[left:right])\\n\",\n",
      "2026-01-21 11:08:43,974 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,974 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,975 [INFO]         \"def canonicalize_architecture(tokens):\\n\",\n",
      "2026-01-21 11:08:43,976 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,976 [INFO]         \"    Orientation-invariant canonical form\\n\",\n",
      "2026-01-21 11:08:43,976 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,977 [INFO]         \"    tokens = tuple(tokens)\\n\",\n",
      "2026-01-21 11:08:43,977 [INFO]         \"    return min(tokens, tokens[::-1])\\n\",\n",
      "2026-01-21 11:08:43,978 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,978 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,979 [INFO]         \"def is_subtuple(short, long):\\n\",\n",
      "2026-01-21 11:08:43,979 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,979 [INFO]         \"    Check if `short` is a contiguous subtuple of `long`\\n\",\n",
      "2026-01-21 11:08:43,980 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,980 [INFO]         \"    n, m = len(short), len(long)\\n\",\n",
      "2026-01-21 11:08:43,981 [INFO]         \"    if n > m:\\n\",\n",
      "2026-01-21 11:08:43,981 [INFO]         \"        return False\\n\",\n",
      "2026-01-21 11:08:43,981 [INFO]         \"    for i in range(m - n + 1):\\n\",\n",
      "2026-01-21 11:08:43,982 [INFO]         \"        if long[i:i+n] == short:\\n\",\n",
      "2026-01-21 11:08:43,982 [INFO]         \"            return True\\n\",\n",
      "2026-01-21 11:08:43,982 [INFO]         \"    return False\\n\",\n",
      "2026-01-21 11:08:43,983 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,983 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,983 [INFO]         \"def architecture_equivalent(a, b):\\n\",\n",
      "2026-01-21 11:08:43,984 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,985 [INFO]         \"    Equivalence under:\\n\",\n",
      "2026-01-21 11:08:43,985 [INFO]         \"      - inversion\\n\",\n",
      "2026-01-21 11:08:43,985 [INFO]         \"      - truncation (subtuple)\\n\",\n",
      "2026-01-21 11:08:43,986 [INFO]         \"      - inversion + truncation\\n\",\n",
      "2026-01-21 11:08:43,986 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:43,987 [INFO]         \"    a = tuple(a)\\n\",\n",
      "2026-01-21 11:08:43,987 [INFO]         \"    b = tuple(b)\\n\",\n",
      "2026-01-21 11:08:43,988 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,988 [INFO]         \"    return (\\n\",\n",
      "2026-01-21 11:08:43,988 [INFO]         \"        is_subtuple(a, b) or\\n\",\n",
      "2026-01-21 11:08:43,989 [INFO]         \"        is_subtuple(a, b[::-1]) or\\n\",\n",
      "2026-01-21 11:08:43,989 [INFO]         \"        is_subtuple(a[::-1], b) or\\n\",\n",
      "2026-01-21 11:08:43,990 [INFO]         \"        is_subtuple(a[::-1], b[::-1])\\n\",\n",
      "2026-01-21 11:08:43,990 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:43,990 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,991 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,991 [INFO]         \"# Step 1: Load data\\n\",\n",
      "2026-01-21 11:08:43,992 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,992 [INFO]         \"logging.info(\\\"Loading annotated neighborhood table\\\")\\n\",\n",
      "2026-01-21 11:08:43,993 [INFO]         \"df = pd.read_csv(INPUT_CSV)\\n\",\n",
      "2026-01-21 11:08:43,993 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,994 [INFO]         \"df[\\\"neighbor_architecture\\\"] = df[\\\"neighbor_architecture\\\"].str.strip()\\n\",\n",
      "2026-01-21 11:08:43,994 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,994 [INFO]         \"required_cols = {\\n\",\n",
      "2026-01-21 11:08:43,995 [INFO]         \"    \\\"genome_id_x\\\", \\\"contig\\\", \\\"center_protein\\\",\\n\",\n",
      "2026-01-21 11:08:43,995 [INFO]         \"    \\\"relative_pos\\\", \\\"neighbor_architecture\\\",\\n\",\n",
      "2026-01-21 11:08:43,995 [INFO]         \"    LINEAGE_LEVEL\\n\",\n",
      "2026-01-21 11:08:43,996 [INFO]         \"}\\n\",\n",
      "2026-01-21 11:08:43,996 [INFO]         \"missing = required_cols - set(df.columns)\\n\",\n",
      "2026-01-21 11:08:43,997 [INFO]         \"if missing:\\n\",\n",
      "2026-01-21 11:08:43,997 [INFO]         \"    raise ValueError(f\\\"Missing required columns: {missing}\\\")\\n\",\n",
      "2026-01-21 11:08:43,998 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,998 [INFO]         \"logging.info(f\\\"Loaded {len(df)} gene-level rows\\\")\\n\",\n",
      "2026-01-21 11:08:43,998 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:43,999 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:43,999 [INFO]         \"# Step 2: Encode architecture tokens\\n\",\n",
      "2026-01-21 11:08:44,000 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,000 [INFO]         \"logging.info(\\\"Encoding architecture tokens\\\")\\n\",\n",
      "2026-01-21 11:08:44,000 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,001 [INFO]         \"df[\\\"arch_token\\\"] = df[\\\"neighbor_architecture\\\"].fillna(\\\"other\\\")\\n\",\n",
      "2026-01-21 11:08:44,002 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,002 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,002 [INFO]         \"# Step 3: Build contig-level architectures\\n\",\n",
      "2026-01-21 11:08:44,003 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,003 [INFO]         \"logging.info(\\\"Constructing contig-level architectures\\\")\\n\",\n",
      "2026-01-21 11:08:44,004 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,004 [INFO]         \"arch_df = (\\n\",\n",
      "2026-01-21 11:08:44,004 [INFO]         \"    df\\n\",\n",
      "2026-01-21 11:08:44,005 [INFO]         \"    .sort_values(\\\"relative_pos\\\")\\n\",\n",
      "2026-01-21 11:08:44,005 [INFO]         \"    .groupby(\\n\",\n",
      "2026-01-21 11:08:44,005 [INFO]         \"        [\\\"genome_id_x\\\", \\\"contig\\\", \\\"center_protein\\\", LINEAGE_LEVEL],\\n\",\n",
      "2026-01-21 11:08:44,006 [INFO]         \"        as_index=False\\n\",\n",
      "2026-01-21 11:08:44,007 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:44,007 [INFO]         \"    .agg(\\n\",\n",
      "2026-01-21 11:08:44,007 [INFO]         \"        arch_token=(\\\"arch_token\\\", lambda x: tuple(x)),\\n\",\n",
      "2026-01-21 11:08:44,008 [INFO]         \"        n_genes=(\\\"arch_token\\\", \\\"count\\\")\\n\",\n",
      "2026-01-21 11:08:44,008 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:44,009 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,009 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,009 [INFO]         \"logging.info(f\\\"Identified {len(arch_df)} contig-level architectures\\\")\\n\",\n",
      "2026-01-21 11:08:44,010 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,010 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,011 [INFO]         \"arch_df.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,011 [INFO]         \"    OUTDIR / f\\\"[STEP:{STEP}]contig_architectures_raw.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,011 [INFO]         \"    index=False\\n\",\n",
      "2026-01-21 11:08:44,012 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,013 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,013 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,013 [INFO]         \"# Step 4: Trim flanks + canonicalize\\n\",\n",
      "2026-01-21 11:08:44,013 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,014 [INFO]         \"logging.info(f\\\"Trimming architectures (k={FLANK_K}) and collapsing inverses\\\")\\n\",\n",
      "2026-01-21 11:08:44,014 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,015 [INFO]         \"arch_df[\\\"arch_token_trimmed\\\"] = arch_df[\\\"arch_token\\\"].apply(\\n\",\n",
      "2026-01-21 11:08:44,015 [INFO]         \"    lambda x: trim_architecture(x, k=FLANK_K)\\n\",\n",
      "2026-01-21 11:08:44,016 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,016 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,017 [INFO]         \"arch_df[\\\"arch_token_canonical\\\"] = arch_df[\\\"arch_token_trimmed\\\"].apply(\\n\",\n",
      "2026-01-21 11:08:44,017 [INFO]         \"    canonicalize_architecture\\n\",\n",
      "2026-01-21 11:08:44,017 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,018 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,018 [INFO]         \"arch_df[\\\"trimmed_len\\\"] = arch_df[\\\"arch_token_trimmed\\\"].apply(len)\\n\",\n",
      "2026-01-21 11:08:44,018 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,019 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,019 [INFO]         \"arch_df.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,019 [INFO]         \"    OUTDIR / f\\\"[STEP:{STEP}]contig_architectures_trimmed_canonical.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,020 [INFO]         \"    index=False\\n\",\n",
      "2026-01-21 11:08:44,020 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,021 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,021 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,022 [INFO]         \"# Step 5A: Collapse to maximal architectures per lineage\\n\",\n",
      "2026-01-21 11:08:44,022 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,023 [INFO]         \"logging.info(\\\"Collapsing architectures using inversion + subtuple equivalence\\\")\\n\",\n",
      "2026-01-21 11:08:44,023 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,023 [INFO]         \"collapsed_rows = []\\n\",\n",
      "2026-01-21 11:08:44,024 [INFO]         \"representatives = {}  # lineage -> list of maximal architectures\\n\",\n",
      "2026-01-21 11:08:44,024 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,025 [INFO]         \"for lineage, subdf in arch_df.groupby(LINEAGE_LEVEL):\\n\",\n",
      "2026-01-21 11:08:44,025 [INFO]         \"    subdf = subdf.copy()\\n\",\n",
      "2026-01-21 11:08:44,025 [INFO]         \"    subdf[\\\"arch_len\\\"] = subdf[\\\"arch_token_trimmed\\\"].apply(len)\\n\",\n",
      "2026-01-21 11:08:44,026 [INFO]         \"    subdf = subdf.sort_values(\\\"arch_len\\\", ascending=False)\\n\",\n",
      "2026-01-21 11:08:44,027 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,027 [INFO]         \"    kept_archs = []\\n\",\n",
      "2026-01-21 11:08:44,028 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,028 [INFO]         \"    for _, row in subdf.iterrows():\\n\",\n",
      "2026-01-21 11:08:44,028 [INFO]         \"        arch = row[\\\"arch_token_trimmed\\\"]\\n\",\n",
      "2026-01-21 11:08:44,029 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,029 [INFO]         \"        if any(architecture_equivalent(arch, kept) for kept in kept_archs):\\n\",\n",
      "2026-01-21 11:08:44,030 [INFO]         \"            continue\\n\",\n",
      "2026-01-21 11:08:44,030 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,030 [INFO]         \"        kept_archs.append(arch)\\n\",\n",
      "2026-01-21 11:08:44,030 [INFO]         \"        collapsed_rows.append(row)\\n\",\n",
      "2026-01-21 11:08:44,031 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,031 [INFO]         \"    representatives[lineage] = kept_archs\\n\",\n",
      "2026-01-21 11:08:44,031 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,032 [INFO]         \"collapsed_arch_df = pd.DataFrame(collapsed_rows).drop(columns=\\\"arch_len\\\")\\n\",\n",
      "2026-01-21 11:08:44,032 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,033 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,033 [INFO]         \"collapsed_arch_df.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,033 [INFO]         \"    OUTDIR / f\\\"[STEP:{STEP}]collapsed_arch_df.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,034 [INFO]         \"    index=False\\n\",\n",
      "2026-01-21 11:08:44,035 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,035 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,036 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,036 [INFO]         \"# Step 5B: Assign EVERY architecture to a representative\\n\",\n",
      "2026-01-21 11:08:44,037 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,037 [INFO]         \"logging.info(\\n\",\n",
      "2026-01-21 11:08:44,037 [INFO]         \"    \\\"Assigning architectures to maximal representatives (subtuple + inverse-aware)\\\"\\n\",\n",
      "2026-01-21 11:08:44,038 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,038 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,039 [INFO]         \"def assign_representative(row):\\n\",\n",
      "2026-01-21 11:08:44,039 [INFO]         \"    lineage = row[LINEAGE_LEVEL]\\n\",\n",
      "2026-01-21 11:08:44,039 [INFO]         \"    arch = row[\\\"arch_token_trimmed\\\"]\\n\",\n",
      "2026-01-21 11:08:44,039 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,040 [INFO]         \"    for rep in representatives[lineage]:\\n\",\n",
      "2026-01-21 11:08:44,040 [INFO]         \"        if architecture_equivalent(arch, rep):\\n\",\n",
      "2026-01-21 11:08:44,041 [INFO]         \"            return canonicalize_architecture(rep)\\n\",\n",
      "2026-01-21 11:08:44,041 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,042 [INFO]         \"    return None\\n\",\n",
      "2026-01-21 11:08:44,042 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,042 [INFO]         \"arch_df[\\\"rep_arch_canonical\\\"] = arch_df.apply(assign_representative, axis=1)\\n\",\n",
      "2026-01-21 11:08:44,043 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,043 [INFO]         \"if arch_df[\\\"rep_arch_canonical\\\"].isna().any():\\n\",\n",
      "2026-01-21 11:08:44,044 [INFO]         \"    raise RuntimeError(\\\"Some architectures could not be assigned to a representative\\\")\\n\",\n",
      "2026-01-21 11:08:44,044 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,045 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,045 [INFO]         \"arch_df.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,045 [INFO]         \"    OUTDIR / f\\\"[STEP:{STEP}]contig_architectures_with_representatives.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,046 [INFO]         \"    index=False\\n\",\n",
      "2026-01-21 11:08:44,046 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,047 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,047 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,048 [INFO]         \"# Step 5C: Count INCLUDING subtuples\\n\",\n",
      "2026-01-21 11:08:44,048 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,048 [INFO]         \"logging.info(\\n\",\n",
      "2026-01-21 11:08:44,049 [INFO]         \"    f\\\"Counting architectures per {LINEAGE_LEVEL} (inverse + subtuple collapsed)\\\"\\n\",\n",
      "2026-01-21 11:08:44,049 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,049 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,050 [INFO]         \"arch_counts = (\\n\",\n",
      "2026-01-21 11:08:44,050 [INFO]         \"    arch_df\\n\",\n",
      "2026-01-21 11:08:44,051 [INFO]         \"    .groupby([LINEAGE_LEVEL, \\\"rep_arch_canonical\\\"], as_index=False)\\n\",\n",
      "2026-01-21 11:08:44,051 [INFO]         \"    .size()\\n\",\n",
      "2026-01-21 11:08:44,052 [INFO]         \"    .rename(columns={\\\"size\\\": \\\"count\\\"})\\n\",\n",
      "2026-01-21 11:08:44,052 [INFO]         \"    .sort_values([LINEAGE_LEVEL, \\\"count\\\"], ascending=[True, False])\\n\",\n",
      "2026-01-21 11:08:44,052 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,053 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,053 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,054 [INFO]         \"arch_counts.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,054 [INFO]         \"    OUTDIR / f\\\"[STEP:{STEP}]architecture_frequencies_inverse_subtuple_collapsed.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,054 [INFO]         \"    index=False\\n\",\n",
      "2026-01-21 11:08:44,055 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,055 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,055 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,056 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,056 [INFO]         \"# ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,056 [INFO]         \"# Step 6: Select representative architecture per lineage\\n\",\n",
      "2026-01-21 11:08:44,057 [INFO]         \"# ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,058 [INFO]         \"logging.info(\\\"Selecting representative architecture per lineage\\\")\\n\",\n",
      "2026-01-21 11:08:44,058 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,059 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,059 [INFO]         \"# doesnt consider singlets for representative selection\\n\",\n",
      "2026-01-21 11:08:44,059 [INFO]         \"arch_counts[\\\"information\\\"] = arch_counts[\\\"rep_arch_canonical\\\"].apply(\\n\",\n",
      "2026-01-21 11:08:44,060 [INFO]         \"    lambda arch: sum(gene != \\\"other\\\" for gene in arch)\\n\",\n",
      "2026-01-21 11:08:44,060 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,061 [INFO]         \"logging.info(arch_counts[[\\\"rep_arch_canonical\\\", \\\"information\\\", \\\"count\\\"]].head(10))\\n\",\n",
      "2026-01-21 11:08:44,061 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,061 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,062 [INFO]         \"rep_arch = (\\n\",\n",
      "2026-01-21 11:08:44,062 [INFO]         \"    arch_counts\\n\",\n",
      "2026-01-21 11:08:44,063 [INFO]         \"    .query(\\\"information >= 2\\\")\\n\",\n",
      "2026-01-21 11:08:44,063 [INFO]         \"    .sort_values([\\\"information\\\", \\\"count\\\"], ascending=[False, False])\\n\",\n",
      "2026-01-21 11:08:44,063 [INFO]         \"    .groupby(LINEAGE_LEVEL, as_index=False)\\n\",\n",
      "2026-01-21 11:08:44,064 [INFO]         \"    .head(1)\\n\",\n",
      "2026-01-21 11:08:44,064 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,065 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,065 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,065 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,066 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,066 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,067 [INFO]         \"rep_arch.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,067 [INFO]         \"    OUTDIR / f\\\"[STEP:{STEP}]representative_architectures.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,067 [INFO]         \"    index=False\\n\",\n",
      "2026-01-21 11:08:44,068 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,068 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,068 [INFO]         \"logging.info(f\\\"Selected {len(rep_arch)} representative architectures\\\")\\n\",\n",
      "2026-01-21 11:08:44,069 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,069 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,070 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,070 [INFO]         \"# Step 7: Recover genomes encoding the longest representative architectures\\n\",\n",
      "2026-01-21 11:08:44,071 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,071 [INFO]         \"logging.info(\\n\",\n",
      "2026-01-21 11:08:44,072 [INFO]         \"    \\\"Recovering genomes encoding longest architectures with maximal subtuple support\\\"\\n\",\n",
      "2026-01-21 11:08:44,072 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,072 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,073 [INFO]         \"# Only maximal (longest) architectures per lineage\\n\",\n",
      "2026-01-21 11:08:44,073 [INFO]         \"longest_arch_contigs = collapsed_arch_df[[\\n\",\n",
      "2026-01-21 11:08:44,074 [INFO]         \"    LINEAGE_LEVEL,\\n\",\n",
      "2026-01-21 11:08:44,074 [INFO]         \"    \\\"genome_id_x\\\",\\n\",\n",
      "2026-01-21 11:08:44,075 [INFO]         \"    \\\"contig\\\",\\n\",\n",
      "2026-01-21 11:08:44,075 [INFO]         \"    \\\"center_protein\\\",\\n\",\n",
      "2026-01-21 11:08:44,075 [INFO]         \"    \\\"arch_token_canonical\\\",\\n\",\n",
      "2026-01-21 11:08:44,076 [INFO]         \"    \\\"arch_token_trimmed\\\"\\n\",\n",
      "2026-01-21 11:08:44,076 [INFO]         \"]].copy()\\n\",\n",
      "2026-01-21 11:08:44,077 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,077 [INFO]         \"# Merge architecture counts \\u2192 longest architecture contigs\\n\",\n",
      "2026-01-21 11:08:44,078 [INFO]         \"rep_keys = rep_arch.merge(\\n\",\n",
      "2026-01-21 11:08:44,078 [INFO]         \"    longest_arch_contigs,\\n\",\n",
      "2026-01-21 11:08:44,079 [INFO]         \"    left_on=[LINEAGE_LEVEL, \\\"rep_arch_canonical\\\"],\\n\",\n",
      "2026-01-21 11:08:44,079 [INFO]         \"    right_on=[LINEAGE_LEVEL, \\\"arch_token_canonical\\\"],\\n\",\n",
      "2026-01-21 11:08:44,079 [INFO]         \"    how=\\\"left\\\"\\n\",\n",
      "2026-01-21 11:08:44,080 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,080 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,081 [INFO]         \"# Defensive check: every representative should map to \\u22651 genome\\n\",\n",
      "2026-01-21 11:08:44,081 [INFO]         \"if rep_keys[\\\"genome_id_x\\\"].isna().any():\\n\",\n",
      "2026-01-21 11:08:44,081 [INFO]         \"    raise RuntimeError(\\n\",\n",
      "2026-01-21 11:08:44,082 [INFO]         \"        \\\"Some representative architectures could not be mapped to a genome\\\"\\n\",\n",
      "2026-01-21 11:08:44,082 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:44,082 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,083 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,083 [INFO]         \"rep_keys.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,084 [INFO]         \"    OUTDIR / f\\\"[STEP:{STEP}]representative_architectures_with_genomes.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,084 [INFO]         \"    index=False\\n\",\n",
      "2026-01-21 11:08:44,084 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,085 [INFO]         \"# # ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,086 [INFO]         \"# # Step 8: Recover gene-level rows for plotting (representative architectures only)\\n\",\n",
      "2026-01-21 11:08:44,086 [INFO]         \"# # ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,086 [INFO]         \"# logging.info(\\\"Extracting gene-level rows for plotting (representative architectures)\\\")\\n\",\n",
      "2026-01-21 11:08:44,087 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,087 [INFO]         \"# logging.info(\\\"Columns in input df: %s\\\", str(\\\", \\\".join(df.columns.tolist())))\\n\",\n",
      "2026-01-21 11:08:44,087 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,088 [INFO]         \"# plot_df = df.merge(\\n\",\n",
      "2026-01-21 11:08:44,088 [INFO]         \"#     rep_keys[\\n\",\n",
      "2026-01-21 11:08:44,089 [INFO]         \"#         [\\n\",\n",
      "2026-01-21 11:08:44,089 [INFO]         \"#             LINEAGE_LEVEL,\\n\",\n",
      "2026-01-21 11:08:44,089 [INFO]         \"#             \\\"genome_id_x\\\",\\n\",\n",
      "2026-01-21 11:08:44,090 [INFO]         \"#             \\\"contig\\\",\\n\",\n",
      "2026-01-21 11:08:44,090 [INFO]         \"#             \\\"center_protein\\\",\\n\",\n",
      "2026-01-21 11:08:44,091 [INFO]         \"#             \\\"rep_arch_canonical\\\"\\n\",\n",
      "2026-01-21 11:08:44,091 [INFO]         \"#         ]\\n\",\n",
      "2026-01-21 11:08:44,091 [INFO]         \"#     ],\\n\",\n",
      "2026-01-21 11:08:44,092 [INFO]         \"#     on=[LINEAGE_LEVEL, \\\"genome_id_x\\\"],\\n\",\n",
      "2026-01-21 11:08:44,092 [INFO]         \"#     how=\\\"inner\\\"\\n\",\n",
      "2026-01-21 11:08:44,092 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,092 [INFO]         \"# logging.info(\\n\",\n",
      "2026-01-21 11:08:44,093 [INFO]         \"#     \\\"Columns in plot df: %s\\\",\\n\",\n",
      "2026-01-21 11:08:44,093 [INFO]         \"#     \\\", \\\".join(plot_df.columns.tolist())\\n\",\n",
      "2026-01-21 11:08:44,094 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,094 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,095 [INFO]         \"# plot_df = plot_df.sort_values(\\n\",\n",
      "2026-01-21 11:08:44,096 [INFO]         \"#     [LINEAGE_LEVEL, \\\"genome_id_x\\\", \\\"contig_x\\\", \\\"relative_pos\\\"]\\n\",\n",
      "2026-01-21 11:08:44,097 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,098 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,098 [INFO]         \"# STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,099 [INFO]         \"# plot_df.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,100 [INFO]         \"#     OUTDIR / f\\\"[STEP:{STEP}]plot_ready_architectures.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,100 [INFO]         \"#     index=False\\n\",\n",
      "2026-01-21 11:08:44,101 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,101 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,101 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,102 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,102 [INFO]         \"# Step 8: Recover gene-level rows for plotting\\n\",\n",
      "2026-01-21 11:08:44,102 [INFO]         \"#   - include ALL contigs from representative genomes\\n\",\n",
      "2026-01-21 11:08:44,103 [INFO]         \"#   - ensure at least one contig encodes the representative architecture\\n\",\n",
      "2026-01-21 11:08:44,103 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,103 [INFO]         \"logging.info(\\n\",\n",
      "2026-01-21 11:08:44,104 [INFO]         \"    \\\"Extracting gene-level rows for plotting (all contigs from representative genomes)\\\"\\n\",\n",
      "2026-01-21 11:08:44,104 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,104 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,105 [INFO]         \"# 1. Identify representative genomes per lineage\\n\",\n",
      "2026-01-21 11:08:44,105 [INFO]         \"print(\\\"rep_keys columns: \\\", rep_keys.columns)\\n\",\n",
      "2026-01-21 11:08:44,105 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,106 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,106 [INFO]         \"rep_genomes = (\\n\",\n",
      "2026-01-21 11:08:44,107 [INFO]         \"    rep_keys[\\n\",\n",
      "2026-01-21 11:08:44,107 [INFO]         \"        [\\n\",\n",
      "2026-01-21 11:08:44,108 [INFO]         \"            LINEAGE_LEVEL,\\n\",\n",
      "2026-01-21 11:08:44,108 [INFO]         \"            \\\"genome_id_x\\\",\\n\",\n",
      "2026-01-21 11:08:44,108 [INFO]         \"            \\\"rep_arch_canonical\\\",\\n\",\n",
      "2026-01-21 11:08:44,109 [INFO]         \"            \\\"contig\\\"\\n\",\n",
      "2026-01-21 11:08:44,109 [INFO]         \"        ]\\n\",\n",
      "2026-01-21 11:08:44,110 [INFO]         \"    ]\\n\",\n",
      "2026-01-21 11:08:44,110 [INFO]         \"    .drop_duplicates()\\n\",\n",
      "2026-01-21 11:08:44,111 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,111 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,111 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,113 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,114 [INFO]         \"rep_genomes.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,114 [INFO]         \"    OUTDIR / f\\\"[STEP:{STEP}]representative_genomes.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,115 [INFO]         \"    index=False\\n\",\n",
      "2026-01-21 11:08:44,115 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,116 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,116 [INFO]         \"logging.info(\\n\",\n",
      "2026-01-21 11:08:44,117 [INFO]         \"    \\\"Representative genomes identified: %d\\\",\\n\",\n",
      "2026-01-21 11:08:44,117 [INFO]         \"    len(rep_genomes)\\n\",\n",
      "2026-01-21 11:08:44,118 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,118 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,118 [INFO]         \"# 2. Pull ALL gene-level rows from those genomes\\n\",\n",
      "2026-01-21 11:08:44,119 [INFO]         \"plot_df = df.merge(\\n\",\n",
      "2026-01-21 11:08:44,119 [INFO]         \"    rep_genomes,\\n\",\n",
      "2026-01-21 11:08:44,119 [INFO]         \"    on=[LINEAGE_LEVEL, \\\"genome_id_x\\\", \\\"contig\\\"],\\n\",\n",
      "2026-01-21 11:08:44,120 [INFO]         \"    how=\\\"inner\\\"\\n\",\n",
      "2026-01-21 11:08:44,120 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,121 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,121 [INFO]         \"logging.info(\\n\",\n",
      "2026-01-21 11:08:44,121 [INFO]         \"    \\\"Plot df shape after genome-level filtering: %s\\\",\\n\",\n",
      "2026-01-21 11:08:44,122 [INFO]         \"    plot_df.shape\\n\",\n",
      "2026-01-21 11:08:44,122 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,123 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,123 [INFO]         \"# 3. Sort for clean plotting\\n\",\n",
      "2026-01-21 11:08:44,123 [INFO]         \"plot_df = plot_df.sort_values(\\n\",\n",
      "2026-01-21 11:08:44,124 [INFO]         \"    [LINEAGE_LEVEL, \\\"genome_id_x\\\", \\\"contig\\\", \\\"gene_index\\\"]\\n\",\n",
      "2026-01-21 11:08:44,125 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,125 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,125 [INFO]         \"STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,126 [INFO]         \"plot_df.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,126 [INFO]         \"    OUTDIR / f\\\"[STEP:{STEP}]plot_ready_architectures.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,127 [INFO]         \"    index=False\\n\",\n",
      "2026-01-21 11:08:44,127 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,127 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,128 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,128 [INFO]         \"# Summary\\n\",\n",
      "2026-01-21 11:08:44,129 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,129 [INFO]         \"logging.info(\\\"Architecture analysis complete\\\")\\n\",\n",
      "2026-01-21 11:08:44,130 [INFO]         \"logging.info(f\\\"Results written to: {OUTDIR.resolve()}\\\")\\n\",\n",
      "2026-01-21 11:08:44,130 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,130 [INFO]         \"logging.info(\\\"Files generated:\\\")\\n\",\n",
      "2026-01-21 11:08:44,131 [INFO]         \"for f in sorted(OUTDIR.iterdir()):\\n\",\n",
      "2026-01-21 11:08:44,131 [INFO]         \"    logging.info(f\\\"  - {f.name}\\\")\\n\"\n",
      "2026-01-21 11:08:44,131 [INFO]       ]\n",
      "2026-01-21 11:08:44,132 [INFO]     },\n",
      "2026-01-21 11:08:44,132 [INFO]     {\n",
      "2026-01-21 11:08:44,132 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:44,133 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:44,133 [INFO]       \"id\": \"2191e62c\",\n",
      "2026-01-21 11:08:44,134 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:44,136 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:44,137 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:44,138 [INFO]         \"# #!/usr/bin/env python3\\n\",\n",
      "2026-01-21 11:08:44,139 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,139 [INFO]         \"# # without count for subtuples\\n\",\n",
      "2026-01-21 11:08:44,140 [INFO]         \"# \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,140 [INFO]         \"# Architecture analysis and reduction script (orientation-invariant)\\n\",\n",
      "2026-01-21 11:08:44,141 [INFO]         \"# =================================================================\\n\",\n",
      "2026-01-21 11:08:44,142 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,143 [INFO]         \"# Input:\\n\",\n",
      "2026-01-21 11:08:44,143 [INFO]         \"#   - Annotated neighborhood CSV with taxonomy and architecture labels\\n\",\n",
      "2026-01-21 11:08:44,144 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,145 [INFO]         \"# Output:\\n\",\n",
      "2026-01-21 11:08:44,146 [INFO]         \"#   - Contig-level trimmed & canonical architectures\\n\",\n",
      "2026-01-21 11:08:44,146 [INFO]         \"#   - Lineage-level architecture counts (inverse-collapsed)\\n\",\n",
      "2026-01-21 11:08:44,147 [INFO]         \"#   - Representative contigs per lineage\\n\",\n",
      "2026-01-21 11:08:44,149 [INFO]         \"#   - Gene-level dataframe for plotting\\n\",\n",
      "2026-01-21 11:08:44,150 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,151 [INFO]         \"# Key features:\\n\",\n",
      "2026-01-21 11:08:44,151 [INFO]         \"#   - Flank trimming (k=2)\\n\",\n",
      "2026-01-21 11:08:44,152 [INFO]         \"#   - Orientation-invariant (inverse) collapsing\\n\",\n",
      "2026-01-21 11:08:44,153 [INFO]         \"#   - Counts incorporate reversed architectures\\n\",\n",
      "2026-01-21 11:08:44,153 [INFO]         \"#   - Subtuple matching for architecture equivalence\\n\",\n",
      "2026-01-21 11:08:44,154 [INFO]         \"# \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,155 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,155 [INFO]         \"# import pandas as pd\\n\",\n",
      "2026-01-21 11:08:44,156 [INFO]         \"# import logging\\n\",\n",
      "2026-01-21 11:08:44,156 [INFO]         \"# from pathlib import Path\\n\",\n",
      "2026-01-21 11:08:44,156 [INFO]         \"# from datetime import datetime\\n\",\n",
      "2026-01-21 11:08:44,156 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,157 [INFO]         \"# INPUT_CSV = out_csv # Output from previous step with taxonomy [should be [step:8]escrt_neighborhoods_with_taxonomy_{rightnow}.csv]\\n\",\n",
      "2026-01-21 11:08:44,157 [INFO]         \"# OUTDIR = Path(os.path.join(MAIN_OUTDIR, f\\\"architecture_results_{rightnow}\\\"))\\n\",\n",
      "2026-01-21 11:08:44,157 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,158 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,159 [INFO]         \"# OUTDIR.mkdir(exist_ok=True)\\n\",\n",
      "2026-01-21 11:08:44,159 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,159 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,160 [INFO]         \"# # Helper functions\\n\",\n",
      "2026-01-21 11:08:44,160 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,160 [INFO]         \"# def trim_architecture(tokens, k=2):\\n\",\n",
      "2026-01-21 11:08:44,161 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,161 [INFO]         \"#     Trim architecture by keeping at most k 'other' tokens\\n\",\n",
      "2026-01-21 11:08:44,162 [INFO]         \"#     at each flank while retaining internal structure.\\n\",\n",
      "2026-01-21 11:08:44,162 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,162 [INFO]         \"#     tokens = list(tokens)\\n\",\n",
      "2026-01-21 11:08:44,163 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,163 [INFO]         \"#     # Trim left\\n\",\n",
      "2026-01-21 11:08:44,164 [INFO]         \"#     left = 0\\n\",\n",
      "2026-01-21 11:08:44,164 [INFO]         \"#     while left < len(tokens) and tokens[left] == \\\"other\\\":\\n\",\n",
      "2026-01-21 11:08:44,165 [INFO]         \"#         left += 1\\n\",\n",
      "2026-01-21 11:08:44,166 [INFO]         \"#     left = max(0, left - k)\\n\",\n",
      "2026-01-21 11:08:44,166 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,167 [INFO]         \"#     # Trim right\\n\",\n",
      "2026-01-21 11:08:44,167 [INFO]         \"#     right = len(tokens)\\n\",\n",
      "2026-01-21 11:08:44,167 [INFO]         \"#     while right > 0 and tokens[right - 1] == \\\"other\\\":\\n\",\n",
      "2026-01-21 11:08:44,168 [INFO]         \"#         right -= 1\\n\",\n",
      "2026-01-21 11:08:44,168 [INFO]         \"#     right = min(len(tokens), right + k)\\n\",\n",
      "2026-01-21 11:08:44,169 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,169 [INFO]         \"#     return tuple(tokens[left:right])\\n\",\n",
      "2026-01-21 11:08:44,169 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,170 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,170 [INFO]         \"# def canonicalize_architecture(tokens):\\n\",\n",
      "2026-01-21 11:08:44,170 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,171 [INFO]         \"#     Make architecture orientation-invariant by collapsing\\n\",\n",
      "2026-01-21 11:08:44,172 [INFO]         \"#     forward and reverse into a single canonical form.\\n\",\n",
      "2026-01-21 11:08:44,172 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,173 [INFO]         \"#     tokens = tuple(tokens)\\n\",\n",
      "2026-01-21 11:08:44,173 [INFO]         \"#     rev = tokens[::-1]\\n\",\n",
      "2026-01-21 11:08:44,173 [INFO]         \"#     return min(tokens, rev)\\n\",\n",
      "2026-01-21 11:08:44,174 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,174 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,174 [INFO]         \"# def is_subtuple(short, long):\\n\",\n",
      "2026-01-21 11:08:44,175 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,175 [INFO]         \"#     Check if tuple `short` is a contiguous subtuple of `long`\\n\",\n",
      "2026-01-21 11:08:44,176 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,176 [INFO]         \"#     n, m = len(short), len(long)\\n\",\n",
      "2026-01-21 11:08:44,176 [INFO]         \"#     if n > m:\\n\",\n",
      "2026-01-21 11:08:44,177 [INFO]         \"#         return False\\n\",\n",
      "2026-01-21 11:08:44,177 [INFO]         \"#     for i in range(m - n + 1):\\n\",\n",
      "2026-01-21 11:08:44,178 [INFO]         \"#         if long[i:i+n] == short:\\n\",\n",
      "2026-01-21 11:08:44,178 [INFO]         \"#             return True\\n\",\n",
      "2026-01-21 11:08:44,178 [INFO]         \"#     return False\\n\",\n",
      "2026-01-21 11:08:44,179 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,179 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,180 [INFO]         \"# def architecture_equivalent(a, b):\\n\",\n",
      "2026-01-21 11:08:44,180 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,181 [INFO]         \"#     True if architectures a and b are equivalent under:\\n\",\n",
      "2026-01-21 11:08:44,181 [INFO]         \"#       - inversion\\n\",\n",
      "2026-01-21 11:08:44,181 [INFO]         \"#       - truncation (subtuple)\\n\",\n",
      "2026-01-21 11:08:44,182 [INFO]         \"#       - inversion + truncation\\n\",\n",
      "2026-01-21 11:08:44,182 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,182 [INFO]         \"#     a = tuple(a)\\n\",\n",
      "2026-01-21 11:08:44,183 [INFO]         \"#     b = tuple(b)\\n\",\n",
      "2026-01-21 11:08:44,183 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,183 [INFO]         \"#     a_rev = a[::-1]\\n\",\n",
      "2026-01-21 11:08:44,184 [INFO]         \"#     b_rev = b[::-1]\\n\",\n",
      "2026-01-21 11:08:44,185 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,185 [INFO]         \"#     return (\\n\",\n",
      "2026-01-21 11:08:44,186 [INFO]         \"#         is_subtuple(a, b) or\\n\",\n",
      "2026-01-21 11:08:44,186 [INFO]         \"#         is_subtuple(a, b_rev) or\\n\",\n",
      "2026-01-21 11:08:44,186 [INFO]         \"#         is_subtuple(a_rev, b) or\\n\",\n",
      "2026-01-21 11:08:44,187 [INFO]         \"#         is_subtuple(a_rev, b_rev)\\n\",\n",
      "2026-01-21 11:08:44,187 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:44,188 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,188 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,188 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,189 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,189 [INFO]         \"# # Step 1: Load data\\n\",\n",
      "2026-01-21 11:08:44,189 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,190 [INFO]         \"# logging.info(\\\"Loading annotated neighborhood table\\\")\\n\",\n",
      "2026-01-21 11:08:44,190 [INFO]         \"# df = pd.read_csv(INPUT_CSV)\\n\",\n",
      "2026-01-21 11:08:44,191 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,191 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,192 [INFO]         \"# df['neighbor_architecture'] = df['neighbor_architecture'].str.strip()\\n\",\n",
      "2026-01-21 11:08:44,192 [INFO]         \"# required_cols = {\\n\",\n",
      "2026-01-21 11:08:44,193 [INFO]         \"#     \\\"genome_id_x\\\", \\\"contig\\\", \\\"center_protein\\\",\\n\",\n",
      "2026-01-21 11:08:44,193 [INFO]         \"#     \\\"relative_pos\\\", \\\"neighbor_architecture\\\",\\n\",\n",
      "2026-01-21 11:08:44,193 [INFO]         \"#     LINEAGE_LEVEL\\n\",\n",
      "2026-01-21 11:08:44,194 [INFO]         \"# }\\n\",\n",
      "2026-01-21 11:08:44,194 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,194 [INFO]         \"# missing = required_cols - set(df.columns)\\n\",\n",
      "2026-01-21 11:08:44,195 [INFO]         \"# if missing:\\n\",\n",
      "2026-01-21 11:08:44,195 [INFO]         \"#     raise ValueError(f\\\"Missing required columns: {missing}\\\")\\n\",\n",
      "2026-01-21 11:08:44,195 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,196 [INFO]         \"# logging.info(f\\\"Loaded {len(df)} gene-level rows\\\")\\n\",\n",
      "2026-01-21 11:08:44,197 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,197 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,197 [INFO]         \"# # Step 2: Encode architecture tokens\\n\",\n",
      "2026-01-21 11:08:44,197 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,198 [INFO]         \"# logging.info(\\\"Encoding architecture tokens\\\")\\n\",\n",
      "2026-01-21 11:08:44,198 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,199 [INFO]         \"# df[\\\"arch_token\\\"] = (\\n\",\n",
      "2026-01-21 11:08:44,199 [INFO]         \"#     df[\\\"neighbor_architecture\\\"]\\n\",\n",
      "2026-01-21 11:08:44,200 [INFO]         \"#     .fillna(\\\"other\\\")\\n\",\n",
      "2026-01-21 11:08:44,200 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,201 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,201 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,201 [INFO]         \"# # Step 3: Build contig-level architectures\\n\",\n",
      "2026-01-21 11:08:44,202 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,202 [INFO]         \"# logging.info(\\\"Constructing contig-level architectures\\\")\\n\",\n",
      "2026-01-21 11:08:44,203 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,203 [INFO]         \"# arch_df = (\\n\",\n",
      "2026-01-21 11:08:44,204 [INFO]         \"#     df\\n\",\n",
      "2026-01-21 11:08:44,204 [INFO]         \"#     .sort_values(\\\"relative_pos\\\")\\n\",\n",
      "2026-01-21 11:08:44,204 [INFO]         \"#     .groupby(\\n\",\n",
      "2026-01-21 11:08:44,205 [INFO]         \"#         [\\\"genome_id_x\\\", \\\"contig\\\", \\\"center_protein\\\", LINEAGE_LEVEL],\\n\",\n",
      "2026-01-21 11:08:44,205 [INFO]         \"#         as_index=False\\n\",\n",
      "2026-01-21 11:08:44,206 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:44,206 [INFO]         \"#     .agg(\\n\",\n",
      "2026-01-21 11:08:44,207 [INFO]         \"#         arch_token=(\\\"arch_token\\\", lambda x: tuple(x)),\\n\",\n",
      "2026-01-21 11:08:44,207 [INFO]         \"#         n_genes=(\\\"arch_token\\\", \\\"count\\\")\\n\",\n",
      "2026-01-21 11:08:44,208 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:44,208 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,208 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,209 [INFO]         \"# logging.info(f\\\"Identified {len(arch_df)} contig-level architectures\\\")\\n\",\n",
      "2026-01-21 11:08:44,209 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,210 [INFO]         \"# STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,210 [INFO]         \"# arch_df.to_csv(OUTDIR / f\\\"[STEP:{STEP}]contig_architectures_raw.csv\\\", index=False)\\n\",\n",
      "2026-01-21 11:08:44,210 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,210 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,211 [INFO]         \"# # Step 4: Trim flanks + inverse collapse (CORE STEP)\\n\",\n",
      "2026-01-21 11:08:44,211 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,212 [INFO]         \"# logging.info(\\n\",\n",
      "2026-01-21 11:08:44,212 [INFO]         \"#     f\\\"Trimming architectures (k={FLANK_K}) and collapsing inverses\\\"\\n\",\n",
      "2026-01-21 11:08:44,213 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,213 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,213 [INFO]         \"# arch_df[\\\"arch_token_trimmed\\\"] = arch_df[\\\"arch_token\\\"].apply(\\n\",\n",
      "2026-01-21 11:08:44,214 [INFO]         \"#     lambda x: trim_architecture(x, k=FLANK_K)\\n\",\n",
      "2026-01-21 11:08:44,214 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,215 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,215 [INFO]         \"# arch_df[\\\"arch_token_canonical\\\"] = arch_df[\\\"arch_token_trimmed\\\"].apply(\\n\",\n",
      "2026-01-21 11:08:44,215 [INFO]         \"#     canonicalize_architecture\\n\",\n",
      "2026-01-21 11:08:44,216 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,216 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,217 [INFO]         \"# arch_df[\\\"trimmed_len\\\"] = arch_df[\\\"arch_token_trimmed\\\"].apply(len)\\n\",\n",
      "2026-01-21 11:08:44,217 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,218 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,218 [INFO]         \"# STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,219 [INFO]         \"# arch_df.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,219 [INFO]         \"#     OUTDIR / f\\\"[STEP:{STEP}]contig_architectures_trimmed_canonical.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,220 [INFO]         \"#     index=False\\n\",\n",
      "2026-01-21 11:08:44,220 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,221 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,221 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,221 [INFO]         \"# # Step 5: Count architectures by lineage (INVERSE-AWARE)\\n\",\n",
      "2026-01-21 11:08:44,222 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,222 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,223 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,223 [INFO]         \"# logging.info(\\\"Collapsing architectures using inversion + subtuple equivalence\\\")\\n\",\n",
      "2026-01-21 11:08:44,223 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,224 [INFO]         \"# collapsed_rows = []\\n\",\n",
      "2026-01-21 11:08:44,224 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,225 [INFO]         \"# for lineage, subdf in arch_df.groupby(LINEAGE_LEVEL):\\n\",\n",
      "2026-01-21 11:08:44,225 [INFO]         \"#     subdf = subdf.copy()\\n\",\n",
      "2026-01-21 11:08:44,225 [INFO]         \"#     subdf[\\\"arch_len\\\"] = subdf[\\\"arch_token_trimmed\\\"].apply(len)\\n\",\n",
      "2026-01-21 11:08:44,226 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,227 [INFO]         \"#     # longest-first ensures maximal architecture survives\\n\",\n",
      "2026-01-21 11:08:44,227 [INFO]         \"#     subdf = subdf.sort_values(\\\"arch_len\\\", ascending=False)\\n\",\n",
      "2026-01-21 11:08:44,227 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,230 [INFO]         \"#     kept_archs = []\\n\",\n",
      "2026-01-21 11:08:44,230 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,231 [INFO]         \"#     for _, row in subdf.iterrows():\\n\",\n",
      "2026-01-21 11:08:44,232 [INFO]         \"#         arch = row[\\\"arch_token_trimmed\\\"]\\n\",\n",
      "2026-01-21 11:08:44,232 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,233 [INFO]         \"#         if any(architecture_equivalent(arch, kept) for kept in kept_archs):\\n\",\n",
      "2026-01-21 11:08:44,234 [INFO]         \"#             continue\\n\",\n",
      "2026-01-21 11:08:44,234 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,235 [INFO]         \"#         kept_archs.append(arch)\\n\",\n",
      "2026-01-21 11:08:44,236 [INFO]         \"#         collapsed_rows.append(row)\\n\",\n",
      "2026-01-21 11:08:44,236 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,237 [INFO]         \"# collapsed_arch_df = pd.DataFrame(collapsed_rows).drop(columns=\\\"arch_len\\\")\\n\",\n",
      "2026-01-21 11:08:44,238 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,239 [INFO]         \"# STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,240 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,241 [INFO]         \"# collapsed_arch_df.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,242 [INFO]         \"#     OUTDIR / f\\\"[STEP:{STEP}]collapsed_arch_df.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,243 [INFO]         \"#     index=False\\n\",\n",
      "2026-01-21 11:08:44,243 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,244 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,245 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,246 [INFO]         \"# logging.info(\\n\",\n",
      "2026-01-21 11:08:44,246 [INFO]         \"#     f\\\"Counting architectures per {LINEAGE_LEVEL} (inverse-aware)\\\"\\n\",\n",
      "2026-01-21 11:08:44,247 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,247 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,247 [INFO]         \"# arch_counts = (\\n\",\n",
      "2026-01-21 11:08:44,248 [INFO]         \"#     collapsed_arch_df\\n\",\n",
      "2026-01-21 11:08:44,248 [INFO]         \"#     .groupby([LINEAGE_LEVEL, \\\"arch_token_canonical\\\"], as_index=False)\\n\",\n",
      "2026-01-21 11:08:44,249 [INFO]         \"#     .size()\\n\",\n",
      "2026-01-21 11:08:44,249 [INFO]         \"#     .rename(columns={\\\"size\\\": \\\"count\\\"})\\n\",\n",
      "2026-01-21 11:08:44,250 [INFO]         \"#     .sort_values([LINEAGE_LEVEL, \\\"count\\\"], ascending=[True, False])\\n\",\n",
      "2026-01-21 11:08:44,250 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,251 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,251 [INFO]         \"# STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,251 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,252 [INFO]         \"# arch_counts.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,252 [INFO]         \"#     OUTDIR / f\\\"[STEP:{STEP}]architecture_frequencies_inverse_collapsed.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,253 [INFO]         \"#     index=False\\n\",\n",
      "2026-01-21 11:08:44,253 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,253 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,253 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,254 [INFO]         \"# # # Step 6: Select representative architecture per lineage\\n\",\n",
      "2026-01-21 11:08:44,254 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,255 [INFO]         \"# # logging.info(\\\"Selecting representative architecture per lineage\\\")\\n\",\n",
      "2026-01-21 11:08:44,255 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,256 [INFO]         \"# # rep_arch = (\\n\",\n",
      "2026-01-21 11:08:44,257 [INFO]         \"# #     arch_counts\\n\",\n",
      "2026-01-21 11:08:44,257 [INFO]         \"# #     .groupby(LINEAGE_LEVEL, as_index=False)\\n\",\n",
      "2026-01-21 11:08:44,258 [INFO]         \"# #     .head(1)\\n\",\n",
      "2026-01-21 11:08:44,258 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,259 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,259 [INFO]         \"# # STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,260 [INFO]         \"# # rep_arch.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,260 [INFO]         \"# #     OUTDIR / f\\\"[STEP:{STEP}]representative_architectures.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,260 [INFO]         \"# #     index=False\\n\",\n",
      "2026-01-21 11:08:44,261 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,261 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,262 [INFO]         \"# # logging.info(f\\\"Selected {len(rep_arch)} representative architectures\\\")\\n\",\n",
      "2026-01-21 11:08:44,262 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,263 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,263 [INFO]         \"# # # Step 7: Recover representative contigs\\n\",\n",
      "2026-01-21 11:08:44,263 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,264 [INFO]         \"# # logging.info(\\\"Recovering representative contigs\\\")\\n\",\n",
      "2026-01-21 11:08:44,264 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,265 [INFO]         \"# # rep_keys = rep_arch.merge(\\n\",\n",
      "2026-01-21 11:08:44,265 [INFO]         \"# #     arch_df,\\n\",\n",
      "2026-01-21 11:08:44,266 [INFO]         \"# #     on=[LINEAGE_LEVEL, \\\"arch_token_canonical\\\"],\\n\",\n",
      "2026-01-21 11:08:44,266 [INFO]         \"# #     how=\\\"left\\\"\\n\",\n",
      "2026-01-21 11:08:44,266 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,267 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,267 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,268 [INFO]         \"# # STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,268 [INFO]         \"# # rep_keys.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,268 [INFO]         \"# #     OUTDIR / f\\\"[STEP:{STEP}]representative_contigs.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,269 [INFO]         \"# #     index=False\\n\",\n",
      "2026-01-21 11:08:44,269 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,270 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,270 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,271 [INFO]         \"# # # Step 8: Recover gene-level rows for plotting\\n\",\n",
      "2026-01-21 11:08:44,271 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,271 [INFO]         \"# # logging.info(\\\"Extracting gene-level rows for plotting\\\")\\n\",\n",
      "2026-01-21 11:08:44,272 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,272 [INFO]         \"# # plot_df = df.merge(\\n\",\n",
      "2026-01-21 11:08:44,272 [INFO]         \"# #     rep_keys[[\\\"genome_id_x\\\", \\\"contig\\\", \\\"center_protein\\\"]],\\n\",\n",
      "2026-01-21 11:08:44,273 [INFO]         \"# #     on=[\\\"genome_id_x\\\", \\\"contig\\\", \\\"center_protein\\\"],\\n\",\n",
      "2026-01-21 11:08:44,273 [INFO]         \"# #     how=\\\"inner\\\"\\n\",\n",
      "2026-01-21 11:08:44,273 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,274 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,274 [INFO]         \"# # plot_df = plot_df.sort_values(\\n\",\n",
      "2026-01-21 11:08:44,275 [INFO]         \"# #     [LINEAGE_LEVEL, \\\"genome_id_x\\\", \\\"contig\\\", \\\"relative_pos\\\"]\\n\",\n",
      "2026-01-21 11:08:44,275 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,276 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,276 [INFO]         \"# # STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,277 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,277 [INFO]         \"# # plot_df.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,277 [INFO]         \"# #     OUTDIR / f\\\"[STEP:{STEP}]plot_ready_architectures.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,278 [INFO]         \"# #     index=False\\n\",\n",
      "2026-01-21 11:08:44,278 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,279 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,279 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,279 [INFO]         \"# # Summary\\n\",\n",
      "2026-01-21 11:08:44,280 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,280 [INFO]         \"# logging.info(\\\"Architecture analysis complete\\\")\\n\",\n",
      "2026-01-21 11:08:44,281 [INFO]         \"# logging.info(f\\\"Results written to: {OUTDIR.resolve()}\\\")\\n\",\n",
      "2026-01-21 11:08:44,281 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,282 [INFO]         \"# logging.info(\\\"Files generated:\\\")\\n\",\n",
      "2026-01-21 11:08:44,282 [INFO]         \"# for f in sorted(OUTDIR.iterdir()):\\n\",\n",
      "2026-01-21 11:08:44,282 [INFO]         \"#     logging.info(f\\\"  - {f.name}\\\")\\n\"\n",
      "2026-01-21 11:08:44,282 [INFO]       ]\n",
      "2026-01-21 11:08:44,283 [INFO]     },\n",
      "2026-01-21 11:08:44,284 [INFO]     {\n",
      "2026-01-21 11:08:44,284 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:44,284 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:44,284 [INFO]       \"id\": \"4276bfef\",\n",
      "2026-01-21 11:08:44,285 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:44,285 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:44,286 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:44,286 [INFO]         \"# # Without Subtuple matching \\n\",\n",
      "2026-01-21 11:08:44,286 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,287 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,287 [INFO]         \"# \\\"\\\"#!/usr/bin/env python3\\n\",\n",
      "2026-01-21 11:08:44,287 [INFO]         \"# \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,287 [INFO]         \"# Architecture analysis and reduction script (orientation-invariant)\\n\",\n",
      "2026-01-21 11:08:44,288 [INFO]         \"# =================================================================\\n\",\n",
      "2026-01-21 11:08:44,289 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,289 [INFO]         \"# Input:\\n\",\n",
      "2026-01-21 11:08:44,289 [INFO]         \"#   - Annotated neighborhood CSV with taxonomy and architecture labels\\n\",\n",
      "2026-01-21 11:08:44,290 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,290 [INFO]         \"# Output:\\n\",\n",
      "2026-01-21 11:08:44,291 [INFO]         \"#   - Contig-level trimmed & canonical architectures\\n\",\n",
      "2026-01-21 11:08:44,291 [INFO]         \"#   - Lineage-level architecture counts (inverse-collapsed)\\n\",\n",
      "2026-01-21 11:08:44,291 [INFO]         \"#   - Representative contigs per lineage\\n\",\n",
      "2026-01-21 11:08:44,292 [INFO]         \"#   - Gene-level dataframe for plotting\\n\",\n",
      "2026-01-21 11:08:44,292 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,292 [INFO]         \"# Key features:\\n\",\n",
      "2026-01-21 11:08:44,293 [INFO]         \"#   - Flank trimming (k=2)\\n\",\n",
      "2026-01-21 11:08:44,294 [INFO]         \"#   - Orientation-invariant (inverse) collapsing\\n\",\n",
      "2026-01-21 11:08:44,294 [INFO]         \"#   - Counts incorporate reversed architectures\\n\",\n",
      "2026-01-21 11:08:44,294 [INFO]         \"# \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,295 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,295 [INFO]         \"# import pandas as pd\\n\",\n",
      "2026-01-21 11:08:44,296 [INFO]         \"# import logging\\n\",\n",
      "2026-01-21 11:08:44,296 [INFO]         \"# from pathlib import Path\\n\",\n",
      "2026-01-21 11:08:44,297 [INFO]         \"# from datetime import datetime\\n\",\n",
      "2026-01-21 11:08:44,297 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,297 [INFO]         \"# INPUT_CSV = out_csv # Output from previous step with taxonomy [should be [step:8]escrt_neighborhoods_with_taxonomy_{rightnow}.csv]\\n\",\n",
      "2026-01-21 11:08:44,298 [INFO]         \"# OUTDIR = Path(os.path.join(MAIN_OUTDIR, f\\\"architecture_results_{rightnow}\\\"))\\n\",\n",
      "2026-01-21 11:08:44,298 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,299 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,299 [INFO]         \"# OUTDIR.mkdir(exist_ok=True)\\n\",\n",
      "2026-01-21 11:08:44,299 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,300 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,300 [INFO]         \"# STEP += 100\\n\",\n",
      "2026-01-21 11:08:44,301 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,301 [INFO]         \"# # Helper functions\\n\",\n",
      "2026-01-21 11:08:44,302 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,302 [INFO]         \"# def trim_architecture(tokens, k=2):\\n\",\n",
      "2026-01-21 11:08:44,303 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,303 [INFO]         \"#     Trim architecture by keeping at most k 'other' tokens\\n\",\n",
      "2026-01-21 11:08:44,303 [INFO]         \"#     at each flank while retaining internal structure.\\n\",\n",
      "2026-01-21 11:08:44,303 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,304 [INFO]         \"#     tokens = list(tokens)\\n\",\n",
      "2026-01-21 11:08:44,304 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,305 [INFO]         \"#     # Trim left\\n\",\n",
      "2026-01-21 11:08:44,305 [INFO]         \"#     left = 0\\n\",\n",
      "2026-01-21 11:08:44,305 [INFO]         \"#     while left < len(tokens) and tokens[left] == \\\"other\\\":\\n\",\n",
      "2026-01-21 11:08:44,305 [INFO]         \"#         left += 1\\n\",\n",
      "2026-01-21 11:08:44,306 [INFO]         \"#     left = max(0, left - k)\\n\",\n",
      "2026-01-21 11:08:44,306 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,307 [INFO]         \"#     # Trim right\\n\",\n",
      "2026-01-21 11:08:44,307 [INFO]         \"#     right = len(tokens)\\n\",\n",
      "2026-01-21 11:08:44,308 [INFO]         \"#     while right > 0 and tokens[right - 1] == \\\"other\\\":\\n\",\n",
      "2026-01-21 11:08:44,308 [INFO]         \"#         right -= 1\\n\",\n",
      "2026-01-21 11:08:44,309 [INFO]         \"#     right = min(len(tokens), right + k)\\n\",\n",
      "2026-01-21 11:08:44,309 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,310 [INFO]         \"#     return tuple(tokens[left:right])\\n\",\n",
      "2026-01-21 11:08:44,310 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,311 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,311 [INFO]         \"# def canonicalize_architecture(tokens):\\n\",\n",
      "2026-01-21 11:08:44,312 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,312 [INFO]         \"#     Make architecture orientation-invariant by collapsing\\n\",\n",
      "2026-01-21 11:08:44,313 [INFO]         \"#     forward and reverse into a single canonical form.\\n\",\n",
      "2026-01-21 11:08:44,313 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,313 [INFO]         \"#     tokens = tuple(tokens)\\n\",\n",
      "2026-01-21 11:08:44,314 [INFO]         \"#     rev = tokens[::-1]\\n\",\n",
      "2026-01-21 11:08:44,315 [INFO]         \"#     return min(tokens, rev)\\n\",\n",
      "2026-01-21 11:08:44,315 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,316 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,316 [INFO]         \"# # Step 1: Load data\\n\",\n",
      "2026-01-21 11:08:44,316 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,317 [INFO]         \"# logging.info(\\\"Loading annotated neighborhood table\\\")\\n\",\n",
      "2026-01-21 11:08:44,318 [INFO]         \"# df = pd.read_csv(INPUT_CSV)\\n\",\n",
      "2026-01-21 11:08:44,318 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,318 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,319 [INFO]         \"# df['neighbor_architecture'] = df['neighbor_architecture'].str.strip()\\n\",\n",
      "2026-01-21 11:08:44,319 [INFO]         \"# required_cols = {\\n\",\n",
      "2026-01-21 11:08:44,319 [INFO]         \"#     \\\"genome_id_x\\\", \\\"contig\\\", \\\"center_protein\\\",\\n\",\n",
      "2026-01-21 11:08:44,320 [INFO]         \"#     \\\"relative_pos\\\", \\\"neighbor_architecture\\\",\\n\",\n",
      "2026-01-21 11:08:44,321 [INFO]         \"#     LINEAGE_LEVEL\\n\",\n",
      "2026-01-21 11:08:44,321 [INFO]         \"# }\\n\",\n",
      "2026-01-21 11:08:44,322 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,323 [INFO]         \"# missing = required_cols - set(df.columns)\\n\",\n",
      "2026-01-21 11:08:44,323 [INFO]         \"# if missing:\\n\",\n",
      "2026-01-21 11:08:44,323 [INFO]         \"#     raise ValueError(f\\\"Missing required columns: {missing}\\\")\\n\",\n",
      "2026-01-21 11:08:44,324 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,324 [INFO]         \"# logging.info(f\\\"Loaded {len(df)} gene-level rows\\\")\\n\",\n",
      "2026-01-21 11:08:44,325 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,327 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,327 [INFO]         \"# # Step 2: Encode architecture tokens\\n\",\n",
      "2026-01-21 11:08:44,328 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,329 [INFO]         \"# logging.info(\\\"Encoding architecture tokens\\\")\\n\",\n",
      "2026-01-21 11:08:44,329 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,330 [INFO]         \"# df[\\\"arch_token\\\"] = (\\n\",\n",
      "2026-01-21 11:08:44,330 [INFO]         \"#     df[\\\"neighbor_architecture\\\"]\\n\",\n",
      "2026-01-21 11:08:44,331 [INFO]         \"#     .fillna(\\\"other\\\")\\n\",\n",
      "2026-01-21 11:08:44,331 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,332 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,333 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,334 [INFO]         \"# # Step 3: Build contig-level architectures\\n\",\n",
      "2026-01-21 11:08:44,335 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,335 [INFO]         \"# logging.info(\\\"Constructing contig-level architectures\\\")\\n\",\n",
      "2026-01-21 11:08:44,336 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,336 [INFO]         \"# arch_df = (\\n\",\n",
      "2026-01-21 11:08:44,337 [INFO]         \"#     df\\n\",\n",
      "2026-01-21 11:08:44,338 [INFO]         \"#     .sort_values(\\\"relative_pos\\\")\\n\",\n",
      "2026-01-21 11:08:44,338 [INFO]         \"#     .groupby(\\n\",\n",
      "2026-01-21 11:08:44,339 [INFO]         \"#         [\\\"genome_id_x\\\", \\\"contig\\\", \\\"center_protein\\\", LINEAGE_LEVEL],\\n\",\n",
      "2026-01-21 11:08:44,340 [INFO]         \"#         as_index=False\\n\",\n",
      "2026-01-21 11:08:44,341 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:44,341 [INFO]         \"#     .agg(\\n\",\n",
      "2026-01-21 11:08:44,342 [INFO]         \"#         arch_token=(\\\"arch_token\\\", lambda x: tuple(x)),\\n\",\n",
      "2026-01-21 11:08:44,342 [INFO]         \"#         n_genes=(\\\"arch_token\\\", \\\"count\\\")\\n\",\n",
      "2026-01-21 11:08:44,344 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:44,345 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,345 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,346 [INFO]         \"# logging.info(f\\\"Identified {len(arch_df)} contig-level architectures\\\")\\n\",\n",
      "2026-01-21 11:08:44,346 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,346 [INFO]         \"# STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,347 [INFO]         \"# arch_df.to_csv(OUTDIR / f\\\"[STEP:{STEP}]contig_architectures_raw.csv\\\", index=False)\\n\",\n",
      "2026-01-21 11:08:44,347 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,348 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,348 [INFO]         \"# # Step 4: Trim flanks + inverse collapse (CORE STEP)\\n\",\n",
      "2026-01-21 11:08:44,348 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,349 [INFO]         \"# logging.info(\\n\",\n",
      "2026-01-21 11:08:44,349 [INFO]         \"#     f\\\"Trimming architectures (k={FLANK_K}) and collapsing inverses\\\"\\n\",\n",
      "2026-01-21 11:08:44,349 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,350 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,350 [INFO]         \"# arch_df[\\\"arch_token_trimmed\\\"] = arch_df[\\\"arch_token\\\"].apply(\\n\",\n",
      "2026-01-21 11:08:44,351 [INFO]         \"#     lambda x: trim_architecture(x, k=FLANK_K)\\n\",\n",
      "2026-01-21 11:08:44,351 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,352 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,353 [INFO]         \"# arch_df[\\\"arch_token_canonical\\\"] = arch_df[\\\"arch_token_trimmed\\\"].apply(\\n\",\n",
      "2026-01-21 11:08:44,354 [INFO]         \"#     canonicalize_architecture\\n\",\n",
      "2026-01-21 11:08:44,355 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,356 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,356 [INFO]         \"# arch_df[\\\"trimmed_len\\\"] = arch_df[\\\"arch_token_trimmed\\\"].apply(len)\\n\",\n",
      "2026-01-21 11:08:44,356 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,357 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,358 [INFO]         \"# STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,358 [INFO]         \"# arch_df.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,358 [INFO]         \"#     OUTDIR / f\\\"[STEP:{STEP}]contig_architectures_trimmed_canonical.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,359 [INFO]         \"#     index=False\\n\",\n",
      "2026-01-21 11:08:44,359 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,359 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,360 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,360 [INFO]         \"# # Step 5: Count architectures by lineage (INVERSE-AWARE)\\n\",\n",
      "2026-01-21 11:08:44,361 [INFO]         \"# # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,361 [INFO]         \"# logging.info(\\n\",\n",
      "2026-01-21 11:08:44,362 [INFO]         \"#     f\\\"Counting architectures per {LINEAGE_LEVEL} (inverse-aware)\\\"\\n\",\n",
      "2026-01-21 11:08:44,362 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,362 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,363 [INFO]         \"# arch_counts = (\\n\",\n",
      "2026-01-21 11:08:44,364 [INFO]         \"#     arch_df\\n\",\n",
      "2026-01-21 11:08:44,364 [INFO]         \"#     .groupby([LINEAGE_LEVEL, \\\"arch_token_canonical\\\"], as_index=False)\\n\",\n",
      "2026-01-21 11:08:44,364 [INFO]         \"#     .size()\\n\",\n",
      "2026-01-21 11:08:44,365 [INFO]         \"#     .rename(columns={\\\"size\\\": \\\"count\\\"})\\n\",\n",
      "2026-01-21 11:08:44,365 [INFO]         \"#     .sort_values([LINEAGE_LEVEL, \\\"count\\\"], ascending=[True, False])\\n\",\n",
      "2026-01-21 11:08:44,365 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,366 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,366 [INFO]         \"# STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,366 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,368 [INFO]         \"# arch_counts.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,368 [INFO]         \"#     OUTDIR / f\\\"[STEP:{STEP}]architecture_frequencies_inverse_collapsed.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,369 [INFO]         \"#     index=False\\n\",\n",
      "2026-01-21 11:08:44,369 [INFO]         \"# )\\n\",\n",
      "2026-01-21 11:08:44,370 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,370 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,371 [INFO]         \"# # # Step 6: Select representative architecture per lineage\\n\",\n",
      "2026-01-21 11:08:44,371 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,372 [INFO]         \"# # logging.info(\\\"Selecting representative architecture per lineage\\\")\\n\",\n",
      "2026-01-21 11:08:44,372 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,373 [INFO]         \"# # rep_arch = (\\n\",\n",
      "2026-01-21 11:08:44,373 [INFO]         \"# #     arch_counts\\n\",\n",
      "2026-01-21 11:08:44,374 [INFO]         \"# #     .groupby(LINEAGE_LEVEL, as_index=False)\\n\",\n",
      "2026-01-21 11:08:44,374 [INFO]         \"# #     .head(1)\\n\",\n",
      "2026-01-21 11:08:44,375 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,375 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,376 [INFO]         \"# # STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,376 [INFO]         \"# # rep_arch.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,377 [INFO]         \"# #     OUTDIR / f\\\"[STEP:{STEP}]representative_architectures.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,377 [INFO]         \"# #     index=False\\n\",\n",
      "2026-01-21 11:08:44,378 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,378 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,379 [INFO]         \"# # logging.info(f\\\"Selected {len(rep_arch)} representative architectures\\\")\\n\",\n",
      "2026-01-21 11:08:44,379 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,380 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,380 [INFO]         \"# # # Step 7: Recover representative contigs\\n\",\n",
      "2026-01-21 11:08:44,380 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,381 [INFO]         \"# # logging.info(\\\"Recovering representative contigs\\\")\\n\",\n",
      "2026-01-21 11:08:44,381 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,381 [INFO]         \"# # rep_keys = rep_arch.merge(\\n\",\n",
      "2026-01-21 11:08:44,382 [INFO]         \"# #     arch_df,\\n\",\n",
      "2026-01-21 11:08:44,382 [INFO]         \"# #     on=[LINEAGE_LEVEL, \\\"arch_token_canonical\\\"],\\n\",\n",
      "2026-01-21 11:08:44,383 [INFO]         \"# #     how=\\\"left\\\"\\n\",\n",
      "2026-01-21 11:08:44,383 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,384 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,384 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,384 [INFO]         \"# # STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,385 [INFO]         \"# # rep_keys.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,385 [INFO]         \"# #     OUTDIR / f\\\"[STEP:{STEP}]representative_contigs.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,386 [INFO]         \"# #     index=False\\n\",\n",
      "2026-01-21 11:08:44,386 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,386 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,387 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,387 [INFO]         \"# # # Step 8: Recover gene-level rows for plotting\\n\",\n",
      "2026-01-21 11:08:44,388 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,388 [INFO]         \"# # logging.info(\\\"Extracting gene-level rows for plotting\\\")\\n\",\n",
      "2026-01-21 11:08:44,389 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,389 [INFO]         \"# # plot_df = df.merge(\\n\",\n",
      "2026-01-21 11:08:44,389 [INFO]         \"# #     rep_keys[[\\\"genome_id_x\\\", \\\"contig\\\", \\\"center_protein\\\"]],\\n\",\n",
      "2026-01-21 11:08:44,390 [INFO]         \"# #     on=[\\\"genome_id_x\\\", \\\"contig\\\", \\\"center_protein\\\"],\\n\",\n",
      "2026-01-21 11:08:44,390 [INFO]         \"# #     how=\\\"inner\\\"\\n\",\n",
      "2026-01-21 11:08:44,391 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,391 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,391 [INFO]         \"# # plot_df = plot_df.sort_values(\\n\",\n",
      "2026-01-21 11:08:44,392 [INFO]         \"# #     [LINEAGE_LEVEL, \\\"genome_id_x\\\", \\\"contig\\\", \\\"relative_pos\\\"]\\n\",\n",
      "2026-01-21 11:08:44,392 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,392 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,392 [INFO]         \"# # STEP += 1\\n\",\n",
      "2026-01-21 11:08:44,393 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,393 [INFO]         \"# # plot_df.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,394 [INFO]         \"# #     OUTDIR / f\\\"[STEP:{STEP}]plot_ready_architectures.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,394 [INFO]         \"# #     index=False\\n\",\n",
      "2026-01-21 11:08:44,395 [INFO]         \"# # )\\n\",\n",
      "2026-01-21 11:08:44,395 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,396 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,396 [INFO]         \"# # # Summary\\n\",\n",
      "2026-01-21 11:08:44,396 [INFO]         \"# # # ------------------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,397 [INFO]         \"# # logging.info(\\\"Architecture analysis complete\\\")\\n\",\n",
      "2026-01-21 11:08:44,397 [INFO]         \"# # logging.info(f\\\"Results written to: {OUTDIR.resolve()}\\\")\\n\",\n",
      "2026-01-21 11:08:44,397 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,398 [INFO]         \"# # logging.info(\\\"Files generated:\\\")\\n\",\n",
      "2026-01-21 11:08:44,398 [INFO]         \"# # for f in sorted(OUTDIR.iterdir()):\\n\",\n",
      "2026-01-21 11:08:44,399 [INFO]         \"# #     logging.info(f\\\"  - {f.name}\\\")\\n\"\n",
      "2026-01-21 11:08:44,400 [INFO]       ]\n",
      "2026-01-21 11:08:44,400 [INFO]     },\n",
      "2026-01-21 11:08:44,400 [INFO]     {\n",
      "2026-01-21 11:08:44,401 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:44,401 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:44,401 [INFO]       \"id\": \"4d477882\",\n",
      "2026-01-21 11:08:44,402 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:44,402 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:44,403 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:44,403 [INFO]         \"# adding script to the log file\\n\",\n",
      "2026-01-21 11:08:44,403 [INFO]         \"import json\\n\",\n",
      "2026-01-21 11:08:44,404 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,404 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,404 [INFO]         \"# Load the current notebook file (Jupyter notebooks are JSON)\\n\",\n",
      "2026-01-21 11:08:44,405 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,405 [INFO]         \"with open(NOTEBOOK_PATH, \\\"r\\\", encoding=\\\"utf-8\\\") as nb:\\n\",\n",
      "2026-01-21 11:08:44,406 [INFO]         \"    notebook_json = json.load(nb)\\n\",\n",
      "2026-01-21 11:08:44,406 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,407 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,407 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,408 [INFO]         \"# Remove execution outputs from code cells\\n\",\n",
      "2026-01-21 11:08:44,409 [INFO]         \"#   - prevents massive logs\\n\",\n",
      "2026-01-21 11:08:44,409 [INFO]         \"#   - avoids embedding binary blobs (plots, images)\\n\",\n",
      "2026-01-21 11:08:44,410 [INFO]         \"#   - keeps only the executable logic + structure\\n\",\n",
      "2026-01-21 11:08:44,410 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,412 [INFO]         \"def strip_outputs(nb):\\n\",\n",
      "2026-01-21 11:08:44,413 [INFO]         \"    for cell in nb.get(\\\"cells\\\", []):\\n\",\n",
      "2026-01-21 11:08:44,413 [INFO]         \"        if cell.get(\\\"cell_type\\\") == \\\"code\\\":\\n\",\n",
      "2026-01-21 11:08:44,414 [INFO]         \"            cell[\\\"outputs\\\"] = []\\n\",\n",
      "2026-01-21 11:08:44,416 [INFO]         \"            cell[\\\"execution_count\\\"] = None\\n\",\n",
      "2026-01-21 11:08:44,417 [INFO]         \"    return nb\\n\",\n",
      "2026-01-21 11:08:44,417 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,418 [INFO]         \"notebook_json = strip_outputs(notebook_json)\\n\",\n",
      "2026-01-21 11:08:44,419 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,419 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,421 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,421 [INFO]         \"# Serialize notebook JSON to a formatted string\\n\",\n",
      "2026-01-21 11:08:44,422 [INFO]         \"#   - indentation preserves readability in logs\\n\",\n",
      "2026-01-21 11:08:44,422 [INFO]         \"#   - done once to avoid repeated JSON encoding\\n\",\n",
      "2026-01-21 11:08:44,423 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,423 [INFO]         \"notebook_str = json.dumps(notebook_json, indent=2)\\n\",\n",
      "2026-01-21 11:08:44,424 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,427 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,428 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,428 [INFO]         \"# Append notebook snapshot to the log file\\n\",\n",
      "2026-01-21 11:08:44,429 [INFO]         \"#   - logged line-by-line to preserve formatting\\n\",\n",
      "2026-01-21 11:08:44,429 [INFO]         \"#   - ensures compatibility with logging handlers\\n\",\n",
      "2026-01-21 11:08:44,429 [INFO]         \"# ------------------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,430 [INFO]         \"logging.info(\\\"=\\\" * 80)\\n\",\n",
      "2026-01-21 11:08:44,430 [INFO]         \"logging.info(\\\"NOTEBOOK JSON SNAPSHOT (END OF RUN)\\\")\\n\",\n",
      "2026-01-21 11:08:44,430 [INFO]         \"logging.info(\\\"=\\\" * 80)\\n\",\n",
      "2026-01-21 11:08:44,431 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,431 [INFO]         \"for line in notebook_str.splitlines():\\n\",\n",
      "2026-01-21 11:08:44,431 [INFO]         \"    logging.info(line)\\n\"\n",
      "2026-01-21 11:08:44,432 [INFO]       ]\n",
      "2026-01-21 11:08:44,432 [INFO]     },\n",
      "2026-01-21 11:08:44,433 [INFO]     {\n",
      "2026-01-21 11:08:44,433 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:44,434 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:44,434 [INFO]       \"id\": \"89c38cc8\",\n",
      "2026-01-21 11:08:44,435 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:44,435 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:44,436 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:44,437 [INFO]         \"import os\\n\",\n",
      "2026-01-21 11:08:44,437 [INFO]         \"import shutil\\n\",\n",
      "2026-01-21 11:08:44,438 [INFO]         \"import logging\\n\",\n",
      "2026-01-21 11:08:44,438 [INFO]         \"from pathlib import Path\\n\",\n",
      "2026-01-21 11:08:44,439 [INFO]         \"import pandas as pd\\n\",\n",
      "2026-01-21 11:08:44,439 [INFO]         \"from Bio import SeqIO\\n\",\n",
      "2026-01-21 11:08:44,439 [INFO]         \"from Bio.SeqFeature import SeqFeature\\n\",\n",
      "2026-01-21 11:08:44,440 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,440 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,440 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,441 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,441 [INFO]         \"def compress_others(tokens, threshold=10):\\n\",\n",
      "2026-01-21 11:08:44,442 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,442 [INFO]         \"    Compress long runs of 'other' into 'other[n]' if n > threshold.\\n\",\n",
      "2026-01-21 11:08:44,442 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,443 [INFO]         \"    compressed = []\\n\",\n",
      "2026-01-21 11:08:44,443 [INFO]         \"    i = 0\\n\",\n",
      "2026-01-21 11:08:44,444 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,444 [INFO]         \"    while i < len(tokens):\\n\",\n",
      "2026-01-21 11:08:44,445 [INFO]         \"        if tokens[i] != \\\"other\\\":\\n\",\n",
      "2026-01-21 11:08:44,446 [INFO]         \"            compressed.append(tokens[i])\\n\",\n",
      "2026-01-21 11:08:44,446 [INFO]         \"            i += 1\\n\",\n",
      "2026-01-21 11:08:44,447 [INFO]         \"            continue\\n\",\n",
      "2026-01-21 11:08:44,447 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,448 [INFO]         \"        # count run\\n\",\n",
      "2026-01-21 11:08:44,448 [INFO]         \"        j = i\\n\",\n",
      "2026-01-21 11:08:44,449 [INFO]         \"        while j < len(tokens) and tokens[j] == \\\"other\\\":\\n\",\n",
      "2026-01-21 11:08:44,449 [INFO]         \"            j += 1\\n\",\n",
      "2026-01-21 11:08:44,449 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,450 [INFO]         \"        run_len = j - i\\n\",\n",
      "2026-01-21 11:08:44,450 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,450 [INFO]         \"        if run_len > threshold:\\n\",\n",
      "2026-01-21 11:08:44,450 [INFO]         \"            compressed.append(f\\\"other[{run_len}]\\\")\\n\",\n",
      "2026-01-21 11:08:44,451 [INFO]         \"        else:\\n\",\n",
      "2026-01-21 11:08:44,451 [INFO]         \"            compressed.extend([\\\"other\\\"] * run_len)\\n\",\n",
      "2026-01-21 11:08:44,452 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,452 [INFO]         \"        i = j\\n\",\n",
      "2026-01-21 11:08:44,452 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,453 [INFO]         \"    return compressed\\n\",\n",
      "2026-01-21 11:08:44,454 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,454 [INFO]         \"def extract_architecture_full_contig(anchor_df, gff_df, window=5):\\n\",\n",
      "2026-01-21 11:08:44,455 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,455 [INFO]         \"    Extract genomic neighborhoods around ESCRT-related anchor genes.\\n\",\n",
      "2026-01-21 11:08:44,455 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,455 [INFO]         \"    keywords = CORE_TARGETS\\n\",\n",
      "2026-01-21 11:08:44,456 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,457 [INFO]         \"    logging.info(f\\\"Starting neighborhood extraction (\\u00b1{window} genes)\\\")\\n\",\n",
      "2026-01-21 11:08:44,457 [INFO]         \"    logging.info(f\\\"Initial anchors: {len(anchor_df)}\\\")\\n\",\n",
      "2026-01-21 11:08:44,457 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,458 [INFO]         \"    # Filter anchors by keywords\\n\",\n",
      "2026-01-21 11:08:44,458 [INFO]         \"    filtered_anchors = anchor_df[\\n\",\n",
      "2026-01-21 11:08:44,459 [INFO]         \"        anchor_df[\\\"architecture\\\"]\\n\",\n",
      "2026-01-21 11:08:44,459 [INFO]         \"        .astype(str)\\n\",\n",
      "2026-01-21 11:08:44,460 [INFO]         \"        .str.lower()\\n\",\n",
      "2026-01-21 11:08:44,460 [INFO]         \"        .str.contains(\\\"|\\\".join(keywords))\\n\",\n",
      "2026-01-21 11:08:44,461 [INFO]         \"    ].copy()\\n\",\n",
      "2026-01-21 11:08:44,461 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,461 [INFO]         \"    logging.info(f\\\"Anchors after ESCRT filter: {len(filtered_anchors)}\\\")\\n\",\n",
      "2026-01-21 11:08:44,462 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,462 [INFO]         \"    if filtered_anchors.empty:\\n\",\n",
      "2026-01-21 11:08:44,463 [INFO]         \"        logging.error(\\\"No ESCRT-related anchors found\\\")\\n\",\n",
      "2026-01-21 11:08:44,463 [INFO]         \"        sys.exit(1)\\n\",\n",
      "2026-01-21 11:08:44,464 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,464 [INFO]         \"    neighborhoods = []\\n\",\n",
      "2026-01-21 11:08:44,464 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,464 [INFO]         \"    # Group by genome and contig\\n\",\n",
      "2026-01-21 11:08:44,465 [INFO]         \"    for (genome, contig), anchors in filtered_anchors.groupby(\\n\",\n",
      "2026-01-21 11:08:44,465 [INFO]         \"        [\\\"genome_id\\\", \\\"contig\\\"]\\n\",\n",
      "2026-01-21 11:08:44,465 [INFO]         \"    ):\\n\",\n",
      "2026-01-21 11:08:44,466 [INFO]         \"        anchor_indices = anchors[\\\"gene_index\\\"].values\\n\",\n",
      "2026-01-21 11:08:44,466 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,466 [INFO]         \"        # Define window boundaries\\n\",\n",
      "2026-01-21 11:08:44,467 [INFO]         \"        start = anchor_indices.min() - window\\n\",\n",
      "2026-01-21 11:08:44,467 [INFO]         \"        end = anchor_indices.max() + window\\n\",\n",
      "2026-01-21 11:08:44,468 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,469 [INFO]         \"        # Extract all genes in the window from gff_df\\n\",\n",
      "2026-01-21 11:08:44,469 [INFO]         \"        block = gff_df[\\n\",\n",
      "2026-01-21 11:08:44,470 [INFO]         \"            (gff_df[\\\"genome_id\\\"] == genome) &\\n\",\n",
      "2026-01-21 11:08:44,470 [INFO]         \"            (gff_df[\\\"contig\\\"] == contig) &\\n\",\n",
      "2026-01-21 11:08:44,470 [INFO]         \"            (gff_df[\\\"gene_index\\\"].between(start, end))\\n\",\n",
      "2026-01-21 11:08:44,471 [INFO]         \"        ].copy()\\n\",\n",
      "2026-01-21 11:08:44,471 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,472 [INFO]         \"        if block.empty:\\n\",\n",
      "2026-01-21 11:08:44,472 [INFO]         \"            continue\\n\",\n",
      "2026-01-21 11:08:44,473 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,473 [INFO]         \"        # Sort by gene position\\n\",\n",
      "2026-01-21 11:08:44,473 [INFO]         \"        block = block.sort_values(\\\"gene_index\\\").reset_index(drop=True)\\n\",\n",
      "2026-01-21 11:08:44,474 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,474 [INFO]         \"        # Create a mapping of protein_id to architecture from ALL anchors\\n\",\n",
      "2026-01-21 11:08:44,474 [INFO]         \"        # (not just filtered ones), so we get complete architecture info\\n\",\n",
      "2026-01-21 11:08:44,475 [INFO]         \"        arch_map = anchor_df.set_index(\\\"protein_id\\\")[\\\"architecture\\\"].to_dict()\\n\",\n",
      "2026-01-21 11:08:44,475 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,476 [INFO]         \"        # Apply architecture: use anchor architecture if available, else \\\"other\\\"\\n\",\n",
      "2026-01-21 11:08:44,476 [INFO]         \"        block[\\\"architecture\\\"] = block[\\\"protein_id\\\"].map(arch_map).fillna(\\\"other\\\")\\n\",\n",
      "2026-01-21 11:08:44,476 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,477 [INFO]         \"        # Build architecture token list for the ENTIRE neighborhood\\n\",\n",
      "2026-01-21 11:08:44,477 [INFO]         \"        tokens = block[\\\"architecture\\\"].tolist()\\n\",\n",
      "2026-01-21 11:08:44,478 [INFO]         \"        compressed_tokens = compress_others(tokens, threshold=10)\\n\",\n",
      "2026-01-21 11:08:44,478 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,478 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,479 [INFO]         \"        # Add metadata about the neighborhood\\n\",\n",
      "2026-01-21 11:08:44,479 [INFO]         \"        block[\\\"num_anchors\\\"] = len(anchors)\\n\",\n",
      "2026-01-21 11:08:44,479 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,480 [INFO]         \"        block[\\\"window_start\\\"] = start\\n\",\n",
      "2026-01-21 11:08:44,480 [INFO]         \"        block[\\\"window_end\\\"] = end\\n\",\n",
      "2026-01-21 11:08:44,481 [INFO]         \"        block[\\\"neighborhood_architecture_compressed\\\"] = \\\",\\\".join(compressed_tokens)\\n\",\n",
      "2026-01-21 11:08:44,481 [INFO]         \"        block[\\\"position_in_neighborhood\\\"] = range(len(block))\\n\",\n",
      "2026-01-21 11:08:44,482 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,482 [INFO]         \"        neighborhoods.append(block)\\n\",\n",
      "2026-01-21 11:08:44,482 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,483 [INFO]         \"    if not neighborhoods:\\n\",\n",
      "2026-01-21 11:08:44,483 [INFO]         \"        logging.error(\\\"No neighborhoods extracted after processing\\\")\\n\",\n",
      "2026-01-21 11:08:44,484 [INFO]         \"        sys.exit(1)\\n\",\n",
      "2026-01-21 11:08:44,484 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,484 [INFO]         \"    combined = pd.concat(neighborhoods, ignore_index=True)\\n\",\n",
      "2026-01-21 11:08:44,485 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,485 [INFO]         \"    logging.info(\\n\",\n",
      "2026-01-21 11:08:44,486 [INFO]         \"        f\\\"Extracted {len(combined)} genes from \\\"\\n\",\n",
      "2026-01-21 11:08:44,486 [INFO]         \"        f\\\"{len(neighborhoods)} contig neighborhoods\\\"\\n\",\n",
      "2026-01-21 11:08:44,486 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:44,487 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,487 [INFO]         \"    return combined\\n\",\n",
      "2026-01-21 11:08:44,487 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,488 [INFO]         \"# -----------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,488 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,488 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,489 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,490 [INFO]         \"# merge rep_genomes with anchor_df on genome_id\\n\",\n",
      "2026-01-21 11:08:44,491 [INFO]         \"print(anchor_df.columns)\\n\",\n",
      "2026-01-21 11:08:44,491 [INFO]         \"print(rep_genomes.columns)\\n\",\n",
      "2026-01-21 11:08:44,492 [INFO]         \"rep_genomes_anchor = (\\n\",\n",
      "2026-01-21 11:08:44,492 [INFO]         \"    rep_genomes\\n\",\n",
      "2026-01-21 11:08:44,493 [INFO]         \"    .merge(\\n\",\n",
      "2026-01-21 11:08:44,494 [INFO]         \"        anchor_df.drop_duplicates(),\\n\",\n",
      "2026-01-21 11:08:44,495 [INFO]         \"        left_on=[\\\"genome_id_x\\\", \\\"contig\\\"],\\n\",\n",
      "2026-01-21 11:08:44,496 [INFO]         \"        right_on=[\\\"genome_id\\\", \\\"contig\\\"],\\n\",\n",
      "2026-01-21 11:08:44,497 [INFO]         \"        how=\\\"inner\\\"\\n\",\n",
      "2026-01-21 11:08:44,498 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:44,498 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,499 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,500 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,500 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,501 [INFO]         \"logging.info(\\n\",\n",
      "2026-01-21 11:08:44,501 [INFO]         \"    \\\"Representative genomes retained: %d\\\",\\n\",\n",
      "2026-01-21 11:08:44,502 [INFO]         \"    rep_genomes_anchor[\\\"genome_id_x\\\"].nunique()\\n\",\n",
      "2026-01-21 11:08:44,502 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,503 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,503 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,505 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,505 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,506 [INFO]         \"# Extract full contig architecture to modify gbk files\\n\",\n",
      "2026-01-21 11:08:44,507 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,508 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,509 [INFO]         \"gff_dir = Path(\\\"/home/anirudh/genomes/selected_genomes/prokka_results\\\")\\n\",\n",
      "2026-01-21 11:08:44,509 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,509 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,510 [INFO]         \"# --------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,510 [INFO]         \"# Load GFFs\\n\",\n",
      "2026-01-21 11:08:44,510 [INFO]         \"# --------------------------------------------------------\\n\",\n",
      "2026-01-21 11:08:44,511 [INFO]         \"logging.info(\\\"\\\\n[STEP 1] Loading GFF files...\\\")\\n\",\n",
      "2026-01-21 11:08:44,511 [INFO]         \"gff_df = load_gffs_from_hits(rep_genomes_anchor, gff_dir)\\n\",\n",
      "2026-01-21 11:08:44,512 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,512 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,513 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,513 [INFO]         \"rep_df = extract_architecture_full_contig(rep_genomes_anchor, gff_df, window=1000)\\n\",\n",
      "2026-01-21 11:08:44,513 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,514 [INFO]         \"rep_df.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,514 [INFO]         \"    OUTDIR / f\\\"[STEP:{STEP}]representative_genomes_full_contig_architectures.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,515 [INFO]         \"    index=False\\n\",\n",
      "2026-01-21 11:08:44,515 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,515 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,516 [INFO]         \"print(\\\"df:\\\", df.columns)\\n\",\n",
      "2026-01-21 11:08:44,516 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,517 [INFO]         \"# taxonomy_df must have genome_id and family\\n\",\n",
      "2026-01-21 11:08:44,517 [INFO]         \"taxonomy_df = df[[\\\"genome_id_x\\\", \\\"family\\\"]].drop_duplicates()\\n\",\n",
      "2026-01-21 11:08:44,517 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,518 [INFO]         \"rep_df = rep_df.merge(\\n\",\n",
      "2026-01-21 11:08:44,518 [INFO]         \"    taxonomy_df,\\n\",\n",
      "2026-01-21 11:08:44,519 [INFO]         \"    left_on=\\\"genome_id\\\",\\n\",\n",
      "2026-01-21 11:08:44,519 [INFO]         \"    right_on=\\\"genome_id_x\\\",\\n\",\n",
      "2026-01-21 11:08:44,520 [INFO]         \"    how=\\\"left\\\"\\n\",\n",
      "2026-01-21 11:08:44,520 [INFO]         \")\\n\",\n",
      "2026-01-21 11:08:44,522 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,522 [INFO]         \"# sanity check\\n\",\n",
      "2026-01-21 11:08:44,523 [INFO]         \"if rep_df[\\\"family\\\"].isna().any():\\n\",\n",
      "2026-01-21 11:08:44,523 [INFO]         \"    raise RuntimeError(\\\"Some rows in rep_df are missing family taxonomy\\\")\\n\",\n",
      "2026-01-21 11:08:44,524 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,524 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,525 [INFO]         \"# yield a csv file for gene function annotation in clinker protein_id, protein_name\\n\",\n",
      "2026-01-21 11:08:44,525 [INFO]         \"print(\\\"rep_df columns:\\\", rep_df.head(10))\\n\",\n",
      "2026-01-21 11:08:44,525 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,526 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,526 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,527 [INFO]         \"annotation_df = rep_df[[\\\"protein_id\\\", \\\"architecture\\\"]].drop_duplicates()\\n\",\n",
      "2026-01-21 11:08:44,527 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,527 [INFO]         \"annotation_df = annotation_df[annotation_df[\\\"architecture\\\"] != \\\"other\\\"]\\n\",\n",
      "2026-01-21 11:08:44,528 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,528 [INFO]         \"annotation_csv =  OUTDIR / f\\\"[STEP:{STEP}.9]representative_genomes_gene_function_annotation.csv\\\",\\n\",\n",
      "2026-01-21 11:08:44,529 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,529 [INFO]         \"annotation_df.to_csv(\\n\",\n",
      "2026-01-21 11:08:44,529 [INFO]         \"    annotation_csv,\\n\",\n",
      "2026-01-21 11:08:44,530 [INFO]         \"    index=False\\n\",\n",
      "2026-01-21 11:08:44,530 [INFO]         \")\\n\"\n",
      "2026-01-21 11:08:44,531 [INFO]       ]\n",
      "2026-01-21 11:08:44,531 [INFO]     },\n",
      "2026-01-21 11:08:44,531 [INFO]     {\n",
      "2026-01-21 11:08:44,532 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:44,532 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:44,533 [INFO]       \"id\": \"511f4812\",\n",
      "2026-01-21 11:08:44,533 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:44,533 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:44,534 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:44,534 [INFO]         \"from pathlib import Path\\n\",\n",
      "2026-01-21 11:08:44,535 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,535 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,535 [INFO]         \"MAIN_OUTDIR = Path(MAIN_OUTDIR)\\n\",\n",
      "2026-01-21 11:08:44,536 [INFO]         \"GBK_OUT_DIR = MAIN_OUTDIR / f\\\"gbk_family_organized_{rightnow}\\\"\\n\",\n",
      "2026-01-21 11:08:44,536 [INFO]         \"GBK_OUT_DIR.mkdir(exist_ok=True)\\n\",\n",
      "2026-01-21 11:08:44,536 [INFO]         \"gbk_out = MAIN_OUTDIR / \\\"GBK_patched_dir\\\"\\n\",\n",
      "2026-01-21 11:08:44,537 [INFO]         \"gbk_out.mkdir(exist_ok=True)\\n\",\n",
      "2026-01-21 11:08:44,537 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,538 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,538 [INFO]         \"# Copy GBK files organized by family\\n\",\n",
      "2026-01-21 11:08:44,539 [INFO]         \"for family, fam_df in rep_df.groupby(\\\"family\\\"):\\n\",\n",
      "2026-01-21 11:08:44,539 [INFO]         \"    fam_dir = GBK_OUT_DIR / family\\n\",\n",
      "2026-01-21 11:08:44,540 [INFO]         \"    fam_dir.mkdir(exist_ok=True)\\n\",\n",
      "2026-01-21 11:08:44,540 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,541 [INFO]         \"    for genome in fam_df[\\\"genome_id\\\"].unique():  # Fixed: removed _x suffix\\n\",\n",
      "2026-01-21 11:08:44,541 [INFO]         \"        src_gbk = gff_dir / f\\\"{genome}_genomic\\\" / f\\\"{genome}_genomic.gbk\\\"\\n\",\n",
      "2026-01-21 11:08:44,542 [INFO]         \"        dst_gbk = fam_dir / f\\\"{genome}.gbk\\\"\\n\",\n",
      "2026-01-21 11:08:44,542 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,544 [INFO]         \"        if not src_gbk.exists():\\n\",\n",
      "2026-01-21 11:08:44,544 [INFO]         \"            logging.warning(\\\"Missing GBK: %s\\\", src_gbk)\\n\",\n",
      "2026-01-21 11:08:44,544 [INFO]         \"            continue\\n\",\n",
      "2026-01-21 11:08:44,545 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,545 [INFO]         \"        shutil.copy(src_gbk, dst_gbk)\\n\",\n",
      "2026-01-21 11:08:44,545 [INFO]         \"        logging.info(f\\\"Copied {genome}.gbk to {family}/\\\")\\n\",\n",
      "2026-01-21 11:08:44,546 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,546 [INFO]         \"logging.info(\\\"GBK files copied into family directories\\\")\\n\"\n",
      "2026-01-21 11:08:44,546 [INFO]       ]\n",
      "2026-01-21 11:08:44,547 [INFO]     },\n",
      "2026-01-21 11:08:44,548 [INFO]     {\n",
      "2026-01-21 11:08:44,548 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:44,549 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:44,549 [INFO]       \"id\": \"39c503b6\",\n",
      "2026-01-21 11:08:44,550 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:44,550 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:44,551 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:44,551 [INFO]         \"# from Bio import SeqIO\\n\",\n",
      "2026-01-21 11:08:44,551 [INFO]         \"# from tqdm import tqdm\\n\",\n",
      "2026-01-21 11:08:44,552 [INFO]         \"# import logging\\n\",\n",
      "2026-01-21 11:08:44,552 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,552 [INFO]         \"# def has_gene(record):\\n\",\n",
      "2026-01-21 11:08:44,553 [INFO]         \"#     \\\"\\\"\\\"Check if a record has any CDS or gene features.\\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,553 [INFO]         \"#     return any(\\n\",\n",
      "2026-01-21 11:08:44,554 [INFO]         \"#         f.type in {\\\"CDS\\\", \\\"gene\\\"} \\n\",\n",
      "2026-01-21 11:08:44,555 [INFO]         \"#         for f in record.features\\n\",\n",
      "2026-01-21 11:08:44,555 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:44,556 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,556 [INFO]         \"# def patch_gbk_with_architecture(\\n\",\n",
      "2026-01-21 11:08:44,556 [INFO]         \"#     gbk_path,\\n\",\n",
      "2026-01-21 11:08:44,557 [INFO]         \"#     arch_df,\\n\",\n",
      "2026-01-21 11:08:44,557 [INFO]         \"#     protein_col=\\\"protein_id\\\",\\n\",\n",
      "2026-01-21 11:08:44,558 [INFO]         \"#     arch_col=\\\"architecture\\\",\\n\",\n",
      "2026-01-21 11:08:44,558 [INFO]         \"#     rep_col=\\\"rep_arch_canonical\\\"\\n\",\n",
      "2026-01-21 11:08:44,558 [INFO]         \"# ):\\n\",\n",
      "2026-01-21 11:08:44,559 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,559 [INFO]         \"#     Patch GenBank file with architecture annotations.\\n\",\n",
      "2026-01-21 11:08:44,559 [INFO]         \"#     Modifies CDS features to include architecture information.\\n\",\n",
      "2026-01-21 11:08:44,560 [INFO]         \"#     Filters out empty contigs after patching.\\n\",\n",
      "2026-01-21 11:08:44,560 [INFO]         \"#     \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,560 [INFO]         \"#     print(arch_df.columns)\\n\",\n",
      "2026-01-21 11:08:44,560 [INFO]         \"#     # Create lookup dictionary\\n\",\n",
      "2026-01-21 11:08:44,561 [INFO]         \"#     lookup = arch_df.set_index(protein_col).to_dict(\\\"index\\\")\\n\",\n",
      "2026-01-21 11:08:44,561 [INFO]         \"#     logging.info(f\\\"Lookup keys sample: {list(lookup.keys())[:5]}\\\")\\n\",\n",
      "2026-01-21 11:08:44,561 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,562 [INFO]         \"#     logging.info(f\\\"Patching {gbk_path.name} with {len(lookup)} annotated proteins\\\")\\n\",\n",
      "2026-01-21 11:08:44,563 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,563 [INFO]         \"#     records = []\\n\",\n",
      "2026-01-21 11:08:44,564 [INFO]         \"#     total_genes_found = 0\\n\",\n",
      "2026-01-21 11:08:44,564 [INFO]         \"#     total_genes_annotated = 0\\n\",\n",
      "2026-01-21 11:08:44,564 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,565 [INFO]         \"#     for record in SeqIO.parse(gbk_path, \\\"genbank\\\"):\\n\",\n",
      "2026-01-21 11:08:44,565 [INFO]         \"#         new_features = []\\n\",\n",
      "2026-01-21 11:08:44,565 [INFO]         \"#         genes_found = 0\\n\",\n",
      "2026-01-21 11:08:44,566 [INFO]         \"#         genes_annotated = 0\\n\",\n",
      "2026-01-21 11:08:44,566 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,566 [INFO]         \"#         for feat in record.features:\\n\",\n",
      "2026-01-21 11:08:44,567 [INFO]         \"#             # Keep non-CDS features as-is\\n\",\n",
      "2026-01-21 11:08:44,567 [INFO]         \"#             if feat.type != \\\"CDS\\\":\\n\",\n",
      "2026-01-21 11:08:44,568 [INFO]         \"#                 new_features.append(feat)\\n\",\n",
      "2026-01-21 11:08:44,569 [INFO]         \"#                 continue\\n\",\n",
      "2026-01-21 11:08:44,569 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,569 [INFO]         \"#             genes_found += 1\\n\",\n",
      "2026-01-21 11:08:44,570 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,570 [INFO]         \"#             # Get protein_id from the CDS feature\\n\",\n",
      "2026-01-21 11:08:44,571 [INFO]         \"#             pid = feat.qualifiers.get(\\\"locus_tag\\\", [None])[0]\\n\",\n",
      "2026-01-21 11:08:44,571 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,571 [INFO]         \"#             if pid is None or pid not in lookup:\\n\",\n",
      "2026-01-21 11:08:44,572 [INFO]         \"#                 # Gene is outside annotation windows - skip\\n\",\n",
      "2026-01-21 11:08:44,572 [INFO]         \"#                 continue\\n\",\n",
      "2026-01-21 11:08:44,574 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,575 [INFO]         \"#             # Get architecture info\\n\",\n",
      "2026-01-21 11:08:44,576 [INFO]         \"#             info = lookup[pid]\\n\",\n",
      "2026-01-21 11:08:44,577 [INFO]         \"#             arch = info.get(arch_col, \\\"other\\\")\\n\",\n",
      "2026-01-21 11:08:44,578 [INFO]         \"#             rep = info.get(rep_col, \\\"NA\\\")\\n\",\n",
      "2026-01-21 11:08:44,579 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,580 [INFO]         \"#             genes_annotated += 1\\n\",\n",
      "2026-01-21 11:08:44,580 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,581 [INFO]         \"#             # Modify the CDS feature qualifiers\\n\",\n",
      "2026-01-21 11:08:44,582 [INFO]         \"#             if arch != \\\"other\\\":\\n\",\n",
      "2026-01-21 11:08:44,582 [INFO]         \"#                 feat.qualifiers[\\\"gene\\\"] = [arch]\\n\",\n",
      "2026-01-21 11:08:44,583 [INFO]         \"#                 feat.qualifiers[\\\"product\\\"] = [arch]\\n\",\n",
      "2026-01-21 11:08:44,583 [INFO]         \"#             else:\\n\",\n",
      "2026-01-21 11:08:44,584 [INFO]         \"#                 continue\\n\",\n",
      "2026-01-21 11:08:44,585 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,585 [INFO]         \"#             # Add architecture notes\\n\",\n",
      "2026-01-21 11:08:44,586 [INFO]         \"#             if \\\"note\\\" not in feat.qualifiers:\\n\",\n",
      "2026-01-21 11:08:44,586 [INFO]         \"#                 feat.qualifiers[\\\"note\\\"] = []\\n\",\n",
      "2026-01-21 11:08:44,587 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,588 [INFO]         \"#             feat.qualifiers[\\\"note\\\"].append(f\\\"architecture={arch}\\\")\\n\",\n",
      "2026-01-21 11:08:44,589 [INFO]         \"#             if rep != \\\"NA\\\":\\n\",\n",
      "2026-01-21 11:08:44,589 [INFO]         \"#                 feat.qualifiers[\\\"note\\\"].append(f\\\"representative_arch={rep}\\\")\\n\",\n",
      "2026-01-21 11:08:44,590 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,590 [INFO]         \"#             new_features.append(feat)\\n\",\n",
      "2026-01-21 11:08:44,591 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,591 [INFO]         \"#         record.features = new_features\\n\",\n",
      "2026-01-21 11:08:44,592 [INFO]         \"#         total_genes_found += genes_found\\n\",\n",
      "2026-01-21 11:08:44,592 [INFO]         \"#         total_genes_annotated += genes_annotated\\n\",\n",
      "2026-01-21 11:08:44,593 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,593 [INFO]         \"#         # Only keep records that have genes after patching\\n\",\n",
      "2026-01-21 11:08:44,594 [INFO]         \"#         if has_gene(record):\\n\",\n",
      "2026-01-21 11:08:44,595 [INFO]         \"#             records.append(record)\\n\",\n",
      "2026-01-21 11:08:44,595 [INFO]         \"#             logging.info(\\n\",\n",
      "2026-01-21 11:08:44,595 [INFO]         \"#                 f\\\"  {record.id}: {genes_annotated}/{genes_found} genes annotated - KEPT\\\"\\n\",\n",
      "2026-01-21 11:08:44,596 [INFO]         \"#             )\\n\",\n",
      "2026-01-21 11:08:44,596 [INFO]         \"#         else:\\n\",\n",
      "2026-01-21 11:08:44,597 [INFO]         \"#             logging.info(\\n\",\n",
      "2026-01-21 11:08:44,597 [INFO]         \"#                 f\\\"  {record.id}: {genes_annotated}/{genes_found} genes annotated - REMOVED (empty)\\\"\\n\",\n",
      "2026-01-21 11:08:44,598 [INFO]         \"#             )\\n\",\n",
      "2026-01-21 11:08:44,598 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,598 [INFO]         \"#     gbk_file = gbk_out / f\\\"{arch_df['family'].unique()[0]}_patched.gbk\\\"\\n\",\n",
      "2026-01-21 11:08:44,598 [INFO]         \"#     print(gbk_file)\\n\",\n",
      "2026-01-21 11:08:44,599 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,600 [INFO]         \"#     out_gbk_path = gbk_file\\n\",\n",
      "2026-01-21 11:08:44,601 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,601 [INFO]         \"#     # Write modified records back\\n\",\n",
      "2026-01-21 11:08:44,602 [INFO]         \"#     with open(out_gbk_path, \\\"w\\\") as out_handle:\\n\",\n",
      "2026-01-21 11:08:44,602 [INFO]         \"#         SeqIO.write(records, out_handle, \\\"genbank\\\")\\n\",\n",
      "2026-01-21 11:08:44,603 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,603 [INFO]         \"#     logging.info(\\n\",\n",
      "2026-01-21 11:08:44,604 [INFO]         \"#         f\\\"Successfully patched {gbk_path.name}: \\\"\\n\",\n",
      "2026-01-21 11:08:44,605 [INFO]         \"#         f\\\"kept {len(records)} contigs, \\\"\\n\",\n",
      "2026-01-21 11:08:44,605 [INFO]         \"#         f\\\"annotated {total_genes_annotated}/{total_genes_found} genes\\\"\\n\",\n",
      "2026-01-21 11:08:44,605 [INFO]         \"#     )\\n\",\n",
      "2026-01-21 11:08:44,605 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,606 [INFO]         \"#     return len(records), total_genes_annotated\\n\",\n",
      "2026-01-21 11:08:44,606 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,607 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,607 [INFO]         \"# # Patch all GBK files with architecture annotations\\n\",\n",
      "2026-01-21 11:08:44,608 [INFO]         \"# for family, fam_df in tqdm(rep_df.groupby(\\\"family\\\")):\\n\",\n",
      "2026-01-21 11:08:44,608 [INFO]         \"#     fam_dir = GBK_OUT_DIR / family\\n\",\n",
      "2026-01-21 11:08:44,608 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,609 [INFO]         \"#     logging.info(f\\\"Patching family: {family} ({len(fam_df)} annotations)\\\")\\n\",\n",
      "2026-01-21 11:08:44,609 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,610 [INFO]         \"#     for gbk_file in fam_dir.glob(\\\"*.gbk\\\"):\\n\",\n",
      "2026-01-21 11:08:44,610 [INFO]         \"#         # Extract genome_id from filename\\n\",\n",
      "2026-01-21 11:08:44,610 [INFO]         \"#         genome_id = gbk_file.stem  # removes .gbk extension\\n\",\n",
      "2026-01-21 11:08:44,611 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,611 [INFO]         \"#         # Filter annotations for this specific genome\\n\",\n",
      "2026-01-21 11:08:44,612 [INFO]         \"#         genome_df = fam_df[fam_df[\\\"genome_id\\\"] == genome_id]\\n\",\n",
      "2026-01-21 11:08:44,613 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,613 [INFO]         \"#         if genome_df.empty:\\n\",\n",
      "2026-01-21 11:08:44,614 [INFO]         \"#             logging.warning(f\\\"No annotations found for {genome_id}, skipping\\\")\\n\",\n",
      "2026-01-21 11:08:44,614 [INFO]         \"#             continue\\n\",\n",
      "2026-01-21 11:08:44,615 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,615 [INFO]         \"#         num_contigs, num_genes = patch_gbk_with_architecture(\\n\",\n",
      "2026-01-21 11:08:44,616 [INFO]         \"#             gbk_path=gbk_file,\\n\",\n",
      "2026-01-21 11:08:44,616 [INFO]         \"#             arch_df=genome_df\\n\",\n",
      "2026-01-21 11:08:44,617 [INFO]         \"#         )\\n\",\n",
      "2026-01-21 11:08:44,617 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,618 [INFO]         \"# logging.info(\\\"All GBK files patched with architecture annotations and filtered\\\")\"\n",
      "2026-01-21 11:08:44,619 [INFO]       ]\n",
      "2026-01-21 11:08:44,619 [INFO]     },\n",
      "2026-01-21 11:08:44,619 [INFO]     {\n",
      "2026-01-21 11:08:44,620 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:44,620 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:44,621 [INFO]       \"id\": \"a20f7820\",\n",
      "2026-01-21 11:08:44,621 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:44,622 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:44,622 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:44,623 [INFO]         \"from Bio import SeqIO\\n\",\n",
      "2026-01-21 11:08:44,623 [INFO]         \"from Bio.SeqFeature import SeqFeature, FeatureLocation\\n\",\n",
      "2026-01-21 11:08:44,623 [INFO]         \"from Bio.Seq import Seq\\n\",\n",
      "2026-01-21 11:08:44,624 [INFO]         \"from tqdm import tqdm\\n\",\n",
      "2026-01-21 11:08:44,624 [INFO]         \"import logging\\n\",\n",
      "2026-01-21 11:08:44,625 [INFO]         \"import time\\n\",\n",
      "2026-01-21 11:08:44,625 [INFO]         \"import random\\n\",\n",
      "2026-01-21 11:08:44,625 [INFO]         \"# ============================================================================\\n\",\n",
      "2026-01-21 11:08:44,626 [INFO]         \"# CONFIGURATION PARAMETERS\\n\",\n",
      "2026-01-21 11:08:44,626 [INFO]         \"# ============================================================================\\n\",\n",
      "2026-01-21 11:08:44,626 [INFO]         \"UPSTREAM_BUFFER = 1000      # Max bp to keep upstream of first gene\\n\",\n",
      "2026-01-21 11:08:44,627 [INFO]         \"GAP_THRESHOLD = 10000       # Gap size that triggers truncation (25kb)\\n\",\n",
      "2026-01-21 11:08:44,627 [INFO]         \"GAP_BUFFER = 1000           # bp to keep on each side of truncated gap\\n\",\n",
      "2026-01-21 11:08:44,628 [INFO]         \"MIN_CONTIG_SIZE = 0         # Minimum contig size after truncation (0 = no limit)\\n\",\n",
      "2026-01-21 11:08:44,628 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,629 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,629 [INFO]         \"# ============================================================================\\n\",\n",
      "2026-01-21 11:08:44,630 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,630 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,631 [INFO]         \"class GapStringGenerator:\\n\",\n",
      "2026-01-21 11:08:44,631 [INFO]         \"    \\\"\\\"\\\"Generates gap strings with minimal similarity to existing gaps\\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,631 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,632 [INFO]         \"    def __init__(self, gap_size, num_candidates=500):\\n\",\n",
      "2026-01-21 11:08:44,632 [INFO]         \"        \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,633 [INFO]         \"        Args:\\n\",\n",
      "2026-01-21 11:08:44,633 [INFO]         \"            gap_size: Length of each gap string\\n\",\n",
      "2026-01-21 11:08:44,633 [INFO]         \"            num_candidates: Number of candidates to evaluate per generation\\n\",\n",
      "2026-01-21 11:08:44,634 [INFO]         \"        \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,634 [INFO]         \"        self.gap_size = gap_size\\n\",\n",
      "2026-01-21 11:08:44,635 [INFO]         \"        self.num_candidates = num_candidates\\n\",\n",
      "2026-01-21 11:08:44,635 [INFO]         \"        self.existing_gaps = []\\n\",\n",
      "2026-01-21 11:08:44,635 [INFO]         \"        self.nucleotides = ['A', 'C', 'G', 'T']\\n\",\n",
      "2026-01-21 11:08:44,636 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,636 [INFO]         \"    def get_next_gap(self):\\n\",\n",
      "2026-01-21 11:08:44,637 [INFO]         \"        \\\"\\\"\\\"Generate and return the next gap string\\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,637 [INFO]         \"        if len(self.existing_gaps) == 0:\\n\",\n",
      "2026-01-21 11:08:44,637 [INFO]         \"            # First gap is random\\n\",\n",
      "2026-01-21 11:08:44,638 [INFO]         \"            gap = self._random_gap()\\n\",\n",
      "2026-01-21 11:08:44,638 [INFO]         \"        else:\\n\",\n",
      "2026-01-21 11:08:44,639 [INFO]         \"            # Find gap with minimal similarity to existing gaps\\n\",\n",
      "2026-01-21 11:08:44,639 [INFO]         \"            gap = self._find_dissimilar_gap()\\n\",\n",
      "2026-01-21 11:08:44,640 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,640 [INFO]         \"        self.existing_gaps.append(gap)\\n\",\n",
      "2026-01-21 11:08:44,640 [INFO]         \"        return gap\\n\",\n",
      "2026-01-21 11:08:44,641 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,641 [INFO]         \"    def _random_gap(self):\\n\",\n",
      "2026-01-21 11:08:44,641 [INFO]         \"        \\\"\\\"\\\"Generate a random nucleotide string\\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,642 [INFO]         \"        return ''.join(random.choices(self.nucleotides, k=self.gap_size))\\n\",\n",
      "2026-01-21 11:08:44,642 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,643 [INFO]         \"    def _find_dissimilar_gap(self):\\n\",\n",
      "2026-01-21 11:08:44,643 [INFO]         \"        \\\"\\\"\\\"Find the most dissimilar gap from candidates\\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,644 [INFO]         \"        best_gap = None\\n\",\n",
      "2026-01-21 11:08:44,644 [INFO]         \"        best_min_dissimilarity = -1\\n\",\n",
      "2026-01-21 11:08:44,644 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,645 [INFO]         \"        for _ in range(self.num_candidates):\\n\",\n",
      "2026-01-21 11:08:44,645 [INFO]         \"            candidate = self._random_gap()\\n\",\n",
      "2026-01-21 11:08:44,645 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,646 [INFO]         \"            # Find minimum dissimilarity to any existing gap\\n\",\n",
      "2026-01-21 11:08:44,646 [INFO]         \"            min_dissimilarity = min(\\n\",\n",
      "2026-01-21 11:08:44,646 [INFO]         \"                self._hamming_distance(candidate, existing)\\n\",\n",
      "2026-01-21 11:08:44,647 [INFO]         \"                for existing in self.existing_gaps\\n\",\n",
      "2026-01-21 11:08:44,647 [INFO]         \"            )\\n\",\n",
      "2026-01-21 11:08:44,648 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,648 [INFO]         \"            # Keep candidate with highest minimum dissimilarity\\n\",\n",
      "2026-01-21 11:08:44,649 [INFO]         \"            if min_dissimilarity > best_min_dissimilarity:\\n\",\n",
      "2026-01-21 11:08:44,649 [INFO]         \"                best_min_dissimilarity = min_dissimilarity\\n\",\n",
      "2026-01-21 11:08:44,649 [INFO]         \"                best_gap = candidate\\n\",\n",
      "2026-01-21 11:08:44,650 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,650 [INFO]         \"        return best_gap\\n\",\n",
      "2026-01-21 11:08:44,651 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,651 [INFO]         \"    def _hamming_distance(self, s1, s2):\\n\",\n",
      "2026-01-21 11:08:44,651 [INFO]         \"        \\\"\\\"\\\"Calculate number of differing positions\\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,652 [INFO]         \"        return sum(c1 != c2 for c1, c2 in zip(s1, s2))\\n\",\n",
      "2026-01-21 11:08:44,652 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,652 [INFO]         \"    def reset(self):\\n\",\n",
      "2026-01-21 11:08:44,653 [INFO]         \"        \\\"\\\"\\\"Clear all existing gaps and start fresh\\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,654 [INFO]         \"        self.existing_gaps = []\\n\",\n",
      "2026-01-21 11:08:44,654 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,654 [INFO]         \"    def get_gap_count(self):\\n\",\n",
      "2026-01-21 11:08:44,655 [INFO]         \"        \\\"\\\"\\\"Return number of gaps generated so far\\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,655 [INFO]         \"        return len(self.existing_gaps)\\n\",\n",
      "2026-01-21 11:08:44,655 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,656 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,656 [INFO]         \"GAP_FEAT_SIZE = 100  # Symbolic gap feature size\\n\",\n",
      "2026-01-21 11:08:44,657 [INFO]         \"gap_string_generator = GapStringGenerator(gap_size=GAP_FEAT_SIZE)\\n\",\n",
      "2026-01-21 11:08:44,657 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,658 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,658 [INFO]         \"def has_gene(record):\\n\",\n",
      "2026-01-21 11:08:44,658 [INFO]         \"    \\\"\\\"\\\"Check if a record has any CDS or gene features.\\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,659 [INFO]         \"    return any(f.type in {\\\"CDS\\\", \\\"gene\\\"} for f in record.features)\\n\",\n",
      "2026-01-21 11:08:44,659 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,660 [INFO]         \"def patch_gbk_with_architecture(\\n\",\n",
      "2026-01-21 11:08:44,660 [INFO]         \"    gbk_path,\\n\",\n",
      "2026-01-21 11:08:44,661 [INFO]         \"    arch_df,\\n\",\n",
      "2026-01-21 11:08:44,661 [INFO]         \"    gbk_out,\\n\",\n",
      "2026-01-21 11:08:44,662 [INFO]         \"    protein_col=\\\"protein_id\\\",\\n\",\n",
      "2026-01-21 11:08:44,662 [INFO]         \"    arch_col=\\\"architecture\\\",\\n\",\n",
      "2026-01-21 11:08:44,662 [INFO]         \"    rep_col=\\\"rep_arch_canonical\\\"\\n\",\n",
      "2026-01-21 11:08:44,663 [INFO]         \"):\\n\",\n",
      "2026-01-21 11:08:44,663 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,663 [INFO]         \"    STEP 1: Patch GenBank file with architecture annotations.\\n\",\n",
      "2026-01-21 11:08:44,664 [INFO]         \"    Modifies CDS features to include architecture information.\\n\",\n",
      "2026-01-21 11:08:44,664 [INFO]         \"    Filters out genes not in lookup and genes with \\\"other\\\" architecture.\\n\",\n",
      "2026-01-21 11:08:44,664 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,665 [INFO]         \"    print(arch_df.columns)\\n\",\n",
      "2026-01-21 11:08:44,665 [INFO]         \"    # Create lookup dictionary\\n\",\n",
      "2026-01-21 11:08:44,666 [INFO]         \"    lookup = arch_df.set_index(protein_col).to_dict(\\\"index\\\")\\n\",\n",
      "2026-01-21 11:08:44,666 [INFO]         \"    logging.info(f\\\"Lookup keys sample: {list(lookup.keys())[:5]}\\\")\\n\",\n",
      "2026-01-21 11:08:44,666 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,667 [INFO]         \"    logging.info(f\\\"Patching {gbk_path.name} with {len(lookup)} annotated proteins\\\")\\n\",\n",
      "2026-01-21 11:08:44,667 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,667 [INFO]         \"    records = []\\n\",\n",
      "2026-01-21 11:08:44,668 [INFO]         \"    total_genes_found = 0\\n\",\n",
      "2026-01-21 11:08:44,668 [INFO]         \"    total_genes_annotated = 0\\n\",\n",
      "2026-01-21 11:08:44,669 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,669 [INFO]         \"    for record in SeqIO.parse(gbk_path, \\\"genbank\\\"):\\n\",\n",
      "2026-01-21 11:08:44,670 [INFO]         \"        new_features = []\\n\",\n",
      "2026-01-21 11:08:44,672 [INFO]         \"        genes_found = 0\\n\",\n",
      "2026-01-21 11:08:44,673 [INFO]         \"        genes_annotated = 0\\n\",\n",
      "2026-01-21 11:08:44,674 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,674 [INFO]         \"        for feat in record.features:\\n\",\n",
      "2026-01-21 11:08:44,675 [INFO]         \"            # Keep non-CDS features as-is\\n\",\n",
      "2026-01-21 11:08:44,675 [INFO]         \"            if feat.type != \\\"CDS\\\":\\n\",\n",
      "2026-01-21 11:08:44,676 [INFO]         \"                new_features.append(feat)\\n\",\n",
      "2026-01-21 11:08:44,676 [INFO]         \"                continue\\n\",\n",
      "2026-01-21 11:08:44,677 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,678 [INFO]         \"            genes_found += 1\\n\",\n",
      "2026-01-21 11:08:44,679 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,680 [INFO]         \"            # Get protein_id from the CDS feature\\n\",\n",
      "2026-01-21 11:08:44,681 [INFO]         \"            pid = feat.qualifiers.get(\\\"locus_tag\\\", [None])[0]\\n\",\n",
      "2026-01-21 11:08:44,681 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,682 [INFO]         \"            if pid is None or pid not in lookup:\\n\",\n",
      "2026-01-21 11:08:44,682 [INFO]         \"                # Gene is outside annotation windows - DISCARD\\n\",\n",
      "2026-01-21 11:08:44,683 [INFO]         \"                continue\\n\",\n",
      "2026-01-21 11:08:44,683 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,684 [INFO]         \"            # Get architecture info\\n\",\n",
      "2026-01-21 11:08:44,685 [INFO]         \"            info = lookup[pid]\\n\",\n",
      "2026-01-21 11:08:44,686 [INFO]         \"            arch = info.get(arch_col, \\\"other\\\")\\n\",\n",
      "2026-01-21 11:08:44,686 [INFO]         \"            rep = info.get(rep_col, \\\"NA\\\")\\n\",\n",
      "2026-01-21 11:08:44,687 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,687 [INFO]         \"            # Only keep genes with real architecture (discard \\\"other\\\")\\n\",\n",
      "2026-01-21 11:08:44,689 [INFO]         \"            if arch == \\\"other\\\":\\n\",\n",
      "2026-01-21 11:08:44,690 [INFO]         \"                continue\\n\",\n",
      "2026-01-21 11:08:44,690 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,691 [INFO]         \"            genes_annotated += 1\\n\",\n",
      "2026-01-21 11:08:44,691 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,692 [INFO]         \"            # Modify the CDS feature qualifiers for clinker compatibility\\n\",\n",
      "2026-01-21 11:08:44,692 [INFO]         \"            feat.qualifiers[\\\"gene\\\"] = [arch]\\n\",\n",
      "2026-01-21 11:08:44,692 [INFO]         \"            feat.qualifiers[\\\"product\\\"] = [arch]  # Clinker uses this for labeling\\n\",\n",
      "2026-01-21 11:08:44,693 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,693 [INFO]         \"            # Add architecture notes\\n\",\n",
      "2026-01-21 11:08:44,693 [INFO]         \"            if \\\"note\\\" not in feat.qualifiers:\\n\",\n",
      "2026-01-21 11:08:44,694 [INFO]         \"                feat.qualifiers[\\\"note\\\"] = []\\n\",\n",
      "2026-01-21 11:08:44,694 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,694 [INFO]         \"            feat.qualifiers[\\\"note\\\"].append(f\\\"architecture={arch}\\\")\\n\",\n",
      "2026-01-21 11:08:44,695 [INFO]         \"            if rep != \\\"NA\\\":\\n\",\n",
      "2026-01-21 11:08:44,695 [INFO]         \"                feat.qualifiers[\\\"note\\\"].append(f\\\"representative_arch={rep}\\\")\\n\",\n",
      "2026-01-21 11:08:44,695 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,696 [INFO]         \"            new_features.append(feat)\\n\",\n",
      "2026-01-21 11:08:44,696 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,696 [INFO]         \"        record.features = new_features\\n\",\n",
      "2026-01-21 11:08:44,697 [INFO]         \"        total_genes_found += genes_found\\n\",\n",
      "2026-01-21 11:08:44,698 [INFO]         \"        total_genes_annotated += genes_annotated\\n\",\n",
      "2026-01-21 11:08:44,699 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,699 [INFO]         \"        # Only keep records that have genes after patching\\n\",\n",
      "2026-01-21 11:08:44,700 [INFO]         \"        if has_gene(record):\\n\",\n",
      "2026-01-21 11:08:44,700 [INFO]         \"            records.append(record)\\n\",\n",
      "2026-01-21 11:08:44,701 [INFO]         \"            logging.info(\\n\",\n",
      "2026-01-21 11:08:44,702 [INFO]         \"                f\\\"  {record.id}: {genes_annotated}/{genes_found} genes annotated - KEPT\\\"\\n\",\n",
      "2026-01-21 11:08:44,702 [INFO]         \"            )\\n\",\n",
      "2026-01-21 11:08:44,702 [INFO]         \"        else:\\n\",\n",
      "2026-01-21 11:08:44,703 [INFO]         \"            logging.info(\\n\",\n",
      "2026-01-21 11:08:44,703 [INFO]         \"                f\\\"  {record.id}: {genes_annotated}/{genes_found} genes annotated - REMOVED (empty)\\\"\\n\",\n",
      "2026-01-21 11:08:44,703 [INFO]         \"            )\\n\",\n",
      "2026-01-21 11:08:44,704 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,704 [INFO]         \"    gbk_file = gbk_out / f\\\"{arch_df['family'].unique()[0]}_patched.gbk\\\"\\n\",\n",
      "2026-01-21 11:08:44,705 [INFO]         \"    print(gbk_file)\\n\",\n",
      "2026-01-21 11:08:44,705 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,705 [INFO]         \"    out_gbk_path = gbk_file\\n\",\n",
      "2026-01-21 11:08:44,706 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,706 [INFO]         \"    # Write modified records back\\n\",\n",
      "2026-01-21 11:08:44,707 [INFO]         \"    with open(out_gbk_path, \\\"w\\\") as out_handle:\\n\",\n",
      "2026-01-21 11:08:44,707 [INFO]         \"        SeqIO.write(records, out_handle, \\\"genbank\\\")\\n\",\n",
      "2026-01-21 11:08:44,708 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,708 [INFO]         \"    logging.info(\\n\",\n",
      "2026-01-21 11:08:44,709 [INFO]         \"        f\\\"Successfully patched {gbk_path.name}: \\\"\\n\",\n",
      "2026-01-21 11:08:44,709 [INFO]         \"        f\\\"kept {len(records)} contigs, \\\"\\n\",\n",
      "2026-01-21 11:08:44,709 [INFO]         \"        f\\\"annotated {total_genes_annotated}/{total_genes_found} genes\\\"\\n\",\n",
      "2026-01-21 11:08:44,710 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:44,710 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,711 [INFO]         \"    return out_gbk_path, len(records), total_genes_annotated\\n\",\n",
      "2026-01-21 11:08:44,711 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,711 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,711 [INFO]         \"def create_gap_feature(start, end, gap_size, gap_id):\\n\",\n",
      "2026-01-21 11:08:44,712 [INFO]         \"    \\\"\\\"\\\"Create a CDS feature representing a truncated gap.\\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,712 [INFO]         \"    gap_label = f\\\"gap [{gap_size:,} bp]\\\"\\n\",\n",
      "2026-01-21 11:08:44,712 [INFO]         \"    gap_feature = SeqFeature(\\n\",\n",
      "2026-01-21 11:08:44,712 [INFO]         \"        FeatureLocation(start, end),\\n\",\n",
      "2026-01-21 11:08:44,713 [INFO]         \"        type=\\\"CDS\\\",\\n\",\n",
      "2026-01-21 11:08:44,713 [INFO]         \"        qualifiers={\\n\",\n",
      "2026-01-21 11:08:44,714 [INFO]         \"            \\\"gene\\\": [gap_label],\\n\",\n",
      "2026-01-21 11:08:44,715 [INFO]         \"            \\\"product\\\": [gap_label],\\n\",\n",
      "2026-01-21 11:08:44,715 [INFO]         \"            \\\"note\\\": [f\\\"Truncated gap: {gap_size:,} bp removed\\\"],\\n\",\n",
      "2026-01-21 11:08:44,715 [INFO]         \"            \\\"pseudo\\\": [\\\"true\\\"]\\n\",\n",
      "2026-01-21 11:08:44,716 [INFO]         \"        }\\n\",\n",
      "2026-01-21 11:08:44,716 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:44,717 [INFO]         \"    return gap_feature\\n\",\n",
      "2026-01-21 11:08:44,717 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,717 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,718 [INFO]         \"def truncate_large_gaps(\\n\",\n",
      "2026-01-21 11:08:44,718 [INFO]         \"    gbk_path,\\n\",\n",
      "2026-01-21 11:08:44,718 [INFO]         \"    gbk_out,\\n\",\n",
      "2026-01-21 11:08:44,719 [INFO]         \"    gap_generator,\\n\",\n",
      "2026-01-21 11:08:44,719 [INFO]         \"    upstream_buffer=UPSTREAM_BUFFER,\\n\",\n",
      "2026-01-21 11:08:44,719 [INFO]         \"    gap_threshold=GAP_THRESHOLD,\\n\",\n",
      "2026-01-21 11:08:44,720 [INFO]         \"    gap_buffer=GAP_BUFFER,\\n\",\n",
      "2026-01-21 11:08:44,721 [INFO]         \"    min_contig_size=MIN_CONTIG_SIZE\\n\",\n",
      "2026-01-21 11:08:44,721 [INFO]         \"):\\n\",\n",
      "2026-01-21 11:08:44,722 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,722 [INFO]         \"    STEP 2: Truncate large gaps in already-filtered GenBank files.\\n\",\n",
      "2026-01-21 11:08:44,722 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,723 [INFO]         \"    Args:\\n\",\n",
      "2026-01-21 11:08:44,723 [INFO]         \"        gbk_path: Path to the filtered/patched GenBank file\\n\",\n",
      "2026-01-21 11:08:44,723 [INFO]         \"        gbk_out: Output directory\\n\",\n",
      "2026-01-21 11:08:44,724 [INFO]         \"        upstream_buffer: Max bp to keep upstream of first gene\\n\",\n",
      "2026-01-21 11:08:44,724 [INFO]         \"        gap_threshold: Gap size that triggers truncation\\n\",\n",
      "2026-01-21 11:08:44,725 [INFO]         \"        gap_buffer: bp to keep on each side of a truncated gap\\n\",\n",
      "2026-01-21 11:08:44,725 [INFO]         \"        min_contig_size: Minimum contig size after truncation (0 = no limit)\\n\",\n",
      "2026-01-21 11:08:44,726 [INFO]         \"    \\\"\\\"\\\"\\n\",\n",
      "2026-01-21 11:08:44,726 [INFO]         \"    logging.info(f\\\"Truncating large gaps in {gbk_path.name}\\\")\\n\",\n",
      "2026-01-21 11:08:44,726 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,727 [INFO]         \"    # Create truncated subdirectory\\n\",\n",
      "2026-01-21 11:08:44,727 [INFO]         \"    truncated_dir = gbk_out / \\\"truncated\\\"\\n\",\n",
      "2026-01-21 11:08:44,728 [INFO]         \"    truncated_dir.mkdir(exist_ok=True)\\n\",\n",
      "2026-01-21 11:08:44,728 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,729 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,729 [INFO]         \"    records = []\\n\",\n",
      "2026-01-21 11:08:44,729 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,729 [INFO]         \"    for record in SeqIO.parse(gbk_path, \\\"genbank\\\"):\\n\",\n",
      "2026-01-21 11:08:44,730 [INFO]         \"        # Get only CDS features\\n\",\n",
      "2026-01-21 11:08:44,730 [INFO]         \"        cds_features = [f for f in record.features if f.type == \\\"CDS\\\"]\\n\",\n",
      "2026-01-21 11:08:44,731 [INFO]         \"        non_cds_features = [f for f in record.features if f.type != \\\"CDS\\\"]\\n\",\n",
      "2026-01-21 11:08:44,731 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,731 [INFO]         \"        if not cds_features:\\n\",\n",
      "2026-01-21 11:08:44,732 [INFO]         \"            records.append(record)\\n\",\n",
      "2026-01-21 11:08:44,732 [INFO]         \"            continue\\n\",\n",
      "2026-01-21 11:08:44,733 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,733 [INFO]         \"        # Sort CDS features by start position\\n\",\n",
      "2026-01-21 11:08:44,734 [INFO]         \"        sorted_cds = sorted(cds_features, key=lambda f: f.location.start)\\n\",\n",
      "2026-01-21 11:08:44,734 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,735 [INFO]         \"        # Calculate truncation map and build new sequence\\n\",\n",
      "2026-01-21 11:08:44,735 [INFO]         \"        position_map = {}\\n\",\n",
      "2026-01-21 11:08:44,735 [INFO]         \"        new_pos = 0\\n\",\n",
      "2026-01-21 11:08:44,736 [INFO]         \"        new_features = []\\n\",\n",
      "2026-01-21 11:08:44,736 [INFO]         \"        new_seq_parts = []\\n\",\n",
      "2026-01-21 11:08:44,736 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,737 [INFO]         \"        # Handle upstream region before first gene\\n\",\n",
      "2026-01-21 11:08:44,737 [INFO]         \"        first_gene_start = sorted_cds[0].location.start\\n\",\n",
      "2026-01-21 11:08:44,737 [INFO]         \"        upstream_start = max(0, first_gene_start - upstream_buffer)\\n\",\n",
      "2026-01-21 11:08:44,738 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,738 [INFO]         \"        # Add upstream sequence\\n\",\n",
      "2026-01-21 11:08:44,738 [INFO]         \"        if upstream_start < first_gene_start:\\n\",\n",
      "2026-01-21 11:08:44,738 [INFO]         \"            new_seq_parts.append(record.seq[upstream_start:first_gene_start])\\n\",\n",
      "2026-01-21 11:08:44,739 [INFO]         \"            for i in range(upstream_start, first_gene_start):\\n\",\n",
      "2026-01-21 11:08:44,739 [INFO]         \"                position_map[i] = new_pos\\n\",\n",
      "2026-01-21 11:08:44,739 [INFO]         \"                new_pos += 1\\n\",\n",
      "2026-01-21 11:08:44,741 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,741 [INFO]         \"        # Process each gene and gaps between them\\n\",\n",
      "2026-01-21 11:08:44,741 [INFO]         \"        for i, feat in enumerate(sorted_cds):\\n\",\n",
      "2026-01-21 11:08:44,742 [INFO]         \"            gene_start = feat.location.start\\n\",\n",
      "2026-01-21 11:08:44,742 [INFO]         \"            gene_end = feat.location.end\\n\",\n",
      "2026-01-21 11:08:44,742 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,743 [INFO]         \"            # Map gene positions\\n\",\n",
      "2026-01-21 11:08:44,744 [INFO]         \"            for pos in range(gene_start, gene_end):\\n\",\n",
      "2026-01-21 11:08:44,745 [INFO]         \"                position_map[pos] = new_pos\\n\",\n",
      "2026-01-21 11:08:44,746 [INFO]         \"                new_pos += 1\\n\",\n",
      "2026-01-21 11:08:44,746 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,747 [INFO]         \"            # Add gene sequence\\n\",\n",
      "2026-01-21 11:08:44,747 [INFO]         \"            new_seq_parts.append(record.seq[gene_start:gene_end])\\n\",\n",
      "2026-01-21 11:08:44,749 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,750 [INFO]         \"            # Update feature location\\n\",\n",
      "2026-01-21 11:08:44,751 [INFO]         \"            new_feat = SeqFeature(\\n\",\n",
      "2026-01-21 11:08:44,752 [INFO]         \"                FeatureLocation(position_map[gene_start], new_pos, strand=feat.location.strand),\\n\",\n",
      "2026-01-21 11:08:44,752 [INFO]         \"                type=feat.type,\\n\",\n",
      "2026-01-21 11:08:44,754 [INFO]         \"                qualifiers=feat.qualifiers.copy()\\n\",\n",
      "2026-01-21 11:08:44,754 [INFO]         \"            )\\n\",\n",
      "2026-01-21 11:08:44,755 [INFO]         \"            new_features.append(new_feat)\\n\",\n",
      "2026-01-21 11:08:44,756 [INFO]         \"            \\n\",\n",
      "2026-01-21 11:08:44,757 [INFO]         \"            # Handle gap to next gene\\n\",\n",
      "2026-01-21 11:08:44,758 [INFO]         \"            if i < len(sorted_cds) - 1:\\n\",\n",
      "2026-01-21 11:08:44,759 [INFO]         \"                next_gene_start = sorted_cds[i + 1].location.start\\n\",\n",
      "2026-01-21 11:08:44,759 [INFO]         \"                gap_size = next_gene_start - gene_end\\n\",\n",
      "2026-01-21 11:08:44,760 [INFO]         \"                \\n\",\n",
      "2026-01-21 11:08:44,761 [INFO]         \"                if gap_size > gap_threshold:\\n\",\n",
      "2026-01-21 11:08:44,761 [INFO]         \"                    # Large gap - truncate it\\n\",\n",
      "2026-01-21 11:08:44,762 [INFO]         \"                    # Keep gap_buffer on current gene side\\n\",\n",
      "2026-01-21 11:08:44,763 [INFO]         \"                    buffer_end = gene_end + gap_buffer\\n\",\n",
      "2026-01-21 11:08:44,764 [INFO]         \"                    for pos in range(gene_end, buffer_end):\\n\",\n",
      "2026-01-21 11:08:44,764 [INFO]         \"                        position_map[pos] = new_pos\\n\",\n",
      "2026-01-21 11:08:44,765 [INFO]         \"                        new_pos += 1\\n\",\n",
      "2026-01-21 11:08:44,766 [INFO]         \"                    new_seq_parts.append(record.seq[gene_end:buffer_end])\\n\",\n",
      "2026-01-21 11:08:44,767 [INFO]         \"                    \\n\",\n",
      "2026-01-21 11:08:44,767 [INFO]         \"                    # Add gap feature\\n\",\n",
      "2026-01-21 11:08:44,768 [INFO]         \"                    gap_feat_start = new_pos\\n\",\n",
      "2026-01-21 11:08:44,768 [INFO]         \"                    gap_feat_size = gap_generator.gap_size\\n\",\n",
      "2026-01-21 11:08:44,769 [INFO]         \"                    gap_feat = create_gap_feature(gap_feat_start, gap_feat_start + gap_feat_size, gap_size - 2 * gap_buffer, None)\\n\",\n",
      "2026-01-21 11:08:44,769 [INFO]         \"                    new_features.append(gap_feat)\\n\",\n",
      "2026-01-21 11:08:44,769 [INFO]         \"                    \\n\",\n",
      "2026-01-21 11:08:44,769 [INFO]         \"                    # Add placeholder sequence for gap feature (Ns)\\n\",\n",
      "2026-01-21 11:08:44,770 [INFO]         \"                    new_seq_parts.append(Seq(gap_generator.get_next_gap()))\\n\",\n",
      "2026-01-21 11:08:44,770 [INFO]         \"                    new_pos += gap_feat_size\\n\",\n",
      "2026-01-21 11:08:44,771 [INFO]         \"                    \\n\",\n",
      "2026-01-21 11:08:44,771 [INFO]         \"                    # Keep gap_buffer on next gene side\\n\",\n",
      "2026-01-21 11:08:44,772 [INFO]         \"                    buffer_start = next_gene_start - gap_buffer\\n\",\n",
      "2026-01-21 11:08:44,772 [INFO]         \"                    for pos in range(buffer_start, next_gene_start):\\n\",\n",
      "2026-01-21 11:08:44,772 [INFO]         \"                        position_map[pos] = new_pos\\n\",\n",
      "2026-01-21 11:08:44,773 [INFO]         \"                        new_pos += 1\\n\",\n",
      "2026-01-21 11:08:44,773 [INFO]         \"                    new_seq_parts.append(record.seq[buffer_start:next_gene_start])\\n\",\n",
      "2026-01-21 11:08:44,774 [INFO]         \"                else:\\n\",\n",
      "2026-01-21 11:08:44,774 [INFO]         \"                    # Small gap - keep it all\\n\",\n",
      "2026-01-21 11:08:44,775 [INFO]         \"                    for pos in range(gene_end, next_gene_start):\\n\",\n",
      "2026-01-21 11:08:44,776 [INFO]         \"                        position_map[pos] = new_pos\\n\",\n",
      "2026-01-21 11:08:44,776 [INFO]         \"                        new_pos += 1\\n\",\n",
      "2026-01-21 11:08:44,777 [INFO]         \"                    new_seq_parts.append(record.seq[gene_end:next_gene_start])\\n\",\n",
      "2026-01-21 11:08:44,777 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,778 [INFO]         \"        # Create new record\\n\",\n",
      "2026-01-21 11:08:44,778 [INFO]         \"        new_record = record[:]\\n\",\n",
      "2026-01-21 11:08:44,779 [INFO]         \"        new_record.seq = sum(new_seq_parts, Seq(\\\"\\\"))\\n\",\n",
      "2026-01-21 11:08:44,779 [INFO]         \"        new_record.features = new_features\\n\",\n",
      "2026-01-21 11:08:44,779 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,780 [INFO]         \"        # Check minimum contig size\\n\",\n",
      "2026-01-21 11:08:44,780 [INFO]         \"        if min_contig_size > 0 and len(new_record.seq) < min_contig_size:\\n\",\n",
      "2026-01-21 11:08:44,781 [INFO]         \"            logging.info(\\n\",\n",
      "2026-01-21 11:08:44,781 [INFO]         \"                f\\\"  {record.id}: {len(record.seq):,} bp -> {len(new_record.seq):,} bp \\\"\\n\",\n",
      "2026-01-21 11:08:44,782 [INFO]         \"                f\\\"- DISCARDED (below minimum size {min_contig_size:,} bp)\\\"\\n\",\n",
      "2026-01-21 11:08:44,782 [INFO]         \"            )\\n\",\n",
      "2026-01-21 11:08:44,783 [INFO]         \"            continue\\n\",\n",
      "2026-01-21 11:08:44,783 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,783 [INFO]         \"        logging.info(\\n\",\n",
      "2026-01-21 11:08:44,784 [INFO]         \"            f\\\"  {record.id}: {len(record.seq):,} bp -> {len(new_record.seq):,} bp \\\"\\n\",\n",
      "2026-01-21 11:08:44,784 [INFO]         \"            f\\\"({len(record.seq) - len(new_record.seq):,} bp removed)\\\"\\n\",\n",
      "2026-01-21 11:08:44,785 [INFO]         \"        )\\n\",\n",
      "2026-01-21 11:08:44,785 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,786 [INFO]         \"        records.append(new_record)\\n\",\n",
      "2026-01-21 11:08:44,786 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,786 [INFO]         \"    # Output file in truncated subdirectory\\n\",\n",
      "2026-01-21 11:08:44,787 [INFO]         \"    out_path = truncated_dir / gbk_path.name.replace(\\\"_patched.gbk\\\", \\\"_truncated.gbk\\\")\\n\",\n",
      "2026-01-21 11:08:44,787 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,787 [INFO]         \"    with open(out_path, \\\"w\\\") as out_handle:\\n\",\n",
      "2026-01-21 11:08:44,788 [INFO]         \"        SeqIO.write(records, out_handle, \\\"genbank\\\")\\n\",\n",
      "2026-01-21 11:08:44,788 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,788 [INFO]         \"    logging.info(f\\\"Truncated gaps written to {out_path}\\\")\\n\",\n",
      "2026-01-21 11:08:44,789 [INFO]         \"    return out_path\\n\",\n",
      "2026-01-21 11:08:44,789 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,790 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,790 [INFO]         \"# STEP 1: Patch all GBK files with architecture annotations\\n\",\n",
      "2026-01-21 11:08:44,790 [INFO]         \"for family, fam_df in tqdm(rep_df.groupby(\\\"family\\\")):\\n\",\n",
      "2026-01-21 11:08:44,791 [INFO]         \"    fam_dir = GBK_OUT_DIR / family\\n\",\n",
      "2026-01-21 11:08:44,792 [INFO]         \"    \\n\",\n",
      "2026-01-21 11:08:44,792 [INFO]         \"    logging.info(f\\\"Patching family: {family} ({len(fam_df)} annotations)\\\")\\n\",\n",
      "2026-01-21 11:08:44,792 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,793 [INFO]         \"    for gbk_file in fam_dir.glob(\\\"*.gbk\\\"):\\n\",\n",
      "2026-01-21 11:08:44,793 [INFO]         \"        # Extract genome_id from filename\\n\",\n",
      "2026-01-21 11:08:44,794 [INFO]         \"        genome_id = gbk_file.stem  # removes .gbk extension\\n\",\n",
      "2026-01-21 11:08:44,794 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,795 [INFO]         \"        # Filter annotations for this specific genome\\n\",\n",
      "2026-01-21 11:08:44,795 [INFO]         \"        genome_df = fam_df[fam_df[\\\"genome_id\\\"] == genome_id]\\n\",\n",
      "2026-01-21 11:08:44,795 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,796 [INFO]         \"        if genome_df.empty:\\n\",\n",
      "2026-01-21 11:08:44,796 [INFO]         \"            logging.warning(f\\\"No annotations found for {genome_id}, skipping\\\")\\n\",\n",
      "2026-01-21 11:08:44,797 [INFO]         \"            continue\\n\",\n",
      "2026-01-21 11:08:44,797 [INFO]         \"        \\n\",\n",
      "2026-01-21 11:08:44,797 [INFO]         \"        patched_path, num_contigs, num_genes = patch_gbk_with_architecture(\\n\",\n",
      "2026-01-21 11:08:44,798 [INFO]         \"            gbk_path=gbk_file,\\n\",\n",
      "2026-01-21 11:08:44,798 [INFO]         \"            arch_df=genome_df,\\n\",\n",
      "2026-01-21 11:08:44,798 [INFO]         \"            gbk_out=gbk_out\\n\",\n",
      "2026-01-21 11:08:44,799 [INFO]         \"        )\\n\",\n",
      "2026-01-21 11:08:44,799 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,799 [INFO]         \"logging.info(\\\"All GBK files patched with architecture annotations\\\")\\n\",\n",
      "2026-01-21 11:08:44,800 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,800 [INFO]         \"# STEP 2: Truncate large gaps in patched files\\n\",\n",
      "2026-01-21 11:08:44,801 [INFO]         \"logging.info(\\\"Starting gap truncation...\\\")\\n\",\n",
      "2026-01-21 11:08:44,801 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,801 [INFO]         \"for patched_file in gbk_out.glob(\\\"*_patched.gbk\\\"):\\n\",\n",
      "2026-01-21 11:08:44,801 [INFO]         \"    truncate_large_gaps(\\n\",\n",
      "2026-01-21 11:08:44,802 [INFO]         \"        gbk_path=patched_file,\\n\",\n",
      "2026-01-21 11:08:44,802 [INFO]         \"        gbk_out=gbk_out,\\n\",\n",
      "2026-01-21 11:08:44,802 [INFO]         \"        gap_generator=gap_string_generator,\\n\",\n",
      "2026-01-21 11:08:44,802 [INFO]         \"        upstream_buffer=UPSTREAM_BUFFER,\\n\",\n",
      "2026-01-21 11:08:44,803 [INFO]         \"        gap_threshold=GAP_THRESHOLD,\\n\",\n",
      "2026-01-21 11:08:44,803 [INFO]         \"        gap_buffer=GAP_BUFFER,\\n\",\n",
      "2026-01-21 11:08:44,803 [INFO]         \"        min_contig_size=MIN_CONTIG_SIZE\\n\",\n",
      "2026-01-21 11:08:44,804 [INFO]         \"    )\\n\",\n",
      "2026-01-21 11:08:44,804 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,805 [INFO]         \"logging.info(\\\"All files processed: patched and truncated\\\")\"\n",
      "2026-01-21 11:08:44,805 [INFO]       ]\n",
      "2026-01-21 11:08:44,805 [INFO]     },\n",
      "2026-01-21 11:08:44,806 [INFO]     {\n",
      "2026-01-21 11:08:44,807 [INFO]       \"cell_type\": \"code\",\n",
      "2026-01-21 11:08:44,807 [INFO]       \"execution_count\": null,\n",
      "2026-01-21 11:08:44,807 [INFO]       \"id\": \"1f5d8536\",\n",
      "2026-01-21 11:08:44,808 [INFO]       \"metadata\": {},\n",
      "2026-01-21 11:08:44,808 [INFO]       \"outputs\": [],\n",
      "2026-01-21 11:08:44,809 [INFO]       \"source\": [\n",
      "2026-01-21 11:08:44,809 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,810 [INFO]         \"\\n\",\n",
      "2026-01-21 11:08:44,811 [INFO]         \"code_block = f\\\"conda activate clinker\\\\nclinker {gbk_out / 'truncated'}/*.gbk -o ESCRT_SYNTENY --plot ESCRT_synteny.html -gf {annotation_csv}\\\"\"\n",
      "2026-01-21 11:08:44,811 [INFO]       ]\n",
      "2026-01-21 11:08:44,812 [INFO]     }\n",
      "2026-01-21 11:08:44,812 [INFO]   ],\n",
      "2026-01-21 11:08:44,812 [INFO]   \"metadata\": {\n",
      "2026-01-21 11:08:44,812 [INFO]     \"kernelspec\": {\n",
      "2026-01-21 11:08:44,813 [INFO]       \"display_name\": \"Reg\",\n",
      "2026-01-21 11:08:44,813 [INFO]       \"language\": \"python\",\n",
      "2026-01-21 11:08:44,814 [INFO]       \"name\": \"python3\"\n",
      "2026-01-21 11:08:44,814 [INFO]     },\n",
      "2026-01-21 11:08:44,814 [INFO]     \"language_info\": {\n",
      "2026-01-21 11:08:44,815 [INFO]       \"codemirror_mode\": {\n",
      "2026-01-21 11:08:44,815 [INFO]         \"name\": \"ipython\",\n",
      "2026-01-21 11:08:44,816 [INFO]         \"version\": 3\n",
      "2026-01-21 11:08:44,816 [INFO]       },\n",
      "2026-01-21 11:08:44,816 [INFO]       \"file_extension\": \".py\",\n",
      "2026-01-21 11:08:44,817 [INFO]       \"mimetype\": \"text/x-python\",\n",
      "2026-01-21 11:08:44,817 [INFO]       \"name\": \"python\",\n",
      "2026-01-21 11:08:44,818 [INFO]       \"nbconvert_exporter\": \"python\",\n",
      "2026-01-21 11:08:44,820 [INFO]       \"pygments_lexer\": \"ipython3\",\n",
      "2026-01-21 11:08:44,821 [INFO]       \"version\": \"3.13.9\"\n",
      "2026-01-21 11:08:44,822 [INFO]     }\n",
      "2026-01-21 11:08:44,823 [INFO]   },\n",
      "2026-01-21 11:08:44,823 [INFO]   \"nbformat\": 4,\n",
      "2026-01-21 11:08:44,824 [INFO]   \"nbformat_minor\": 5\n",
      "2026-01-21 11:08:44,824 [INFO] }\n"
     ]
    }
   ],
   "source": [
    "# adding script to the log file\n",
    "import json\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Load the current notebook file (Jupyter notebooks are JSON)\n",
    "# ------------------------------------------------------------------\n",
    "with open(NOTEBOOK_PATH, \"r\", encoding=\"utf-8\") as nb:\n",
    "    notebook_json = json.load(nb)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Remove execution outputs from code cells\n",
    "#   - prevents massive logs\n",
    "#   - avoids embedding binary blobs (plots, images)\n",
    "#   - keeps only the executable logic + structure\n",
    "# ------------------------------------------------------------------\n",
    "def strip_outputs(nb):\n",
    "    for cell in nb.get(\"cells\", []):\n",
    "        if cell.get(\"cell_type\") == \"code\":\n",
    "            cell[\"outputs\"] = []\n",
    "            cell[\"execution_count\"] = None\n",
    "    return nb\n",
    "\n",
    "notebook_json = strip_outputs(notebook_json)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Serialize notebook JSON to a formatted string\n",
    "#   - indentation preserves readability in logs\n",
    "#   - done once to avoid repeated JSON encoding\n",
    "# ------------------------------------------------------------------\n",
    "notebook_str = json.dumps(notebook_json, indent=2)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Append notebook snapshot to the log file\n",
    "#   - logged line-by-line to preserve formatting\n",
    "#   - ensures compatibility with logging handlers\n",
    "# ------------------------------------------------------------------\n",
    "logging.info(\"=\" * 80)\n",
    "logging.info(\"NOTEBOOK JSON SNAPSHOT (END OF RUN)\")\n",
    "logging.info(\"=\" * 80)\n",
    "\n",
    "for line in notebook_str.splitlines():\n",
    "    logging.info(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89c38cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['target', 'Name', 'Completeness', 'Contamination', 'Contig_N50',\n",
      "       'Total_Contigs', 'organism_name', 'architecture', 'architecture_method',\n",
      "       'architecture_components', 'genome_id', 'contig', 'gene_index',\n",
      "       'protein_id', 'start', 'end', 'strand'],\n",
      "      dtype='object')\n",
      "Index(['family', 'genome_id_x', 'rep_arch_canonical', 'contig'], dtype='object')\n",
      "2026-01-21 11:11:06,024 [INFO] Representative genomes retained: 16\n",
      "2026-01-21 11:11:06,025 [INFO] \n",
      "[STEP 1] Loading GFF files...\n",
      "2026-01-21 11:11:06,026 [INFO] Loading GFFs for 16 unique genomes\n",
      "2026-01-21 11:11:06,026 [INFO] Parsing GFF: GCA_001940665.2_ASM194066v2_genomic.gff\n",
      "2026-01-21 11:11:06,031 [INFO]   → Parsed 1464 CDS features across 1 contigs\n",
      "2026-01-21 11:11:06,034 [INFO] Parsing GFF: GCA_030668875.1_ASM3066887v1_genomic.gff\n",
      "2026-01-21 11:11:06,046 [INFO]   → Parsed 2972 CDS features across 99 contigs\n",
      "2026-01-21 11:11:06,048 [INFO] Parsing GFF: GCA_016840465.1_ASM1684046v1_genomic.gff\n",
      "2026-01-21 11:11:06,058 [INFO]   → Parsed 2367 CDS features across 100 contigs\n",
      "2026-01-21 11:11:06,061 [INFO] Parsing GFF: GCA_003144275.1_ASM314427v1_genomic.gff\n",
      "2026-01-21 11:11:06,073 [INFO]   → Parsed 3520 CDS features across 103 contigs\n",
      "2026-01-21 11:11:06,076 [INFO] Parsing GFF: GCA_005191425.1_ASM519142v1_genomic.gff\n",
      "2026-01-21 11:11:06,087 [INFO]   → Parsed 3164 CDS features across 182 contigs\n",
      "2026-01-21 11:11:06,090 [INFO] Parsing GFF: GCA_030149205.1_ASM3014920v1_genomic.gff\n",
      "2026-01-21 11:11:06,100 [INFO]   → Parsed 3000 CDS features across 12 contigs\n",
      "2026-01-21 11:11:06,104 [INFO] Parsing GFF: GCA_019056805.1_ASM1905680v1_genomic.gff\n",
      "2026-01-21 11:11:06,110 [INFO]   → Parsed 1888 CDS features across 18 contigs\n",
      "2026-01-21 11:11:06,112 [INFO] Parsing GFF: GCA_029855935.1_ASM2985593v1_genomic.gff\n",
      "2026-01-21 11:11:06,122 [INFO]   → Parsed 2731 CDS features across 32 contigs\n",
      "2026-01-21 11:11:06,125 [INFO] Parsing GFF: GCA_016840425.1_ASM1684042v1_genomic.gff\n",
      "2026-01-21 11:11:06,132 [INFO]   → Parsed 2100 CDS features across 277 contigs\n",
      "2026-01-21 11:11:06,135 [INFO] Parsing GFF: GCA_005223125.1_ASM522312v1_genomic.gff\n",
      "2026-01-21 11:11:06,148 [INFO]   → Parsed 4010 CDS features across 71 contigs\n",
      "2026-01-21 11:11:06,152 [INFO] Parsing GFF: GCA_038820475.1_ASM3882047v1_genomic.gff\n",
      "2026-01-21 11:11:06,159 [INFO]   → Parsed 2006 CDS features across 33 contigs\n",
      "2026-01-21 11:11:06,162 [INFO] Parsing GFF: GCA_030614005.1_ASM3061400v1_genomic.gff\n",
      "2026-01-21 11:11:06,173 [INFO]   → Parsed 3303 CDS features across 126 contigs\n",
      "2026-01-21 11:11:06,176 [INFO] Parsing GFF: GCA_021498095.1_ASM2149809v1_genomic.gff\n",
      "2026-01-21 11:11:06,190 [INFO]   → Parsed 3694 CDS features across 1 contigs\n",
      "2026-01-21 11:11:06,193 [INFO] Parsing GFF: GCA_029856435.1_ASM2985643v1_genomic.gff\n",
      "2026-01-21 11:11:06,204 [INFO]   → Parsed 3257 CDS features across 180 contigs\n",
      "2026-01-21 11:11:06,207 [INFO] Parsing GFF: GCA_030587545.2_ASM3058754v2_genomic.gff\n",
      "2026-01-21 11:11:06,296 [INFO]   → Parsed 5086 CDS features across 293 contigs\n",
      "2026-01-21 11:11:06,300 [INFO] Parsing GFF: GCA_026993975.1_ASM2699397v1_genomic.gff\n",
      "2026-01-21 11:11:06,309 [INFO]   → Parsed 2287 CDS features across 216 contigs\n",
      "2026-01-21 11:11:06,315 [INFO] Total CDS features loaded: 46849\n",
      "2026-01-21 11:11:06,319 [INFO] Starting neighborhood extraction (±1000 genes)\n",
      "2026-01-21 11:11:06,320 [INFO] Initial anchors: 144\n",
      "2026-01-21 11:11:06,321 [INFO] Anchors after ESCRT filter: 104\n",
      "2026-01-21 11:11:06,411 [INFO] Extracted 7455 genes from 16 contig neighborhoods\n",
      "df: Index(['genome_id_x', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'relative_pos', 'center_protein', 'center_gene',\n",
      "       'neighbor_architecture', 'is_target_family', 'genome_id_base',\n",
      "       'genome_id_y', 'domain', 'phylum', 'class', 'order', 'family', 'genus',\n",
      "       'species', 'arch_token'],\n",
      "      dtype='object')\n",
      "rep_df columns:                      genome_id      contig  gene_index      protein_id  start  \\\n",
      "0  GCA_001940665.2_ASM194066v2  CP091871.1           1  NDAMOAGK_00001    105   \n",
      "1  GCA_001940665.2_ASM194066v2  CP091871.1           2  NDAMOAGK_00002    994   \n",
      "2  GCA_001940665.2_ASM194066v2  CP091871.1           3  NDAMOAGK_00003   2378   \n",
      "3  GCA_001940665.2_ASM194066v2  CP091871.1           4  NDAMOAGK_00004   2709   \n",
      "4  GCA_001940665.2_ASM194066v2  CP091871.1           5  NDAMOAGK_00005   3198   \n",
      "5  GCA_001940665.2_ASM194066v2  CP091871.1           6  NDAMOAGK_00006   4373   \n",
      "6  GCA_001940665.2_ASM194066v2  CP091871.1           7  NDAMOAGK_00007   5541   \n",
      "7  GCA_001940665.2_ASM194066v2  CP091871.1           8  NDAMOAGK_00008   6800   \n",
      "8  GCA_001940665.2_ASM194066v2  CP091871.1           9  NDAMOAGK_00009   7237   \n",
      "9  GCA_001940665.2_ASM194066v2  CP091871.1          10  NDAMOAGK_00010   8932   \n",
      "\n",
      "    end strand architecture  num_anchors  window_start  window_end  \\\n",
      "0  1004      +        other           11          -859        2099   \n",
      "1  2349      +        other           11          -859        2099   \n",
      "2  2716      -        other           11          -859        2099   \n",
      "3  3038      -        other           11          -859        2099   \n",
      "4  4376      +        other           11          -859        2099   \n",
      "5  5491      -        other           11          -859        2099   \n",
      "6  6713      -        other           11          -859        2099   \n",
      "7  7219      +        other           11          -859        2099   \n",
      "8  8958      +        other           11          -859        2099   \n",
      "9  9756      -        other           11          -859        2099   \n",
      "\n",
      "                neighborhood_architecture_compressed  \\\n",
      "0  other[140],E2-VPS23,other[30],Vps4,other[42],M...   \n",
      "1  other[140],E2-VPS23,other[30],Vps4,other[42],M...   \n",
      "2  other[140],E2-VPS23,other[30],Vps4,other[42],M...   \n",
      "3  other[140],E2-VPS23,other[30],Vps4,other[42],M...   \n",
      "4  other[140],E2-VPS23,other[30],Vps4,other[42],M...   \n",
      "5  other[140],E2-VPS23,other[30],Vps4,other[42],M...   \n",
      "6  other[140],E2-VPS23,other[30],Vps4,other[42],M...   \n",
      "7  other[140],E2-VPS23,other[30],Vps4,other[42],M...   \n",
      "8  other[140],E2-VPS23,other[30],Vps4,other[42],M...   \n",
      "9  other[140],E2-VPS23,other[30],Vps4,other[42],M...   \n",
      "\n",
      "   position_in_neighborhood                  genome_id_x           family  \n",
      "0                         0  GCA_001940665.2_ASM194066v2  Odinarchaeaceae  \n",
      "1                         1  GCA_001940665.2_ASM194066v2  Odinarchaeaceae  \n",
      "2                         2  GCA_001940665.2_ASM194066v2  Odinarchaeaceae  \n",
      "3                         3  GCA_001940665.2_ASM194066v2  Odinarchaeaceae  \n",
      "4                         4  GCA_001940665.2_ASM194066v2  Odinarchaeaceae  \n",
      "5                         5  GCA_001940665.2_ASM194066v2  Odinarchaeaceae  \n",
      "6                         6  GCA_001940665.2_ASM194066v2  Odinarchaeaceae  \n",
      "7                         7  GCA_001940665.2_ASM194066v2  Odinarchaeaceae  \n",
      "8                         8  GCA_001940665.2_ASM194066v2  Odinarchaeaceae  \n",
      "9                         9  GCA_001940665.2_ASM194066v2  Odinarchaeaceae  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqFeature import SeqFeature\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compress_others(tokens, threshold=10):\n",
    "    \"\"\"\n",
    "    Compress long runs of 'other' into 'other[n]' if n > threshold.\n",
    "    \"\"\"\n",
    "    compressed = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(tokens):\n",
    "        if tokens[i] != \"other\":\n",
    "            compressed.append(tokens[i])\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # count run\n",
    "        j = i\n",
    "        while j < len(tokens) and tokens[j] == \"other\":\n",
    "            j += 1\n",
    "\n",
    "        run_len = j - i\n",
    "\n",
    "        if run_len > threshold:\n",
    "            compressed.append(f\"other[{run_len}]\")\n",
    "        else:\n",
    "            compressed.extend([\"other\"] * run_len)\n",
    "\n",
    "        i = j\n",
    "\n",
    "    return compressed\n",
    "\n",
    "def extract_architecture_full_contig(anchor_df, gff_df, window=5):\n",
    "    \"\"\"\n",
    "    Extract genomic neighborhoods around ESCRT-related anchor genes.\n",
    "    \"\"\"\n",
    "    keywords = CORE_TARGETS\n",
    "\n",
    "    logging.info(f\"Starting neighborhood extraction (±{window} genes)\")\n",
    "    logging.info(f\"Initial anchors: {len(anchor_df)}\")\n",
    "\n",
    "    # Filter anchors by keywords\n",
    "    filtered_anchors = anchor_df[\n",
    "        anchor_df[\"architecture\"]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .str.contains(\"|\".join(keywords))\n",
    "    ].copy()\n",
    "\n",
    "    logging.info(f\"Anchors after ESCRT filter: {len(filtered_anchors)}\")\n",
    "\n",
    "    if filtered_anchors.empty:\n",
    "        logging.error(\"No ESCRT-related anchors found\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    neighborhoods = []\n",
    "\n",
    "    # Group by genome and contig\n",
    "    for (genome, contig), anchors in filtered_anchors.groupby(\n",
    "        [\"genome_id\", \"contig\"]\n",
    "    ):\n",
    "        anchor_indices = anchors[\"gene_index\"].values\n",
    "        \n",
    "        # Define window boundaries\n",
    "        start = anchor_indices.min() - window\n",
    "        end = anchor_indices.max() + window\n",
    "\n",
    "        # Extract all genes in the window from gff_df\n",
    "        block = gff_df[\n",
    "            (gff_df[\"genome_id\"] == genome) &\n",
    "            (gff_df[\"contig\"] == contig) &\n",
    "            (gff_df[\"gene_index\"].between(start, end))\n",
    "        ].copy()\n",
    "\n",
    "        if block.empty:\n",
    "            continue\n",
    "\n",
    "        # Sort by gene position\n",
    "        block = block.sort_values(\"gene_index\").reset_index(drop=True)\n",
    "\n",
    "        # Create a mapping of protein_id to architecture from ALL anchors\n",
    "        # (not just filtered ones), so we get complete architecture info\n",
    "        arch_map = anchor_df.set_index(\"protein_id\")[\"architecture\"].to_dict()\n",
    "        \n",
    "        # Apply architecture: use anchor architecture if available, else \"other\"\n",
    "        block[\"architecture\"] = block[\"protein_id\"].map(arch_map).fillna(\"other\")\n",
    "\n",
    "        # Build architecture token list for the ENTIRE neighborhood\n",
    "        tokens = block[\"architecture\"].tolist()\n",
    "        compressed_tokens = compress_others(tokens, threshold=10)\n",
    "\n",
    "\n",
    "        # Add metadata about the neighborhood\n",
    "        block[\"num_anchors\"] = len(anchors)\n",
    "\n",
    "        block[\"window_start\"] = start\n",
    "        block[\"window_end\"] = end\n",
    "        block[\"neighborhood_architecture_compressed\"] = \",\".join(compressed_tokens)\n",
    "        block[\"position_in_neighborhood\"] = range(len(block))\n",
    "\n",
    "        neighborhoods.append(block)\n",
    "\n",
    "    if not neighborhoods:\n",
    "        logging.error(\"No neighborhoods extracted after processing\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    combined = pd.concat(neighborhoods, ignore_index=True)\n",
    "\n",
    "    logging.info(\n",
    "        f\"Extracted {len(combined)} genes from \"\n",
    "        f\"{len(neighborhoods)} contig neighborhoods\"\n",
    "    )\n",
    "\n",
    "    return combined\n",
    "\n",
    "# -----------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# merge rep_genomes with anchor_df on genome_id\n",
    "print(anchor_df.columns)\n",
    "print(rep_genomes.columns)\n",
    "rep_genomes_anchor = (\n",
    "    rep_genomes\n",
    "    .merge(\n",
    "        anchor_df.drop_duplicates(),\n",
    "        left_on=[\"genome_id_x\", \"contig\"],\n",
    "        right_on=[\"genome_id\", \"contig\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "logging.info(\n",
    "    \"Representative genomes retained: %d\",\n",
    "    rep_genomes_anchor[\"genome_id_x\"].nunique()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract full contig architecture to modify gbk files\n",
    "\n",
    "\n",
    "gff_dir = Path(\"/home/anirudh/genomes/selected_genomes/prokka_results\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Load GFFs\n",
    "# --------------------------------------------------------\n",
    "logging.info(\"\\n[STEP 1] Loading GFF files...\")\n",
    "gff_df = load_gffs_from_hits(rep_genomes_anchor, gff_dir)\n",
    "\n",
    "\n",
    "\n",
    "rep_df = extract_architecture_full_contig(rep_genomes_anchor, gff_df, window=1000)\n",
    "\n",
    "rep_df.to_csv(\n",
    "    OUTDIR / f\"[STEP:{STEP}]representative_genomes_full_contig_architectures.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"df:\", df.columns)\n",
    "\n",
    "# taxonomy_df must have genome_id and family\n",
    "taxonomy_df = df[[\"genome_id_x\", \"family\"]].drop_duplicates()\n",
    "\n",
    "rep_df = rep_df.merge(\n",
    "    taxonomy_df,\n",
    "    left_on=\"genome_id\",\n",
    "    right_on=\"genome_id_x\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# sanity check\n",
    "if rep_df[\"family\"].isna().any():\n",
    "    raise RuntimeError(\"Some rows in rep_df are missing family taxonomy\")\n",
    "\n",
    "\n",
    "# yield a csv file for gene function annotation in clinker protein_id, protein_name\n",
    "print(\"rep_df columns:\", rep_df.head(10))\n",
    "\n",
    "\n",
    "\n",
    "annotation_df = rep_df[[\"protein_id\", \"architecture\"]].drop_duplicates()\n",
    "\n",
    "annotation_df = annotation_df[annotation_df[\"architecture\"] != \"other\"]\n",
    "\n",
    "annotation_csv =  OUTDIR / f\"[STEP:{STEP}.9]representative_genomes_gene_function_annotation.csv\"\n",
    "\n",
    "annotation_df.to_csv(\n",
    "    annotation_csv,\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "511f4812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:15,909 [INFO] Copied GCA_016840465.1_ASM1684046v1.gbk to Baldrarchaeaceae/\n",
      "2026-01-21 11:11:15,912 [INFO] Copied GCA_019056805.1_ASM1905680v1.gbk to DXJG01/\n",
      "2026-01-21 11:11:15,916 [INFO] Copied GCA_038820475.1_ASM3882047v1.gbk to Freyrarchaeaceae/\n",
      "2026-01-21 11:11:15,921 [INFO] Copied GCA_005191425.1_ASM519142v1.gbk to HEL-GB-B/\n",
      "2026-01-21 11:11:15,925 [INFO] Copied GCA_030668875.1_ASM3066887v1.gbk to Heimdallarchaeaceae/\n",
      "2026-01-21 11:11:15,929 [INFO] Copied GCA_003144275.1_ASM314427v1.gbk to Hodarchaeaceae/\n",
      "2026-01-21 11:11:15,933 [INFO] Copied GCA_030614005.1_ASM3061400v1.gbk to JABLTI01/\n",
      "2026-01-21 11:11:15,937 [INFO] Copied GCA_029856435.1_ASM2985643v1.gbk to Jordiarchaeaceae/\n",
      "2026-01-21 11:11:15,940 [INFO] Copied GCA_030149205.1_ASM3014920v1.gbk to Kariarchaeaceae/\n",
      "2026-01-21 11:11:15,944 [INFO] Copied GCA_021498095.1_ASM2149809v1.gbk to MK-D1/\n",
      "2026-01-21 11:11:15,947 [INFO] Copied GCA_026993975.1_ASM2699397v1.gbk to Njordarchaeaceae/\n",
      "2026-01-21 11:11:15,950 [INFO] Copied GCA_001940665.2_ASM194066v2.gbk to Odinarchaeaceae/\n",
      "2026-01-21 11:11:15,954 [INFO] Copied GCA_005223125.1_ASM522312v1.gbk to SOKP01/\n",
      "2026-01-21 11:11:15,959 [INFO] Copied GCA_030587545.2_ASM3058754v2.gbk to Sigynarchaeaceae/\n",
      "2026-01-21 11:11:15,962 [INFO] Copied GCA_029855935.1_ASM2985593v1.gbk to Thorarchaeaceae/\n",
      "2026-01-21 11:11:15,965 [INFO] Copied GCA_016840425.1_ASM1684042v1.gbk to Wukongarchaeaceae/\n",
      "2026-01-21 11:11:15,965 [INFO] GBK files copied into family directories\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "MAIN_OUTDIR = Path(MAIN_OUTDIR)\n",
    "GBK_OUT_DIR = MAIN_OUTDIR / f\"gbk_family_organized_{rightnow}\"\n",
    "GBK_OUT_DIR.mkdir(exist_ok=True)\n",
    "gbk_out = MAIN_OUTDIR / \"GBK_patched_dir\"\n",
    "gbk_out.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# Copy GBK files organized by family\n",
    "for family, fam_df in rep_df.groupby(\"family\"):\n",
    "    fam_dir = GBK_OUT_DIR / family\n",
    "    fam_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for genome in fam_df[\"genome_id\"].unique():  # Fixed: removed _x suffix\n",
    "        src_gbk = gff_dir / f\"{genome}_genomic\" / f\"{genome}_genomic.gbk\"\n",
    "        dst_gbk = fam_dir / f\"{genome}.gbk\"\n",
    "\n",
    "        if not src_gbk.exists():\n",
    "            logging.warning(\"Missing GBK: %s\", src_gbk)\n",
    "            continue\n",
    "\n",
    "        shutil.copy(src_gbk, dst_gbk)\n",
    "        logging.info(f\"Copied {genome}.gbk to {family}/\")\n",
    "\n",
    "logging.info(\"GBK files copied into family directories\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39c503b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Bio import SeqIO\n",
    "# from tqdm import tqdm\n",
    "# import logging\n",
    "\n",
    "# def has_gene(record):\n",
    "#     \"\"\"Check if a record has any CDS or gene features.\"\"\"\n",
    "#     return any(\n",
    "#         f.type in {\"CDS\", \"gene\"} \n",
    "#         for f in record.features\n",
    "#     )\n",
    "\n",
    "# def patch_gbk_with_architecture(\n",
    "#     gbk_path,\n",
    "#     arch_df,\n",
    "#     protein_col=\"protein_id\",\n",
    "#     arch_col=\"architecture\",\n",
    "#     rep_col=\"rep_arch_canonical\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Patch GenBank file with architecture annotations.\n",
    "#     Modifies CDS features to include architecture information.\n",
    "#     Filters out empty contigs after patching.\n",
    "#     \"\"\"\n",
    "#     print(arch_df.columns)\n",
    "#     # Create lookup dictionary\n",
    "#     lookup = arch_df.set_index(protein_col).to_dict(\"index\")\n",
    "#     logging.info(f\"Lookup keys sample: {list(lookup.keys())[:5]}\")\n",
    "    \n",
    "#     logging.info(f\"Patching {gbk_path.name} with {len(lookup)} annotated proteins\")\n",
    "\n",
    "#     records = []\n",
    "#     total_genes_found = 0\n",
    "#     total_genes_annotated = 0\n",
    "\n",
    "#     for record in SeqIO.parse(gbk_path, \"genbank\"):\n",
    "#         new_features = []\n",
    "#         genes_found = 0\n",
    "#         genes_annotated = 0\n",
    "\n",
    "#         for feat in record.features:\n",
    "#             # Keep non-CDS features as-is\n",
    "#             if feat.type != \"CDS\":\n",
    "#                 new_features.append(feat)\n",
    "#                 continue\n",
    "\n",
    "#             genes_found += 1\n",
    "            \n",
    "#             # Get protein_id from the CDS feature\n",
    "#             pid = feat.qualifiers.get(\"locus_tag\", [None])[0]\n",
    "\n",
    "#             if pid is None or pid not in lookup:\n",
    "#                 # Gene is outside annotation windows - skip\n",
    "#                 continue\n",
    "\n",
    "#             # Get architecture info\n",
    "#             info = lookup[pid]\n",
    "#             arch = info.get(arch_col, \"other\")\n",
    "#             rep = info.get(rep_col, \"NA\")\n",
    "\n",
    "#             genes_annotated += 1\n",
    "\n",
    "#             # Modify the CDS feature qualifiers\n",
    "#             if arch != \"other\":\n",
    "#                 feat.qualifiers[\"gene\"] = [arch]\n",
    "#                 feat.qualifiers[\"product\"] = [arch]\n",
    "#             else:\n",
    "#                 continue\n",
    "            \n",
    "#             # Add architecture notes\n",
    "#             if \"note\" not in feat.qualifiers:\n",
    "#                 feat.qualifiers[\"note\"] = []\n",
    "            \n",
    "#             feat.qualifiers[\"note\"].append(f\"architecture={arch}\")\n",
    "#             if rep != \"NA\":\n",
    "#                 feat.qualifiers[\"note\"].append(f\"representative_arch={rep}\")\n",
    "            \n",
    "#             new_features.append(feat)\n",
    "\n",
    "#         record.features = new_features\n",
    "#         total_genes_found += genes_found\n",
    "#         total_genes_annotated += genes_annotated\n",
    "        \n",
    "#         # Only keep records that have genes after patching\n",
    "#         if has_gene(record):\n",
    "#             records.append(record)\n",
    "#             logging.info(\n",
    "#                 f\"  {record.id}: {genes_annotated}/{genes_found} genes annotated - KEPT\"\n",
    "#             )\n",
    "#         else:\n",
    "#             logging.info(\n",
    "#                 f\"  {record.id}: {genes_annotated}/{genes_found} genes annotated - REMOVED (empty)\"\n",
    "#             )\n",
    "\n",
    "#     gbk_file = gbk_out / f\"{arch_df['family'].unique()[0]}_patched.gbk\"\n",
    "#     print(gbk_file)\n",
    "    \n",
    "#     out_gbk_path = gbk_file\n",
    "    \n",
    "#     # Write modified records back\n",
    "#     with open(out_gbk_path, \"w\") as out_handle:\n",
    "#         SeqIO.write(records, out_handle, \"genbank\")\n",
    "    \n",
    "#     logging.info(\n",
    "#         f\"Successfully patched {gbk_path.name}: \"\n",
    "#         f\"kept {len(records)} contigs, \"\n",
    "#         f\"annotated {total_genes_annotated}/{total_genes_found} genes\"\n",
    "#     )\n",
    "    \n",
    "#     return len(records), total_genes_annotated\n",
    "\n",
    "\n",
    "# # Patch all GBK files with architecture annotations\n",
    "# for family, fam_df in tqdm(rep_df.groupby(\"family\")):\n",
    "#     fam_dir = GBK_OUT_DIR / family\n",
    "    \n",
    "#     logging.info(f\"Patching family: {family} ({len(fam_df)} annotations)\")\n",
    "\n",
    "#     for gbk_file in fam_dir.glob(\"*.gbk\"):\n",
    "#         # Extract genome_id from filename\n",
    "#         genome_id = gbk_file.stem  # removes .gbk extension\n",
    "        \n",
    "#         # Filter annotations for this specific genome\n",
    "#         genome_df = fam_df[fam_df[\"genome_id\"] == genome_id]\n",
    "        \n",
    "#         if genome_df.empty:\n",
    "#             logging.warning(f\"No annotations found for {genome_id}, skipping\")\n",
    "#             continue\n",
    "        \n",
    "#         num_contigs, num_genes = patch_gbk_with_architecture(\n",
    "#             gbk_path=gbk_file,\n",
    "#             arch_df=genome_df\n",
    "#         )\n",
    "\n",
    "# logging.info(\"All GBK files patched with architecture annotations and filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a20f7820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:15,992 [INFO] Patching family: Baldrarchaeaceae (12 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:15,994 [INFO] Lookup keys sample: ['JPJMNJDP_00791', 'JPJMNJDP_00792', 'JPJMNJDP_00793', 'JPJMNJDP_00794', 'JPJMNJDP_00795']\n",
      "2026-01-21 11:11:15,994 [INFO] Patching GCA_016840465.1_ASM1684046v1.gbk with 12 annotated proteins\n",
      "2026-01-21 11:11:15,997 [INFO]   JAEOSH010000005.1: 0/78 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:15,997 [INFO]   JAEOSH010000087.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:15,998 [INFO]   JAEOSH010000053.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:15,999 [INFO]   JAEOSH010000054.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,000 [INFO]   JAEOSH010000055.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,001 [INFO]   JAEOSH010000056.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,002 [INFO]   JAEOSH010000018.1: 0/40 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,003 [INFO]   JAEOSH010000088.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,004 [INFO]   JAEOSH010000019.1: 0/34 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,005 [INFO]   JAEOSH010000089.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,006 [INFO]   JAEOSH010000057.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,009 [INFO]   JAEOSH010000006.1: 0/75 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,009 [INFO]   JAEOSH010000090.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,010 [INFO]   JAEOSH010000091.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,011 [INFO]   JAEOSH010000020.1: 0/31 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,012 [INFO]   JAEOSH010000092.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,012 [INFO]   JAEOSH010000093.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,013 [INFO]   JAEOSH010000058.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,014 [INFO]   JAEOSH010000021.1: 0/35 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,015 [INFO]   JAEOSH010000059.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,016 [INFO]   JAEOSH010000060.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,017 [INFO]   JAEOSH010000061.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,018 [INFO]   JAEOSH010000022.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,018 [INFO]   JAEOSH010000094.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,019 [INFO]   JAEOSH010000062.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,020 [INFO]   JAEOSH010000095.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,020 [INFO]   JAEOSH010000063.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,021 [INFO]   JAEOSH010000064.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,022 [INFO]   JAEOSH010000096.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,024 [INFO]   JAEOSH010000007.1: 0/66 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,024 [INFO]   JAEOSH010000065.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,025 [INFO]   JAEOSH010000023.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,026 [INFO]   JAEOSH010000066.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,027 [INFO]   JAEOSH010000097.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,028 [INFO]   JAEOSH010000024.1: 0/37 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,028 [INFO]   JAEOSH010000098.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,029 [INFO]   JAEOSH010000067.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,030 [INFO]   JAEOSH010000025.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,031 [INFO]   JAEOSH010000068.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,032 [INFO]   JAEOSH010000099.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,032 [INFO]   JAEOSH010000069.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,035 [INFO]   JAEOSH010000008.1: 0/52 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,035 [INFO]   JAEOSH010000100.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,036 [INFO]   JAEOSH010000070.1: 9/12 genes annotated - KEPT\n",
      "2026-01-21 11:11:16,037 [INFO]   JAEOSH010000026.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,038 [INFO]   JAEOSH010000027.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,039 [INFO]   JAEOSH010000071.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,039 [INFO]   JAEOSH010000072.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,040 [INFO]   JAEOSH010000028.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,041 [INFO]   JAEOSH010000029.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,042 [INFO]   JAEOSH010000030.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,044 [INFO]   JAEOSH010000009.1: 0/60 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,045 [INFO]   JAEOSH010000073.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,046 [INFO]   JAEOSH010000010.1: 0/50 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,048 [INFO]   JAEOSH010000031.1: 0/27 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,051 [INFO]   JAEOSH010000001.1: 0/122 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,052 [INFO]   JAEOSH010000032.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,053 [INFO]   JAEOSH010000033.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,054 [INFO]   JAEOSH010000034.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,055 [INFO]   JAEOSH010000035.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,057 [INFO]   JAEOSH010000011.1: 0/45 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,058 [INFO]   JAEOSH010000036.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,059 [INFO]   JAEOSH010000037.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,060 [INFO]   JAEOSH010000012.1: 0/56 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,061 [INFO]   JAEOSH010000038.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,062 [INFO]   JAEOSH010000039.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,070 [INFO]   JAEOSH010000002.1: 0/124 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,073 [INFO]   JAEOSH010000013.1: 0/44 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,074 [INFO]   JAEOSH010000040.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,076 [INFO]   JAEOSH010000041.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,077 [INFO]   JAEOSH010000042.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,080 [INFO]   JAEOSH010000014.1: 0/46 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,081 [INFO]   JAEOSH010000074.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,083 [INFO]   JAEOSH010000043.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,084 [INFO]   JAEOSH010000044.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,086 [INFO]   JAEOSH010000015.1: 0/51 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,086 [INFO]   JAEOSH010000075.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,087 [INFO]   JAEOSH010000045.1: 0/29 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,088 [INFO]   JAEOSH010000046.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,089 [INFO]   JAEOSH010000076.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,090 [INFO]   JAEOSH010000047.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,091 [INFO]   JAEOSH010000077.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,093 [INFO]   JAEOSH010000016.1: 0/43 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,096 [INFO]   JAEOSH010000003.1: 0/90 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,097 [INFO]   JAEOSH010000048.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,098 [INFO]   JAEOSH010000049.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,099 [INFO]   JAEOSH010000078.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,100 [INFO]   JAEOSH010000079.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,102 [INFO]   JAEOSH010000004.1: 0/98 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,103 [INFO]   JAEOSH010000080.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,103 [INFO]   JAEOSH010000081.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,104 [INFO]   JAEOSH010000050.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,105 [INFO]   JAEOSH010000082.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,106 [INFO]   JAEOSH010000051.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,106 [INFO]   JAEOSH010000083.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,108 [INFO]   JAEOSH010000017.1: 0/41 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,109 [INFO]   JAEOSH010000084.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,109 [INFO]   JAEOSH010000085.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,110 [INFO]   JAEOSH010000086.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,111 [INFO]   JAEOSH010000052.1: 0/14 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/Baldrarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:16,112 [INFO] Successfully patched GCA_016840465.1_ASM1684046v1.gbk: kept 1 contigs, annotated 9/2367 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1/16 [00:00<00:01,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:16,112 [INFO] Patching family: DXJG01 (333 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:16,115 [INFO] Lookup keys sample: ['DBDKMGEL_01461', 'DBDKMGEL_01462', 'DBDKMGEL_01463', 'DBDKMGEL_01464', 'DBDKMGEL_01465']\n",
      "2026-01-21 11:11:16,115 [INFO] Patching GCA_019056805.1_ASM1905680v1.gbk with 333 annotated proteins\n",
      "2026-01-21 11:11:16,116 [INFO]   DXJG01000011.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,118 [INFO]   DXJG01000012.1: 0/27 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,119 [INFO]   DXJG01000013.1: 0/35 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,120 [INFO]   DXJG01000014.1: 0/27 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,121 [INFO]   DXJG01000015.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,126 [INFO]   DXJG01000001.1: 0/188 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,127 [INFO]   DXJG01000016.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,128 [INFO]   DXJG01000017.1: 0/28 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,144 [INFO]   DXJG01000002.1: 0/587 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,146 [INFO]   DXJG01000003.1: 0/79 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,153 [INFO]   DXJG01000004.1: 0/253 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,154 [INFO]   DXJG01000018.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,155 [INFO]   DXJG01000005.1: 0/50 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,156 [INFO]   DXJG01000006.1: 0/36 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,159 [INFO]   DXJG01000007.1: 0/80 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,160 [INFO]   DXJG01000008.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,169 [INFO]   DXJG01000009.1: 16/333 genes annotated - KEPT\n",
      "2026-01-21 11:11:16,171 [INFO]   DXJG01000010.1: 0/106 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/DXJG01_patched.gbk\n",
      "2026-01-21 11:11:16,177 [INFO] Successfully patched GCA_019056805.1_ASM1905680v1.gbk: kept 1 contigs, annotated 16/1888 genes\n",
      "2026-01-21 11:11:16,177 [INFO] Patching family: Freyrarchaeaceae (577 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:16,181 [INFO] Lookup keys sample: ['OGPGAEMM_00001', 'OGPGAEMM_00002', 'OGPGAEMM_00003', 'OGPGAEMM_00004', 'OGPGAEMM_00005']\n",
      "2026-01-21 11:11:16,181 [INFO] Patching GCA_038820475.1_ASM3882047v1.gbk with 577 annotated proteins\n",
      "2026-01-21 11:11:16,196 [INFO]   JAWBET010000001.1: 7/577 genes annotated - KEPT\n",
      "2026-01-21 11:11:16,202 [INFO]   JAWBET010000002.1: 0/227 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,208 [INFO]   JAWBET010000003.1: 0/235 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,213 [INFO]   JAWBET010000004.1: 0/170 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,216 [INFO]   JAWBET010000005.1: 0/97 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,218 [INFO]   JAWBET010000006.1: 0/112 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,221 [INFO]   JAWBET010000007.1: 0/101 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,224 [INFO]   JAWBET010000008.1: 0/74 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,225 [INFO]   JAWBET010000009.1: 0/67 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,227 [INFO]   JAWBET010000010.1: 0/53 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,229 [INFO]   JAWBET010000011.1: 0/46 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,230 [INFO]   JAWBET010000012.1: 0/27 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,231 [INFO]   JAWBET010000013.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,232 [INFO]   JAWBET010000014.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,233 [INFO]   JAWBET010000015.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,234 [INFO]   JAWBET010000016.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,235 [INFO]   JAWBET010000017.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,235 [INFO]   JAWBET010000018.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,236 [INFO]   JAWBET010000019.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,237 [INFO]   JAWBET010000020.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,238 [INFO]   JAWBET010000021.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,238 [INFO]   JAWBET010000022.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,239 [INFO]   JAWBET010000023.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,240 [INFO]   JAWBET010000024.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,241 [INFO]   JAWBET010000025.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,241 [INFO]   JAWBET010000026.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,242 [INFO]   JAWBET010000027.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,243 [INFO]   JAWBET010000028.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,244 [INFO]   JAWBET010000029.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,244 [INFO]   JAWBET010000030.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,245 [INFO]   JAWBET010000031.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,246 [INFO]   JAWBET010000032.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,246 [INFO]   JAWBET010000033.1: 0/5 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/Freyrarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:16,255 [INFO] Successfully patched GCA_038820475.1_ASM3882047v1.gbk: kept 1 contigs, annotated 7/2006 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3/16 [00:00<00:01, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:16,256 [INFO] Patching family: HEL-GB-B (67 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:16,259 [INFO] Lookup keys sample: ['AEGAMCKF_02026', 'AEGAMCKF_02027', 'AEGAMCKF_02028', 'AEGAMCKF_02029', 'AEGAMCKF_02030']\n",
      "2026-01-21 11:11:16,260 [INFO] Patching GCA_005191425.1_ASM519142v1.gbk with 67 annotated proteins\n",
      "2026-01-21 11:11:16,261 [INFO]   SUPR01000098.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,262 [INFO]   SUPR01000099.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,263 [INFO]   SUPR01000100.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,263 [INFO]   SUPR01000101.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,264 [INFO]   SUPR01000102.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,265 [INFO]   SUPR01000103.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,266 [INFO]   SUPR01000104.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,267 [INFO]   SUPR01000105.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,268 [INFO]   SUPR01000010.1: 0/53 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,269 [INFO]   SUPR01000106.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,270 [INFO]   SUPR01000107.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,271 [INFO]   SUPR01000108.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,271 [INFO]   SUPR01000109.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,272 [INFO]   SUPR01000110.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,273 [INFO]   SUPR01000111.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,274 [INFO]   SUPR01000112.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,274 [INFO]   SUPR01000113.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,275 [INFO]   SUPR01000114.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,278 [INFO]   SUPR01000011.1: 0/53 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,279 [INFO]   SUPR01000115.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,280 [INFO]   SUPR01000116.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,280 [INFO]   SUPR01000117.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,281 [INFO]   SUPR01000118.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,282 [INFO]   SUPR01000119.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,282 [INFO]   SUPR01000120.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,284 [INFO]   SUPR01000012.1: 0/47 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,285 [INFO]   SUPR01000121.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,285 [INFO]   SUPR01000122.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,286 [INFO]   SUPR01000123.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,287 [INFO]   SUPR01000124.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,288 [INFO]   SUPR01000125.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,288 [INFO]   SUPR01000126.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,289 [INFO]   SUPR01000127.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,290 [INFO]   SUPR01000128.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,291 [INFO]   SUPR01000129.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,293 [INFO]   SUPR01000013.1: 0/47 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,294 [INFO]   SUPR01000130.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,295 [INFO]   SUPR01000131.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,295 [INFO]   SUPR01000132.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,296 [INFO]   SUPR01000133.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,297 [INFO]   SUPR01000134.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,297 [INFO]   SUPR01000135.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,298 [INFO]   SUPR01000136.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,299 [INFO]   SUPR01000137.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,300 [INFO]   SUPR01000014.1: 0/44 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,301 [INFO]   SUPR01000138.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,301 [INFO]   SUPR01000139.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,302 [INFO]   SUPR01000140.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,302 [INFO]   SUPR01000141.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,303 [INFO]   SUPR01000142.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,304 [INFO]   SUPR01000143.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,305 [INFO]   SUPR01000144.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,305 [INFO]   SUPR01000145.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,306 [INFO]   SUPR01000146.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,307 [INFO]   SUPR01000147.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,308 [INFO]   SUPR01000015.1: 0/40 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,309 [INFO]   SUPR01000148.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,310 [INFO]   SUPR01000149.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,310 [INFO]   SUPR01000150.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,311 [INFO]   SUPR01000151.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,311 [INFO]   SUPR01000152.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,312 [INFO]   SUPR01000153.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,313 [INFO]   SUPR01000154.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,314 [INFO]   SUPR01000155.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,315 [INFO]   SUPR01000016.1: 0/39 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,316 [INFO]   SUPR01000156.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,317 [INFO]   SUPR01000157.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,317 [INFO]   SUPR01000158.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,318 [INFO]   SUPR01000159.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,318 [INFO]   SUPR01000160.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,319 [INFO]   SUPR01000161.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,320 [INFO]   SUPR01000162.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,320 [INFO]   SUPR01000163.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,322 [INFO]   SUPR01000017.1: 0/43 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,322 [INFO]   SUPR01000164.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,323 [INFO]   SUPR01000165.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,323 [INFO]   SUPR01000166.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,324 [INFO]   SUPR01000167.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,325 [INFO]   SUPR01000168.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,325 [INFO]   SUPR01000169.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,326 [INFO]   SUPR01000170.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,326 [INFO]   SUPR01000171.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,328 [INFO]   SUPR01000018.1: 0/42 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,328 [INFO]   SUPR01000172.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,329 [INFO]   SUPR01000173.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,329 [INFO]   SUPR01000174.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,330 [INFO]   SUPR01000175.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,330 [INFO]   SUPR01000176.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,331 [INFO]   SUPR01000177.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,332 [INFO]   SUPR01000178.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,332 [INFO]   SUPR01000179.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,333 [INFO]   SUPR01000019.1: 0/31 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,336 [INFO]   SUPR01000001.1: 0/63 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,337 [INFO]   SUPR01000180.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,338 [INFO]   SUPR01000020.1: 0/36 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,339 [INFO]   SUPR01000021.1: 0/41 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,340 [INFO]   SUPR01000022.1: 0/31 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,342 [INFO]   SUPR01000023.1: 0/35 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,343 [INFO]   SUPR01000024.1: 0/45 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,344 [INFO]   SUPR01000181.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,344 [INFO]   SUPR01000182.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,345 [INFO]   SUPR01000025.1: 0/36 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,347 [INFO]   SUPR01000026.1: 0/37 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,348 [INFO]   SUPR01000027.1: 0/33 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,351 [INFO]   SUPR01000028.1: 0/44 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,352 [INFO]   SUPR01000029.1: 0/29 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,354 [INFO]   SUPR01000002.1: 0/66 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,355 [INFO]   SUPR01000030.1: 0/30 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,357 [INFO]   SUPR01000031.1: 0/33 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,358 [INFO]   SUPR01000032.1: 0/31 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,359 [INFO]   SUPR01000033.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,360 [INFO]   SUPR01000034.1: 0/33 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,362 [INFO]   SUPR01000035.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,363 [INFO]   SUPR01000036.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,364 [INFO]   SUPR01000037.1: 0/28 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,365 [INFO]   SUPR01000038.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,366 [INFO]   SUPR01000039.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,368 [INFO]   SUPR01000003.1: 0/59 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,369 [INFO]   SUPR01000040.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,370 [INFO]   SUPR01000041.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,371 [INFO]   SUPR01000042.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,372 [INFO]   SUPR01000043.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,373 [INFO]   SUPR01000044.1: 0/29 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,374 [INFO]   SUPR01000045.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,376 [INFO]   SUPR01000046.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,376 [INFO]   SUPR01000047.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,378 [INFO]   SUPR01000048.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,380 [INFO]   SUPR01000004.1: 10/67 genes annotated - KEPT\n",
      "2026-01-21 11:11:16,381 [INFO]   SUPR01000049.1: 0/30 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,382 [INFO]   SUPR01000050.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,383 [INFO]   SUPR01000051.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,384 [INFO]   SUPR01000052.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,385 [INFO]   SUPR01000053.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,386 [INFO]   SUPR01000054.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,387 [INFO]   SUPR01000055.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,388 [INFO]   SUPR01000056.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,389 [INFO]   SUPR01000057.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,390 [INFO]   SUPR01000058.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,392 [INFO]   SUPR01000005.1: 0/61 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,393 [INFO]   SUPR01000059.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,394 [INFO]   SUPR01000060.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,395 [INFO]   SUPR01000061.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,396 [INFO]   SUPR01000062.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,397 [INFO]   SUPR01000063.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,398 [INFO]   SUPR01000064.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,399 [INFO]   SUPR01000065.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,400 [INFO]   SUPR01000066.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,401 [INFO]   SUPR01000067.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,402 [INFO]   SUPR01000068.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,406 [INFO]   SUPR01000006.1: 0/64 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,408 [INFO]   SUPR01000069.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,409 [INFO]   SUPR01000070.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,410 [INFO]   SUPR01000071.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,411 [INFO]   SUPR01000072.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,412 [INFO]   SUPR01000073.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,412 [INFO]   SUPR01000074.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,413 [INFO]   SUPR01000075.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,414 [INFO]   SUPR01000076.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,415 [INFO]   SUPR01000077.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,417 [INFO]   SUPR01000007.1: 0/54 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,417 [INFO]   SUPR01000078.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,418 [INFO]   SUPR01000079.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,419 [INFO]   SUPR01000080.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,420 [INFO]   SUPR01000081.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,421 [INFO]   SUPR01000082.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,421 [INFO]   SUPR01000083.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,422 [INFO]   SUPR01000084.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,423 [INFO]   SUPR01000085.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,424 [INFO]   SUPR01000086.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,425 [INFO]   SUPR01000087.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,426 [INFO]   SUPR01000008.1: 0/49 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,427 [INFO]   SUPR01000088.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,428 [INFO]   SUPR01000089.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,428 [INFO]   SUPR01000090.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,429 [INFO]   SUPR01000091.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,430 [INFO]   SUPR01000092.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,431 [INFO]   SUPR01000093.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,432 [INFO]   SUPR01000094.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,432 [INFO]   SUPR01000095.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,433 [INFO]   SUPR01000096.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,434 [INFO]   SUPR01000097.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,436 [INFO]   SUPR01000009.1: 0/47 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/HEL-GB-B_patched.gbk\n",
      "2026-01-21 11:11:16,438 [INFO] Successfully patched GCA_005191425.1_ASM519142v1.gbk: kept 1 contigs, annotated 10/3164 genes\n",
      "2026-01-21 11:11:16,438 [INFO] Patching family: Heimdallarchaeaceae (78 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:16,440 [INFO] Lookup keys sample: ['OKAEMJCJ_02667', 'OKAEMJCJ_02668', 'OKAEMJCJ_02669', 'OKAEMJCJ_02670', 'OKAEMJCJ_02671']\n",
      "2026-01-21 11:11:16,441 [INFO] Patching GCA_030668875.1_ASM3066887v1.gbk with 78 annotated proteins\n",
      "2026-01-21 11:11:16,442 [INFO]   DAOVER010000058.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,443 [INFO]   DAOVER010000070.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,445 [INFO]   DAOVER010000016.1: 0/63 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,446 [INFO]   DAOVER010000067.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,447 [INFO]   DAOVER010000073.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,447 [INFO]   DAOVER010000077.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,448 [INFO]   DAOVER010000054.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,449 [INFO]   DAOVER010000079.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,451 [INFO]   DAOVER010000014.1: 0/64 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,452 [INFO]   DAOVER010000030.1: 0/33 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,453 [INFO]   DAOVER010000040.1: 0/28 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,455 [INFO]   DAOVER010000017.1: 0/63 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,457 [INFO]   DAOVER010000013.1: 0/60 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,458 [INFO]   DAOVER010000096.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,461 [INFO]   DAOVER010000010.1: 0/80 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,461 [INFO]   DAOVER010000092.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,463 [INFO]   DAOVER010000029.1: 0/37 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,464 [INFO]   DAOVER010000038.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,465 [INFO]   DAOVER010000023.1: 0/37 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,466 [INFO]   DAOVER010000049.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,467 [INFO]   DAOVER010000090.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,468 [INFO]   DAOVER010000015.1: 0/61 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,471 [INFO]   DAOVER010000011.1: 0/71 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,472 [INFO]   DAOVER010000053.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,473 [INFO]   DAOVER010000080.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,474 [INFO]   DAOVER010000074.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,475 [INFO]   DAOVER010000031.1: 0/30 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,476 [INFO]   DAOVER010000097.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,479 [INFO]   DAOVER010000003.1: 0/117 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,480 [INFO]   DAOVER010000062.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,481 [INFO]   DAOVER010000032.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,482 [INFO]   DAOVER010000026.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,483 [INFO]   DAOVER010000034.1: 0/27 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,486 [INFO]   DAOVER010000007.1: 0/89 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,486 [INFO]   DAOVER010000094.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,490 [INFO]   DAOVER010000001.1: 0/99 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,491 [INFO]   DAOVER010000044.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,494 [INFO]   DAOVER010000004.1: 0/101 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,496 [INFO]   DAOVER010000020.1: 0/49 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,498 [INFO]   DAOVER010000002.1: 0/102 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,499 [INFO]   DAOVER010000057.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,500 [INFO]   DAOVER010000061.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,501 [INFO]   DAOVER010000082.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,502 [INFO]   DAOVER010000072.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,502 [INFO]   DAOVER010000095.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,503 [INFO]   DAOVER010000098.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,505 [INFO]   DAOVER010000019.1: 0/59 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,506 [INFO]   DAOVER010000018.1: 0/42 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,507 [INFO]   DAOVER010000059.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,508 [INFO]   DAOVER010000065.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,509 [INFO]   DAOVER010000086.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,510 [INFO]   DAOVER010000045.1: 0/27 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,511 [INFO]   DAOVER010000039.1: 0/27 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,512 [INFO]   DAOVER010000035.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,513 [INFO]   DAOVER010000089.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,514 [INFO]   DAOVER010000055.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,514 [INFO]   DAOVER010000046.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,516 [INFO]   DAOVER010000021.1: 0/58 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,517 [INFO]   DAOVER010000075.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,518 [INFO]   DAOVER010000071.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,519 [INFO]   DAOVER010000050.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,519 [INFO]   DAOVER010000083.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,520 [INFO]   DAOVER010000099.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,521 [INFO]   DAOVER010000060.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,521 [INFO]   DAOVER010000091.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,522 [INFO]   DAOVER010000041.1: 0/36 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,524 [INFO]   DAOVER010000037.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,527 [INFO]   DAOVER010000005.1: 0/112 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,528 [INFO]   DAOVER010000066.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,529 [INFO]   DAOVER010000085.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,530 [INFO]   DAOVER010000024.1: 0/45 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,531 [INFO]   DAOVER010000078.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,532 [INFO]   DAOVER010000063.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,535 [INFO]   DAOVER010000009.1: 0/76 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,536 [INFO]   DAOVER010000027.1: 0/31 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,537 [INFO]   DAOVER010000056.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,538 [INFO]   DAOVER010000093.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,538 [INFO]   DAOVER010000068.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,539 [INFO]   DAOVER010000048.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,540 [INFO]   DAOVER010000064.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,540 [INFO]   DAOVER010000087.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,541 [INFO]   DAOVER010000033.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,543 [INFO]   DAOVER010000028.1: 0/31 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,543 [INFO]   DAOVER010000069.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,544 [INFO]   DAOVER010000036.1: 0/29 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,545 [INFO]   DAOVER010000051.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,546 [INFO]   DAOVER010000084.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,549 [INFO]   DAOVER010000012.1: 0/82 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,550 [INFO]   DAOVER010000052.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,551 [INFO]   DAOVER010000047.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,554 [INFO]   DAOVER010000008.1: 10/78 genes annotated - KEPT\n",
      "2026-01-21 11:11:16,554 [INFO]   DAOVER010000081.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,556 [INFO]   DAOVER010000042.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,557 [INFO]   DAOVER010000025.1: 0/43 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,560 [INFO]   DAOVER010000006.1: 0/97 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,561 [INFO]   DAOVER010000043.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,562 [INFO]   DAOVER010000088.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,562 [INFO]   DAOVER010000076.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,564 [INFO]   DAOVER010000022.1: 0/42 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/Heimdallarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:16,567 [INFO] Successfully patched GCA_030668875.1_ASM3066887v1.gbk: kept 1 contigs, annotated 10/2972 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 5/16 [00:00<00:01,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:16,568 [INFO] Patching family: Hodarchaeaceae (95 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:16,570 [INFO] Lookup keys sample: ['DKIBDBBH_00250', 'DKIBDBBH_00251', 'DKIBDBBH_00252', 'DKIBDBBH_00253', 'DKIBDBBH_00254']\n",
      "2026-01-21 11:11:16,570 [INFO] Patching GCA_003144275.1_ASM314427v1.gbk with 95 annotated proteins\n",
      "2026-01-21 11:11:16,571 [INFO]   NJBF01000082.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,572 [INFO]   NJBF01000083.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,572 [INFO]   NJBF01000084.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,575 [INFO]   NJBF01000008.1: 0/92 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,576 [INFO]   NJBF01000085.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,577 [INFO]   NJBF01000086.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,578 [INFO]   NJBF01000043.1: 0/29 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,580 [INFO]   NJBF01000009.1: 0/81 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,581 [INFO]   NJBF01000087.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,583 [INFO]   NJBF01000010.1: 11/95 genes annotated - KEPT\n",
      "2026-01-21 11:11:16,586 [INFO]   NJBF01000011.1: 0/76 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,587 [INFO]   NJBF01000088.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,587 [INFO]   NJBF01000089.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,588 [INFO]   NJBF01000044.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,589 [INFO]   NJBF01000045.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,590 [INFO]   NJBF01000090.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,590 [INFO]   NJBF01000091.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,591 [INFO]   NJBF01000092.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,594 [INFO]   NJBF01000012.1: 0/87 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,595 [INFO]   NJBF01000093.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,597 [INFO]   NJBF01000013.1: 0/70 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,598 [INFO]   NJBF01000094.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,600 [INFO]   NJBF01000014.1: 0/69 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,600 [INFO]   NJBF01000095.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,601 [INFO]   NJBF01000046.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,602 [INFO]   NJBF01000096.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,604 [INFO]   NJBF01000015.1: 0/74 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,605 [INFO]   NJBF01000097.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,605 [INFO]   NJBF01000098.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,608 [INFO]   NJBF01000016.1: 0/69 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,610 [INFO]   NJBF01000017.1: 0/77 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,612 [INFO]   NJBF01000018.1: 0/63 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,613 [INFO]   NJBF01000047.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,615 [INFO]   NJBF01000019.1: 0/65 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,616 [INFO]   NJBF01000048.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,617 [INFO]   NJBF01000049.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,618 [INFO]   NJBF01000099.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,620 [INFO]   NJBF01000020.1: 0/61 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,620 [INFO]   NJBF01000100.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,621 [INFO]   NJBF01000101.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,622 [INFO]   NJBF01000102.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,622 [INFO]   NJBF01000103.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,625 [INFO]   NJBF01000021.1: 0/70 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,627 [INFO]   NJBF01000022.1: 0/67 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,628 [INFO]   NJBF01000050.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,629 [INFO]   NJBF01000051.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,631 [INFO]   NJBF01000023.1: 0/69 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,633 [INFO]   NJBF01000024.1: 0/52 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,634 [INFO]   NJBF01000025.1: 0/47 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,636 [INFO]   NJBF01000026.1: 0/65 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,637 [INFO]   NJBF01000052.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,638 [INFO]   NJBF01000053.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,640 [INFO]   NJBF01000027.1: 0/62 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,642 [INFO]   NJBF01000028.1: 0/54 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,643 [INFO]   NJBF01000054.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,644 [INFO]   NJBF01000055.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,649 [INFO]   NJBF01000001.1: 0/196 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,650 [INFO]   NJBF01000029.1: 0/60 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,651 [INFO]   NJBF01000056.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,652 [INFO]   NJBF01000057.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,653 [INFO]   NJBF01000030.1: 0/51 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,654 [INFO]   NJBF01000058.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,656 [INFO]   NJBF01000031.1: 0/53 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,657 [INFO]   NJBF01000059.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,658 [INFO]   NJBF01000060.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,659 [INFO]   NJBF01000061.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,660 [INFO]   NJBF01000062.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,660 [INFO]   NJBF01000063.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,661 [INFO]   NJBF01000064.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,663 [INFO]   NJBF01000032.1: 0/48 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,664 [INFO]   NJBF01000065.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,665 [INFO]   NJBF01000066.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,665 [INFO]   NJBF01000067.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,667 [INFO]   NJBF01000033.1: 0/45 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,668 [INFO]   NJBF01000068.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,669 [INFO]   NJBF01000034.1: 0/36 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,670 [INFO]   NJBF01000069.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,671 [INFO]   NJBF01000070.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,671 [INFO]   NJBF01000071.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,675 [INFO]   NJBF01000002.1: 0/139 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,675 [INFO]   NJBF01000072.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,679 [INFO]   NJBF01000003.1: 0/121 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,680 [INFO]   NJBF01000073.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,681 [INFO]   NJBF01000035.1: 0/43 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,682 [INFO]   NJBF01000036.1: 0/40 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,684 [INFO]   NJBF01000037.1: 0/45 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,688 [INFO]   NJBF01000004.1: 0/75 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,691 [INFO]   NJBF01000005.1: 0/122 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,692 [INFO]   NJBF01000074.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,692 [INFO]   NJBF01000075.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,694 [INFO]   NJBF01000038.1: 0/30 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,695 [INFO]   NJBF01000076.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,698 [INFO]   NJBF01000006.1: 0/104 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,699 [INFO]   NJBF01000039.1: 0/31 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,700 [INFO]   NJBF01000077.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,703 [INFO]   NJBF01000007.1: 0/84 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,704 [INFO]   NJBF01000040.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,705 [INFO]   NJBF01000078.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,706 [INFO]   NJBF01000079.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,707 [INFO]   NJBF01000041.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,708 [INFO]   NJBF01000042.1: 0/27 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,708 [INFO]   NJBF01000080.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,709 [INFO]   NJBF01000081.1: 0/5 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/Hodarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:16,712 [INFO] Successfully patched GCA_003144275.1_ASM314427v1.gbk: kept 1 contigs, annotated 11/3520 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 6/16 [00:00<00:01,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:16,712 [INFO] Patching family: JABLTI01 (61 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:16,714 [INFO] Lookup keys sample: ['IDJBKAKB_00001', 'IDJBKAKB_00002', 'IDJBKAKB_00003', 'IDJBKAKB_00004', 'IDJBKAKB_00005']\n",
      "2026-01-21 11:11:16,715 [INFO] Patching GCA_030614005.1_ASM3061400v1.gbk with 61 annotated proteins\n",
      "2026-01-21 11:11:16,717 [INFO]   JAUWKS010000014.1: 4/61 genes annotated - KEPT\n",
      "2026-01-21 11:11:16,718 [INFO]   JAUWKS010000088.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,719 [INFO]   JAUWKS010000053.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,722 [INFO]   JAUWKS010000004.1: 0/97 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,724 [INFO]   JAUWKS010000027.1: 0/37 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,724 [INFO]   JAUWKS010000093.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,726 [INFO]   JAUWKS010000029.1: 0/46 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,727 [INFO]   JAUWKS010000024.1: 0/43 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,731 [INFO]   JAUWKS010000002.1: 0/157 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,732 [INFO]   JAUWKS010000035.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,733 [INFO]   JAUWKS010000080.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,734 [INFO]   JAUWKS010000095.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,735 [INFO]   JAUWKS010000089.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,736 [INFO]   JAUWKS010000076.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,737 [INFO]   JAUWKS010000054.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,737 [INFO]   JAUWKS010000060.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,739 [INFO]   JAUWKS010000063.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,740 [INFO]   JAUWKS010000073.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,740 [INFO]   JAUWKS010000126.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,742 [INFO]   JAUWKS010000017.1: 0/51 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,743 [INFO]   JAUWKS010000033.1: 0/34 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,744 [INFO]   JAUWKS010000101.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,745 [INFO]   JAUWKS010000047.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,747 [INFO]   JAUWKS010000008.1: 0/64 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,749 [INFO]   JAUWKS010000040.1: 0/35 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,750 [INFO]   JAUWKS010000018.1: 0/50 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,751 [INFO]   JAUWKS010000083.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,752 [INFO]   JAUWKS010000122.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,753 [INFO]   JAUWKS010000042.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,754 [INFO]   JAUWKS010000036.1: 0/33 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,756 [INFO]   JAUWKS010000025.1: 0/38 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,756 [INFO]   JAUWKS010000111.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,757 [INFO]   JAUWKS010000087.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,759 [INFO]   JAUWKS010000007.1: 0/69 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,762 [INFO]   JAUWKS010000003.1: 0/104 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,764 [INFO]   JAUWKS010000020.1: 0/53 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,765 [INFO]   JAUWKS010000113.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,765 [INFO]   JAUWKS010000102.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,766 [INFO]   JAUWKS010000123.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,768 [INFO]   JAUWKS010000010.1: 0/59 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,769 [INFO]   JAUWKS010000074.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,769 [INFO]   JAUWKS010000068.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,770 [INFO]   JAUWKS010000055.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,771 [INFO]   JAUWKS010000064.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,772 [INFO]   JAUWKS010000117.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,773 [INFO]   JAUWKS010000028.1: 0/50 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,774 [INFO]   JAUWKS010000115.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,775 [INFO]   JAUWKS010000119.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,776 [INFO]   JAUWKS010000052.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,777 [INFO]   JAUWKS010000085.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,778 [INFO]   JAUWKS010000082.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,779 [INFO]   JAUWKS010000097.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,779 [INFO]   JAUWKS010000120.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,780 [INFO]   JAUWKS010000030.1: 0/33 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,781 [INFO]   JAUWKS010000075.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,782 [INFO]   JAUWKS010000061.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,784 [INFO]   JAUWKS010000023.1: 0/47 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,784 [INFO]   JAUWKS010000057.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,786 [INFO]   JAUWKS010000009.1: 0/63 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,787 [INFO]   JAUWKS010000125.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,788 [INFO]   JAUWKS010000108.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,789 [INFO]   JAUWKS010000105.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,790 [INFO]   JAUWKS010000015.1: 0/49 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,792 [INFO]   JAUWKS010000072.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,792 [INFO]   JAUWKS010000099.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,793 [INFO]   JAUWKS010000081.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,795 [INFO]   JAUWKS010000021.1: 0/47 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,796 [INFO]   JAUWKS010000011.1: 0/46 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,798 [INFO]   JAUWKS010000022.1: 0/46 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,799 [INFO]   JAUWKS010000067.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,803 [INFO]   JAUWKS010000001.1: 0/149 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,804 [INFO]   JAUWKS010000079.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,807 [INFO]   JAUWKS010000005.1: 0/114 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,809 [INFO]   JAUWKS010000026.1: 0/43 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,810 [INFO]   JAUWKS010000048.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,811 [INFO]   JAUWKS010000037.1: 0/29 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,812 [INFO]   JAUWKS010000044.1: 0/29 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,813 [INFO]   JAUWKS010000058.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,814 [INFO]   JAUWKS010000092.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,815 [INFO]   JAUWKS010000114.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,817 [INFO]   JAUWKS010000006.1: 0/87 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,819 [INFO]   JAUWKS010000019.1: 0/58 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,820 [INFO]   JAUWKS010000062.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,821 [INFO]   JAUWKS010000043.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,822 [INFO]   JAUWKS010000045.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,823 [INFO]   JAUWKS010000110.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,824 [INFO]   JAUWKS010000038.1: 0/28 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,825 [INFO]   JAUWKS010000086.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,826 [INFO]   JAUWKS010000039.1: 0/34 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,827 [INFO]   JAUWKS010000078.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,827 [INFO]   JAUWKS010000098.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,828 [INFO]   JAUWKS010000100.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,829 [INFO]   JAUWKS010000091.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,830 [INFO]   JAUWKS010000046.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,831 [INFO]   JAUWKS010000032.1: 0/36 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,832 [INFO]   JAUWKS010000107.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,833 [INFO]   JAUWKS010000069.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,833 [INFO]   JAUWKS010000116.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,834 [INFO]   JAUWKS010000059.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,835 [INFO]   JAUWKS010000112.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,836 [INFO]   JAUWKS010000051.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,836 [INFO]   JAUWKS010000094.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,838 [INFO]   JAUWKS010000050.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,839 [INFO]   JAUWKS010000077.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,839 [INFO]   JAUWKS010000121.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,840 [INFO]   JAUWKS010000104.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,841 [INFO]   JAUWKS010000124.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,841 [INFO]   JAUWKS010000096.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,842 [INFO]   JAUWKS010000118.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,844 [INFO]   JAUWKS010000012.1: 0/64 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,844 [INFO]   JAUWKS010000103.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,846 [INFO]   JAUWKS010000016.1: 0/57 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,847 [INFO]   JAUWKS010000109.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,848 [INFO]   JAUWKS010000031.1: 0/31 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,849 [INFO]   JAUWKS010000106.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,849 [INFO]   JAUWKS010000084.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,850 [INFO]   JAUWKS010000056.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,851 [INFO]   JAUWKS010000071.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,852 [INFO]   JAUWKS010000034.1: 0/31 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,854 [INFO]   JAUWKS010000049.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,855 [INFO]   JAUWKS010000065.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,855 [INFO]   JAUWKS010000066.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,857 [INFO]   JAUWKS010000013.1: 0/56 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,858 [INFO]   JAUWKS010000070.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,859 [INFO]   JAUWKS010000041.1: 0/29 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,860 [INFO]   JAUWKS010000090.1: 0/12 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/JABLTI01_patched.gbk\n",
      "2026-01-21 11:11:16,862 [INFO] Successfully patched GCA_030614005.1_ASM3061400v1.gbk: kept 1 contigs, annotated 4/3303 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 7/16 [00:00<00:01,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:16,863 [INFO] Patching family: Jordiarchaeaceae (20 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:16,865 [INFO] Lookup keys sample: ['LGKOHNAD_02912', 'LGKOHNAD_02913', 'LGKOHNAD_02914', 'LGKOHNAD_02915', 'LGKOHNAD_02916']\n",
      "2026-01-21 11:11:16,866 [INFO] Patching GCA_029856435.1_ASM2985643v1.gbk with 20 annotated proteins\n",
      "2026-01-21 11:11:16,866 [INFO]   JAHQXB010000087.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,867 [INFO]   JAHQXB010000101.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,869 [INFO]   JAHQXB010000123.1: 0/57 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,870 [INFO]   JAHQXB010000175.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,872 [INFO]   JAHQXB010000155.1: 0/58 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,873 [INFO]   JAHQXB010000099.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,874 [INFO]   JAHQXB010000138.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,875 [INFO]   JAHQXB010000013.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,875 [INFO]   JAHQXB010000146.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,876 [INFO]   JAHQXB010000029.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,877 [INFO]   JAHQXB010000020.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,878 [INFO]   JAHQXB010000078.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,879 [INFO]   JAHQXB010000085.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,879 [INFO]   JAHQXB010000049.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,880 [INFO]   JAHQXB010000062.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,881 [INFO]   JAHQXB010000072.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,882 [INFO]   JAHQXB010000095.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,883 [INFO]   JAHQXB010000060.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,884 [INFO]   JAHQXB010000130.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,885 [INFO]   JAHQXB010000174.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,887 [INFO]   JAHQXB010000176.1: 0/48 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,888 [INFO]   JAHQXB010000082.1: 0/53 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,889 [INFO]   JAHQXB010000002.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,890 [INFO]   JAHQXB010000025.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,891 [INFO]   JAHQXB010000105.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,892 [INFO]   JAHQXB010000067.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,893 [INFO]   JAHQXB010000149.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,894 [INFO]   JAHQXB010000037.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,896 [INFO]   JAHQXB010000106.1: 0/55 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,897 [INFO]   JAHQXB010000031.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,898 [INFO]   JAHQXB010000054.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,898 [INFO]   JAHQXB010000009.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,899 [INFO]   JAHQXB010000169.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,900 [INFO]   JAHQXB010000076.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,901 [INFO]   JAHQXB010000027.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,902 [INFO]   JAHQXB010000061.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,903 [INFO]   JAHQXB010000047.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,904 [INFO]   JAHQXB010000048.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,905 [INFO]   JAHQXB010000035.1: 0/47 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,906 [INFO]   JAHQXB010000142.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,907 [INFO]   JAHQXB010000092.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,908 [INFO]   JAHQXB010000135.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,910 [INFO]   JAHQXB010000114.1: 0/55 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,912 [INFO]   JAHQXB010000042.1: 0/50 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,912 [INFO]   JAHQXB010000131.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,913 [INFO]   JAHQXB010000008.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,914 [INFO]   JAHQXB010000046.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,915 [INFO]   JAHQXB010000159.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,916 [INFO]   JAHQXB010000180.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,917 [INFO]   JAHQXB010000044.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,917 [INFO]   JAHQXB010000103.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,918 [INFO]   JAHQXB010000132.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,919 [INFO]   JAHQXB010000050.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,920 [INFO]   JAHQXB010000166.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,922 [INFO]   JAHQXB010000066.1: 0/43 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,922 [INFO]   JAHQXB010000161.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,923 [INFO]   JAHQXB010000083.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,924 [INFO]   JAHQXB010000038.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,926 [INFO]   JAHQXB010000170.1: 0/43 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,926 [INFO]   JAHQXB010000144.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,927 [INFO]   JAHQXB010000053.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,928 [INFO]   JAHQXB010000004.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,928 [INFO]   JAHQXB010000124.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,929 [INFO]   JAHQXB010000181.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,930 [INFO]   JAHQXB010000173.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,931 [INFO]   JAHQXB010000017.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,932 [INFO]   JAHQXB010000074.1: 0/37 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,933 [INFO]   JAHQXB010000091.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,934 [INFO]   JAHQXB010000156.1: 0/38 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,935 [INFO]   JAHQXB010000179.1: 0/34 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,936 [INFO]   JAHQXB010000006.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,937 [INFO]   JAHQXB010000039.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,938 [INFO]   JAHQXB010000100.1: 0/51 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,939 [INFO]   JAHQXB010000115.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,940 [INFO]   JAHQXB010000147.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,941 [INFO]   JAHQXB010000016.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,941 [INFO]   JAHQXB010000015.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,942 [INFO]   JAHQXB010000077.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,943 [INFO]   JAHQXB010000117.1: 0/41 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,944 [INFO]   JAHQXB010000167.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,947 [INFO]   JAHQXB010000063.1: 0/91 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,948 [INFO]   JAHQXB010000134.1: 0/28 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,949 [INFO]   JAHQXB010000043.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,951 [INFO]   JAHQXB010000014.1: 0/35 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,952 [INFO]   JAHQXB010000111.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,952 [INFO]   JAHQXB010000119.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,953 [INFO]   JAHQXB010000068.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,954 [INFO]   JAHQXB010000024.1: 0/31 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,955 [INFO]   JAHQXB010000158.1: 0/34 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,957 [INFO]   JAHQXB010000073.1: 0/30 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,957 [INFO]   JAHQXB010000127.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,958 [INFO]   JAHQXB010000056.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,959 [INFO]   JAHQXB010000141.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,960 [INFO]   JAHQXB010000165.1: 0/42 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,961 [INFO]   JAHQXB010000153.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,962 [INFO]   JAHQXB010000164.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,963 [INFO]   JAHQXB010000163.1: 0/30 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,964 [INFO]   JAHQXB010000137.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,965 [INFO]   JAHQXB010000171.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,965 [INFO]   JAHQXB010000168.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,966 [INFO]   JAHQXB010000093.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,967 [INFO]   JAHQXB010000108.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,968 [INFO]   JAHQXB010000129.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,969 [INFO]   JAHQXB010000088.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,969 [INFO]   JAHQXB010000113.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,970 [INFO]   JAHQXB010000012.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,971 [INFO]   JAHQXB010000028.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,972 [INFO]   JAHQXB010000125.1: 0/33 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,973 [INFO]   JAHQXB010000005.1: 0/34 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,974 [INFO]   JAHQXB010000018.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,975 [INFO]   JAHQXB010000080.1: 0/28 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,976 [INFO]   JAHQXB010000007.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,976 [INFO]   JAHQXB010000084.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,977 [INFO]   JAHQXB010000118.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,978 [INFO]   JAHQXB010000026.1: 0/29 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,979 [INFO]   JAHQXB010000128.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,980 [INFO]   JAHQXB010000122.1: 0/28 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,981 [INFO]   JAHQXB010000154.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,982 [INFO]   JAHQXB010000070.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,982 [INFO]   JAHQXB010000139.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,984 [INFO]   JAHQXB010000112.1: 0/27 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,984 [INFO]   JAHQXB010000178.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,985 [INFO]   JAHQXB010000177.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,986 [INFO]   JAHQXB010000110.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,987 [INFO]   JAHQXB010000071.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,988 [INFO]   JAHQXB010000065.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,989 [INFO]   JAHQXB010000011.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,989 [INFO]   JAHQXB010000090.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,991 [INFO]   JAHQXB010000021.1: 0/30 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,991 [INFO]   JAHQXB010000162.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,992 [INFO]   JAHQXB010000040.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,993 [INFO]   JAHQXB010000157.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,994 [INFO]   JAHQXB010000160.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,994 [INFO]   JAHQXB010000036.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,995 [INFO]   JAHQXB010000094.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,996 [INFO]   JAHQXB010000041.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,997 [INFO]   JAHQXB010000055.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:16,999 [INFO]   JAHQXB010000143.1: 0/69 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,000 [INFO]   JAHQXB010000133.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,000 [INFO]   JAHQXB010000104.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,001 [INFO]   JAHQXB010000126.1: 0/31 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,002 [INFO]   JAHQXB010000034.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,002 [INFO]   JAHQXB010000064.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,003 [INFO]   JAHQXB010000172.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,005 [INFO]   JAHQXB010000075.1: 0/57 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,007 [INFO]   JAHQXB010000089.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,007 [INFO]   JAHQXB010000045.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,008 [INFO]   JAHQXB010000033.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,009 [INFO]   JAHQXB010000145.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,010 [INFO]   JAHQXB010000151.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,011 [INFO]   JAHQXB010000152.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,011 [INFO]   JAHQXB010000057.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,012 [INFO]   JAHQXB010000019.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,013 [INFO]   JAHQXB010000022.1: 3/20 genes annotated - KEPT\n",
      "2026-01-21 11:11:17,014 [INFO]   JAHQXB010000120.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,014 [INFO]   JAHQXB010000098.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,015 [INFO]   JAHQXB010000058.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,016 [INFO]   JAHQXB010000097.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,017 [INFO]   JAHQXB010000051.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,018 [INFO]   JAHQXB010000150.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,018 [INFO]   JAHQXB010000081.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,019 [INFO]   JAHQXB010000001.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,020 [INFO]   JAHQXB010000086.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,021 [INFO]   JAHQXB010000030.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,022 [INFO]   JAHQXB010000032.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,022 [INFO]   JAHQXB010000102.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,023 [INFO]   JAHQXB010000140.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,023 [INFO]   JAHQXB010000121.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,024 [INFO]   JAHQXB010000096.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,025 [INFO]   JAHQXB010000059.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,026 [INFO]   JAHQXB010000003.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,026 [INFO]   JAHQXB010000148.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,027 [INFO]   JAHQXB010000052.1: 0/0 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,028 [INFO]   JAHQXB010000023.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,028 [INFO]   JAHQXB010000069.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,029 [INFO]   JAHQXB010000109.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,030 [INFO]   JAHQXB010000010.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,031 [INFO]   JAHQXB010000116.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,032 [INFO]   JAHQXB010000107.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,034 [INFO]   JAHQXB010000079.1: 0/50 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,034 [INFO]   JAHQXB010000136.1: 0/6 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/Jordiarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:17,035 [INFO] Successfully patched GCA_029856435.1_ASM2985643v1.gbk: kept 1 contigs, annotated 3/3257 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 8/16 [00:01<00:01,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:17,036 [INFO] Patching family: Kariarchaeaceae (561 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:17,039 [INFO] Lookup keys sample: ['IJJBFKFB_02222', 'IJJBFKFB_02223', 'IJJBFKFB_02224', 'IJJBFKFB_02225', 'IJJBFKFB_02226']\n",
      "2026-01-21 11:11:17,040 [INFO] Patching GCA_030149205.1_ASM3014920v1.gbk with 561 annotated proteins\n",
      "2026-01-21 11:11:17,047 [INFO]   JASBSB010000004.1: 0/257 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,062 [INFO]   JASBSB010000006.1: 0/608 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,063 [INFO]   JASBSB010000010.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,086 [INFO]   JASBSB010000001.1: 0/928 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,087 [INFO]   JASBSB010000002.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,088 [INFO]   JASBSB010000012.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,098 [INFO]   JASBSB010000003.1: 0/397 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,112 [INFO]   JASBSB010000007.1: 9/561 genes annotated - KEPT\n",
      "2026-01-21 11:11:17,116 [INFO]   JASBSB010000008.1: 0/124 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,117 [INFO]   JASBSB010000009.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,118 [INFO]   JASBSB010000011.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,120 [INFO]   JASBSB010000005.1: 0/71 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/Kariarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:17,131 [INFO] Successfully patched GCA_030149205.1_ASM3014920v1.gbk: kept 1 contigs, annotated 9/3000 genes\n",
      "2026-01-21 11:11:17,131 [INFO] Patching family: MK-D1 (3694 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:17,141 [INFO] Lookup keys sample: ['AAEOKEPF_00001', 'AAEOKEPF_00002', 'AAEOKEPF_00003', 'AAEOKEPF_00004', 'AAEOKEPF_00005']\n",
      "2026-01-21 11:11:17,141 [INFO] Patching GCA_021498095.1_ASM2149809v1.gbk with 3694 annotated proteins\n",
      "2026-01-21 11:11:17,240 [INFO]   JAIZWK010000001.1: 30/3694 genes annotated - KEPT\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/MK-D1_patched.gbk\n",
      "2026-01-21 11:11:17,302 [INFO] Successfully patched GCA_021498095.1_ASM2149809v1.gbk: kept 1 contigs, annotated 30/3694 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 10/16 [00:01<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:17,303 [INFO] Patching family: Njordarchaeaceae (13 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:17,305 [INFO] Lookup keys sample: ['JMCHHPCH_01220', 'JMCHHPCH_01222', 'JMCHHPCH_01223', 'JMCHHPCH_01224', 'JMCHHPCH_01225']\n",
      "2026-01-21 11:11:17,305 [INFO] Patching GCA_026993975.1_ASM2699397v1.gbk with 13 annotated proteins\n",
      "2026-01-21 11:11:17,306 [INFO]   JALWRR010000001.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,308 [INFO]   JALWRR010000002.1: 0/33 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,308 [INFO]   JALWRR010000003.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,309 [INFO]   JALWRR010000004.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,310 [INFO]   JALWRR010000005.1: 0/30 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,310 [INFO]   JALWRR010000006.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,311 [INFO]   JALWRR010000007.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,312 [INFO]   JALWRR010000008.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,312 [INFO]   JALWRR010000009.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,313 [INFO]   JALWRR010000010.1: 0/35 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,314 [INFO]   JALWRR010000011.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,315 [INFO]   JALWRR010000012.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,316 [INFO]   JALWRR010000013.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,316 [INFO]   JALWRR010000014.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,317 [INFO]   JALWRR010000015.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,317 [INFO]   JALWRR010000016.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,318 [INFO]   JALWRR010000017.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,319 [INFO]   JALWRR010000018.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,320 [INFO]   JALWRR010000019.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,320 [INFO]   JALWRR010000020.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,321 [INFO]   JALWRR010000021.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,322 [INFO]   JALWRR010000022.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,323 [INFO]   JALWRR010000023.1: 0/34 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,324 [INFO]   JALWRR010000024.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,325 [INFO]   JALWRR010000025.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,325 [INFO]   JALWRR010000026.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,326 [INFO]   JALWRR010000027.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,327 [INFO]   JALWRR010000028.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,328 [INFO]   JALWRR010000029.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,329 [INFO]   JALWRR010000030.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,330 [INFO]   JALWRR010000031.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,331 [INFO]   JALWRR010000032.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,331 [INFO]   JALWRR010000033.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,333 [INFO]   JALWRR010000034.1: 0/29 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,333 [INFO]   JALWRR010000035.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,334 [INFO]   JALWRR010000036.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,335 [INFO]   JALWRR010000037.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,336 [INFO]   JALWRR010000038.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,336 [INFO]   JALWRR010000039.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,337 [INFO]   JALWRR010000040.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,337 [INFO]   JALWRR010000041.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,338 [INFO]   JALWRR010000042.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,339 [INFO]   JALWRR010000043.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,340 [INFO]   JALWRR010000044.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,341 [INFO]   JALWRR010000045.1: 0/27 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,342 [INFO]   JALWRR010000046.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,343 [INFO]   JALWRR010000047.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,344 [INFO]   JALWRR010000048.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,345 [INFO]   JALWRR010000049.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,345 [INFO]   JALWRR010000050.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,346 [INFO]   JALWRR010000051.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,346 [INFO]   JALWRR010000052.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,348 [INFO]   JALWRR010000053.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,348 [INFO]   JALWRR010000054.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,349 [INFO]   JALWRR010000055.1: 0/28 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,350 [INFO]   JALWRR010000056.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,351 [INFO]   JALWRR010000057.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,352 [INFO]   JALWRR010000058.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,352 [INFO]   JALWRR010000059.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,353 [INFO]   JALWRR010000060.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,354 [INFO]   JALWRR010000061.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,354 [INFO]   JALWRR010000062.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,355 [INFO]   JALWRR010000063.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,355 [INFO]   JALWRR010000064.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,356 [INFO]   JALWRR010000065.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,356 [INFO]   JALWRR010000066.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,357 [INFO]   JALWRR010000067.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,358 [INFO]   JALWRR010000068.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,359 [INFO]   JALWRR010000069.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,359 [INFO]   JALWRR010000070.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,360 [INFO]   JALWRR010000071.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,361 [INFO]   JALWRR010000072.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,362 [INFO]   JALWRR010000073.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,363 [INFO]   JALWRR010000074.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,364 [INFO]   JALWRR010000075.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,366 [INFO]   JALWRR010000076.1: 0/95 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,367 [INFO]   JALWRR010000077.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,368 [INFO]   JALWRR010000078.1: 0/28 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,368 [INFO]   JALWRR010000079.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,370 [INFO]   JALWRR010000080.1: 0/69 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,371 [INFO]   JALWRR010000081.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,372 [INFO]   JALWRR010000082.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,372 [INFO]   JALWRR010000083.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,373 [INFO]   JALWRR010000084.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,374 [INFO]   JALWRR010000085.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,375 [INFO]   JALWRR010000086.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,376 [INFO]   JALWRR010000087.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,377 [INFO]   JALWRR010000088.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,378 [INFO]   JALWRR010000089.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,379 [INFO]   JALWRR010000090.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,380 [INFO]   JALWRR010000091.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,380 [INFO]   JALWRR010000092.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,381 [INFO]   JALWRR010000093.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,382 [INFO]   JALWRR010000094.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,382 [INFO]   JALWRR010000095.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,383 [INFO]   JALWRR010000096.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,384 [INFO]   JALWRR010000097.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,384 [INFO]   JALWRR010000098.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,385 [INFO]   JALWRR010000099.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,386 [INFO]   JALWRR010000100.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,387 [INFO]   JALWRR010000101.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,387 [INFO]   JALWRR010000102.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,388 [INFO]   JALWRR010000103.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,389 [INFO]   JALWRR010000104.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,389 [INFO]   JALWRR010000105.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,390 [INFO]   JALWRR010000106.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,391 [INFO]   JALWRR010000107.1: 2/13 genes annotated - KEPT\n",
      "2026-01-21 11:11:17,392 [INFO]   JALWRR010000108.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,392 [INFO]   JALWRR010000109.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,393 [INFO]   JALWRR010000110.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,394 [INFO]   JALWRR010000111.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,394 [INFO]   JALWRR010000112.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,395 [INFO]   JALWRR010000113.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,396 [INFO]   JALWRR010000114.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,397 [INFO]   JALWRR010000115.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,398 [INFO]   JALWRR010000116.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,399 [INFO]   JALWRR010000117.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,400 [INFO]   JALWRR010000118.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,401 [INFO]   JALWRR010000119.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,401 [INFO]   JALWRR010000120.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,402 [INFO]   JALWRR010000121.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,403 [INFO]   JALWRR010000122.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,404 [INFO]   JALWRR010000123.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,405 [INFO]   JALWRR010000124.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,405 [INFO]   JALWRR010000125.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,406 [INFO]   JALWRR010000126.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,407 [INFO]   JALWRR010000127.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,408 [INFO]   JALWRR010000128.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,408 [INFO]   JALWRR010000129.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,409 [INFO]   JALWRR010000130.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,410 [INFO]   JALWRR010000131.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,410 [INFO]   JALWRR010000132.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,411 [INFO]   JALWRR010000133.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,411 [INFO]   JALWRR010000134.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,412 [INFO]   JALWRR010000135.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,413 [INFO]   JALWRR010000136.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,414 [INFO]   JALWRR010000137.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,415 [INFO]   JALWRR010000138.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,415 [INFO]   JALWRR010000139.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,416 [INFO]   JALWRR010000140.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,417 [INFO]   JALWRR010000141.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,418 [INFO]   JALWRR010000142.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,418 [INFO]   JALWRR010000143.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,419 [INFO]   JALWRR010000144.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,420 [INFO]   JALWRR010000145.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,421 [INFO]   JALWRR010000146.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,421 [INFO]   JALWRR010000147.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,422 [INFO]   JALWRR010000148.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,423 [INFO]   JALWRR010000149.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,424 [INFO]   JALWRR010000150.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,426 [INFO]   JALWRR010000151.1: 0/56 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,427 [INFO]   JALWRR010000152.1: 0/44 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,428 [INFO]   JALWRR010000153.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,428 [INFO]   JALWRR010000154.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,429 [INFO]   JALWRR010000155.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,430 [INFO]   JALWRR010000156.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,430 [INFO]   JALWRR010000157.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,431 [INFO]   JALWRR010000158.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,431 [INFO]   JALWRR010000159.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,432 [INFO]   JALWRR010000160.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,433 [INFO]   JALWRR010000161.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,434 [INFO]   JALWRR010000162.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,434 [INFO]   JALWRR010000163.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,435 [INFO]   JALWRR010000164.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,436 [INFO]   JALWRR010000165.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,436 [INFO]   JALWRR010000166.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,437 [INFO]   JALWRR010000167.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,437 [INFO]   JALWRR010000168.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,438 [INFO]   JALWRR010000169.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,438 [INFO]   JALWRR010000170.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,439 [INFO]   JALWRR010000171.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,440 [INFO]   JALWRR010000172.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,441 [INFO]   JALWRR010000173.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,441 [INFO]   JALWRR010000174.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,442 [INFO]   JALWRR010000175.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,443 [INFO]   JALWRR010000176.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,443 [INFO]   JALWRR010000177.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,444 [INFO]   JALWRR010000178.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,445 [INFO]   JALWRR010000179.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,446 [INFO]   JALWRR010000180.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,446 [INFO]   JALWRR010000181.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,447 [INFO]   JALWRR010000182.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,447 [INFO]   JALWRR010000183.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,448 [INFO]   JALWRR010000184.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,449 [INFO]   JALWRR010000185.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,450 [INFO]   JALWRR010000186.1: 0/34 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,451 [INFO]   JALWRR010000187.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,452 [INFO]   JALWRR010000188.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,453 [INFO]   JALWRR010000189.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,454 [INFO]   JALWRR010000190.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,454 [INFO]   JALWRR010000191.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,455 [INFO]   JALWRR010000192.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,456 [INFO]   JALWRR010000193.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,457 [INFO]   JALWRR010000194.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,457 [INFO]   JALWRR010000195.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,458 [INFO]   JALWRR010000196.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,459 [INFO]   JALWRR010000197.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,459 [INFO]   JALWRR010000198.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,460 [INFO]   JALWRR010000199.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,460 [INFO]   JALWRR010000200.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,462 [INFO]   JALWRR010000201.1: 0/32 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,462 [INFO]   JALWRR010000202.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,463 [INFO]   JALWRR010000203.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,463 [INFO]   JALWRR010000204.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,464 [INFO]   JALWRR010000205.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,465 [INFO]   JALWRR010000206.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,466 [INFO]   JALWRR010000207.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,466 [INFO]   JALWRR010000208.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,467 [INFO]   JALWRR010000209.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,468 [INFO]   JALWRR010000210.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,468 [INFO]   JALWRR010000211.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,469 [INFO]   JALWRR010000212.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,470 [INFO]   JALWRR010000213.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,471 [INFO]   JALWRR010000214.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,472 [INFO]   JALWRR010000215.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,473 [INFO]   JALWRR010000216.1: 0/24 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/Njordarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:17,474 [INFO] Successfully patched GCA_026993975.1_ASM2699397v1.gbk: kept 1 contigs, annotated 2/2287 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 11/16 [00:01<00:00,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:17,475 [INFO] Patching family: Odinarchaeaceae (1464 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:17,480 [INFO] Lookup keys sample: ['NDAMOAGK_00001', 'NDAMOAGK_00002', 'NDAMOAGK_00003', 'NDAMOAGK_00004', 'NDAMOAGK_00005']\n",
      "2026-01-21 11:11:17,480 [INFO] Patching GCA_001940665.2_ASM194066v2.gbk with 1464 annotated proteins\n",
      "2026-01-21 11:11:17,517 [INFO]   CP091871.1: 17/1464 genes annotated - KEPT\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/Odinarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:17,539 [INFO] Successfully patched GCA_001940665.2_ASM194066v2.gbk: kept 1 contigs, annotated 17/1464 genes\n",
      "2026-01-21 11:11:17,539 [INFO] Patching family: SOKP01 (102 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:17,542 [INFO] Lookup keys sample: ['PDCCFHMA_03680', 'PDCCFHMA_03681', 'PDCCFHMA_03682', 'PDCCFHMA_03683', 'PDCCFHMA_03684']\n",
      "2026-01-21 11:11:17,543 [INFO] Patching GCA_005223125.1_ASM522312v1.gbk with 102 annotated proteins\n",
      "2026-01-21 11:11:17,544 [INFO]   NJBH01000042.1: 0/30 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,547 [INFO]   NJBH01000013.1: 0/92 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,549 [INFO]   NJBH01000014.1: 0/96 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,552 [INFO]   NJBH01000015.1: 0/91 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,553 [INFO]   NJBH01000043.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,555 [INFO]   NJBH01000016.1: 0/86 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,556 [INFO]   NJBH01000069.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,557 [INFO]   NJBH01000044.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,558 [INFO]   NJBH01000045.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,559 [INFO]   NJBH01000046.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,562 [INFO]   NJBH01000017.1: 0/90 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,563 [INFO]   NJBH01000070.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,564 [INFO]   NJBH01000047.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,565 [INFO]   NJBH01000048.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,566 [INFO]   NJBH01000049.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,567 [INFO]   NJBH01000050.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,567 [INFO]   NJBH01000071.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,573 [INFO]   NJBH01000001.1: 0/237 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,574 [INFO]   NJBH01000051.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,575 [INFO]   NJBH01000052.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,581 [INFO]   NJBH01000002.1: 0/235 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,583 [INFO]   NJBH01000018.1: 0/68 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,585 [INFO]   NJBH01000019.1: 0/56 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,591 [INFO]   NJBH01000003.1: 0/227 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,592 [INFO]   NJBH01000053.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,594 [INFO]   NJBH01000020.1: 0/60 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,596 [INFO]   NJBH01000021.1: 0/57 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,597 [INFO]   NJBH01000054.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,599 [INFO]   NJBH01000022.1: 0/64 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,601 [INFO]   NJBH01000023.1: 0/47 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,602 [INFO]   NJBH01000055.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,603 [INFO]   NJBH01000024.1: 0/63 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,605 [INFO]   NJBH01000056.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,605 [INFO]   NJBH01000057.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,606 [INFO]   NJBH01000058.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,611 [INFO]   NJBH01000004.1: 0/186 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,616 [INFO]   NJBH01000005.1: 0/198 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,617 [INFO]   NJBH01000025.1: 0/54 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,619 [INFO]   NJBH01000026.1: 0/49 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,621 [INFO]   NJBH01000027.1: 0/52 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,622 [INFO]   NJBH01000028.1: 0/48 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,624 [INFO]   NJBH01000029.1: 0/52 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,624 [INFO]   NJBH01000059.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,629 [INFO]   NJBH01000006.1: 0/153 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,630 [INFO]   NJBH01000030.1: 0/53 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,631 [INFO]   NJBH01000060.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,633 [INFO]   NJBH01000031.1: 0/61 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,638 [INFO]   NJBH01000007.1: 0/146 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,641 [INFO]   NJBH01000008.1: 0/143 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,643 [INFO]   NJBH01000032.1: 0/39 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,643 [INFO]   NJBH01000061.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,645 [INFO]   NJBH01000033.1: 0/49 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,646 [INFO]   NJBH01000062.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,647 [INFO]   NJBH01000063.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,649 [INFO]   NJBH01000034.1: 0/42 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,650 [INFO]   NJBH01000035.1: 0/33 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,651 [INFO]   NJBH01000036.1: 0/45 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,655 [INFO]   NJBH01000009.1: 0/122 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,655 [INFO]   NJBH01000064.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,656 [INFO]   NJBH01000065.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,659 [INFO]   NJBH01000010.1: 0/97 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,660 [INFO]   NJBH01000066.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,661 [INFO]   NJBH01000037.1: 0/32 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,664 [INFO]   NJBH01000011.1: 4/102 genes annotated - KEPT\n",
      "2026-01-21 11:11:17,666 [INFO]   NJBH01000038.1: 0/41 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,666 [INFO]   NJBH01000067.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,669 [INFO]   NJBH01000012.1: 0/94 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,670 [INFO]   NJBH01000039.1: 0/28 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,671 [INFO]   NJBH01000068.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,672 [INFO]   NJBH01000040.1: 0/40 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,673 [INFO]   NJBH01000041.1: 0/25 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/SOKP01_patched.gbk\n",
      "2026-01-21 11:11:17,676 [INFO] Successfully patched GCA_005223125.1_ASM522312v1.gbk: kept 1 contigs, annotated 4/4010 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 13/16 [00:01<00:00,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:17,677 [INFO] Patching family: Sigynarchaeaceae (24 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:17,679 [INFO] Lookup keys sample: ['EBODJBDI_00447', 'EBODJBDI_00448', 'EBODJBDI_00449', 'EBODJBDI_00450', 'EBODJBDI_00451']\n",
      "2026-01-21 11:11:17,679 [INFO] Patching GCA_030587545.2_ASM3058754v2.gbk with 24 annotated proteins\n",
      "2026-01-21 11:11:17,682 [INFO]   JAUQYX020000280.1: 0/89 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,683 [INFO]   JAUQYX020000038.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,684 [INFO]   JAUQYX020000076.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,685 [INFO]   JAUQYX020000199.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,685 [INFO]   JAUQYX020000226.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,686 [INFO]   JAUQYX020000282.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,687 [INFO]   JAUQYX020000073.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,688 [INFO]   JAUQYX020000124.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,689 [INFO]   JAUQYX020000137.1: 0/28 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,691 [INFO]   JAUQYX020000294.1: 0/43 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,691 [INFO]   JAUQYX020000005.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,692 [INFO]   JAUQYX020000025.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,692 [INFO]   JAUQYX020000040.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,693 [INFO]   JAUQYX020000061.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,694 [INFO]   JAUQYX020000157.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,694 [INFO]   JAUQYX020000129.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,695 [INFO]   JAUQYX020000034.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,698 [INFO]   JAUQYX020000052.1: 0/61 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,699 [INFO]   JAUQYX020000203.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,700 [INFO]   JAUQYX020000049.1: 0/31 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,702 [INFO]   JAUQYX020000059.1: 0/65 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,703 [INFO]   JAUQYX020000077.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,703 [INFO]   JAUQYX020000123.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,704 [INFO]   JAUQYX020000144.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,705 [INFO]   JAUQYX020000181.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,705 [INFO]   JAUQYX020000082.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,706 [INFO]   JAUQYX020000189.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,707 [INFO]   JAUQYX020000206.1: 2/24 genes annotated - KEPT\n",
      "2026-01-21 11:11:17,708 [INFO]   JAUQYX020000136.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,708 [INFO]   JAUQYX020000246.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,709 [INFO]   JAUQYX020000251.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,710 [INFO]   JAUQYX020000065.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,711 [INFO]   JAUQYX020000132.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,712 [INFO]   JAUQYX020000161.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,712 [INFO]   JAUQYX020000265.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,713 [INFO]   JAUQYX020000017.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,715 [INFO]   JAUQYX020000180.1: 0/61 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,716 [INFO]   JAUQYX020000215.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,717 [INFO]   JAUQYX020000216.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,718 [INFO]   JAUQYX020000245.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,718 [INFO]   JAUQYX020000209.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,721 [INFO]   JAUQYX020000281.1: 0/89 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,721 [INFO]   JAUQYX020000056.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,723 [INFO]   JAUQYX020000159.1: 0/42 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,724 [INFO]   JAUQYX020000224.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,725 [INFO]   JAUQYX020000018.1: 0/39 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,725 [INFO]   JAUQYX020000063.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,726 [INFO]   JAUQYX020000193.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,727 [INFO]   JAUQYX020000241.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,727 [INFO]   JAUQYX020000244.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,728 [INFO]   JAUQYX020000276.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,730 [INFO]   JAUQYX020000131.1: 0/35 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,731 [INFO]   JAUQYX020000139.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,732 [INFO]   JAUQYX020000163.1: 0/35 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,733 [INFO]   JAUQYX020000204.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,735 [INFO]   JAUQYX020000274.1: 0/51 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,736 [INFO]   JAUQYX020000287.1: 0/40 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,737 [INFO]   JAUQYX020000010.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,738 [INFO]   JAUQYX020000110.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,740 [INFO]   JAUQYX020000114.1: 0/46 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,740 [INFO]   JAUQYX020000231.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,741 [INFO]   JAUQYX020000186.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,741 [INFO]   JAUQYX020000048.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,742 [INFO]   JAUQYX020000233.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,743 [INFO]   JAUQYX020000271.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,744 [INFO]   JAUQYX020000071.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,747 [INFO]   JAUQYX020000168.1: 0/63 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,747 [INFO]   JAUQYX020000239.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,748 [INFO]   JAUQYX020000277.1: 0/29 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,749 [INFO]   JAUQYX020000279.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,751 [INFO]   JAUQYX020000214.1: 0/59 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,752 [INFO]   JAUQYX020000249.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,752 [INFO]   JAUQYX020000020.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,753 [INFO]   JAUQYX020000088.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,754 [INFO]   JAUQYX020000098.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,755 [INFO]   JAUQYX020000036.1: 0/28 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,756 [INFO]   JAUQYX020000232.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,756 [INFO]   JAUQYX020000285.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,758 [INFO]   JAUQYX020000119.1: 0/37 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,760 [INFO]   JAUQYX020000142.1: 0/70 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,760 [INFO]   JAUQYX020000023.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,761 [INFO]   JAUQYX020000089.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,762 [INFO]   JAUQYX020000100.1: 0/45 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,763 [INFO]   JAUQYX020000151.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,764 [INFO]   JAUQYX020000158.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,765 [INFO]   JAUQYX020000269.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,766 [INFO]   JAUQYX020000171.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,767 [INFO]   JAUQYX020000035.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,768 [INFO]   JAUQYX020000176.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,768 [INFO]   JAUQYX020000173.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,769 [INFO]   JAUQYX020000044.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,770 [INFO]   JAUQYX020000207.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,770 [INFO]   JAUQYX020000107.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,771 [INFO]   JAUQYX020000195.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,771 [INFO]   JAUQYX020000205.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,773 [INFO]   JAUQYX020000086.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,773 [INFO]   JAUQYX020000091.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,774 [INFO]   JAUQYX020000126.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,774 [INFO]   JAUQYX020000252.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,775 [INFO]   JAUQYX020000253.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,776 [INFO]   JAUQYX020000273.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,776 [INFO]   JAUQYX020000288.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,777 [INFO]   JAUQYX020000256.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,778 [INFO]   JAUQYX020000213.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,778 [INFO]   JAUQYX020000237.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,779 [INFO]   JAUQYX020000042.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,779 [INFO]   JAUQYX020000053.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,780 [INFO]   JAUQYX020000003.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,780 [INFO]   JAUQYX020000078.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,781 [INFO]   JAUQYX020000112.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,782 [INFO]   JAUQYX020000179.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,782 [INFO]   JAUQYX020000182.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,783 [INFO]   JAUQYX020000227.1: 0/34 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,785 [INFO]   JAUQYX020000268.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,787 [INFO]   JAUQYX020000069.1: 0/48 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,788 [INFO]   JAUQYX020000106.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,788 [INFO]   JAUQYX020000164.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,791 [INFO]   JAUQYX020000211.1: 0/81 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,793 [INFO]   JAUQYX020000259.1: 0/45 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,794 [INFO]   JAUQYX020000057.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,794 [INFO]   JAUQYX020000130.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,795 [INFO]   JAUQYX020000074.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,796 [INFO]   JAUQYX020000152.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,797 [INFO]   JAUQYX020000153.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,798 [INFO]   JAUQYX020000219.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,798 [INFO]   JAUQYX020000228.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,799 [INFO]   JAUQYX020000234.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,799 [INFO]   JAUQYX020000283.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,800 [INFO]   JAUQYX020000030.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,801 [INFO]   JAUQYX020000148.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,802 [INFO]   JAUQYX020000175.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,803 [INFO]   JAUQYX020000217.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,803 [INFO]   JAUQYX020000236.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,804 [INFO]   JAUQYX020000284.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,805 [INFO]   JAUQYX020000291.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,805 [INFO]   JAUQYX020000080.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,806 [INFO]   JAUQYX020000095.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,810 [INFO]   JAUQYX020000191.1: 0/134 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,811 [INFO]   JAUQYX020000027.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,812 [INFO]   JAUQYX020000075.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,813 [INFO]   JAUQYX020000262.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,814 [INFO]   JAUQYX020000024.1: 0/33 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,819 [INFO]   JAUQYX020000029.1: 0/41 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,822 [INFO]   JAUQYX020000062.1: 0/93 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,823 [INFO]   JAUQYX020000185.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,824 [INFO]   JAUQYX020000187.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,826 [INFO]   JAUQYX020000196.1: 0/33 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,827 [INFO]   JAUQYX020000238.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,827 [INFO]   JAUQYX020000260.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,829 [INFO]   JAUQYX020000015.1: 0/36 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,832 [INFO]   JAUQYX020000033.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,833 [INFO]   JAUQYX020000118.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,836 [INFO]   JAUQYX020000128.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,837 [INFO]   JAUQYX020000166.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,838 [INFO]   JAUQYX020000002.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,838 [INFO]   JAUQYX020000022.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,839 [INFO]   JAUQYX020000064.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,839 [INFO]   JAUQYX020000090.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,840 [INFO]   JAUQYX020000097.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,840 [INFO]   JAUQYX020000183.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,841 [INFO]   JAUQYX020000208.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,841 [INFO]   JAUQYX020000218.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,844 [INFO]   JAUQYX020000008.1: 0/62 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,847 [INFO]   JAUQYX020000188.1: 0/53 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,848 [INFO]   JAUQYX020000192.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,849 [INFO]   JAUQYX020000240.1: 0/31 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,851 [INFO]   JAUQYX020000104.1: 0/57 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,852 [INFO]   JAUQYX020000051.1: 0/34 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,853 [INFO]   JAUQYX020000001.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,854 [INFO]   JAUQYX020000045.1: 0/47 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,855 [INFO]   JAUQYX020000058.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,856 [INFO]   JAUQYX020000210.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,857 [INFO]   JAUQYX020000099.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,857 [INFO]   JAUQYX020000116.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,858 [INFO]   JAUQYX020000133.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,859 [INFO]   JAUQYX020000254.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,859 [INFO]   JAUQYX020000043.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,861 [INFO]   JAUQYX020000122.1: 0/38 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,861 [INFO]   JAUQYX020000140.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,862 [INFO]   JAUQYX020000028.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,864 [INFO]   JAUQYX020000135.1: 0/63 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,865 [INFO]   JAUQYX020000220.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,865 [INFO]   JAUQYX020000046.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,867 [INFO]   JAUQYX020000247.1: 0/62 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,868 [INFO]   JAUQYX020000290.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,869 [INFO]   JAUQYX020000292.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,869 [INFO]   JAUQYX020000039.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,871 [INFO]   JAUQYX020000109.1: 0/49 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,872 [INFO]   JAUQYX020000198.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,872 [INFO]   JAUQYX020000212.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,872 [INFO]   JAUQYX020000235.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,873 [INFO]   JAUQYX020000221.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,873 [INFO]   JAUQYX020000286.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,874 [INFO]   JAUQYX020000009.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,874 [INFO]   JAUQYX020000105.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,875 [INFO]   JAUQYX020000165.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,877 [INFO]   JAUQYX020000248.1: 0/71 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,879 [INFO]   JAUQYX020000177.1: 0/51 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,880 [INFO]   JAUQYX020000258.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,880 [INFO]   JAUQYX020000141.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,881 [INFO]   JAUQYX020000201.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,882 [INFO]   JAUQYX020000007.1: 0/0 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,884 [INFO]   JAUQYX020000138.1: 0/40 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,885 [INFO]   JAUQYX020000149.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,885 [INFO]   JAUQYX020000014.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,885 [INFO]   JAUQYX020000172.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,887 [INFO]   JAUQYX020000178.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,887 [INFO]   JAUQYX020000190.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,889 [INFO]   JAUQYX020000250.1: 0/40 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,889 [INFO]   JAUQYX020000263.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,890 [INFO]   JAUQYX020000103.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,890 [INFO]   JAUQYX020000225.1: 0/0 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,891 [INFO]   JAUQYX020000068.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,892 [INFO]   JAUQYX020000026.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,893 [INFO]   JAUQYX020000041.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,894 [INFO]   JAUQYX020000154.1: 0/33 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,896 [INFO]   JAUQYX020000243.1: 0/73 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,898 [INFO]   JAUQYX020000070.1: 0/29 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,898 [INFO]   JAUQYX020000267.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,899 [INFO]   JAUQYX020000055.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,900 [INFO]   JAUQYX020000092.1: 0/57 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,901 [INFO]   JAUQYX020000174.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,902 [INFO]   JAUQYX020000278.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,902 [INFO]   JAUQYX020000155.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,903 [INFO]   JAUQYX020000156.1: 0/29 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,904 [INFO]   JAUQYX020000170.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,904 [INFO]   JAUQYX020000111.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,906 [INFO]   JAUQYX020000257.1: 0/45 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,907 [INFO]   JAUQYX020000004.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,907 [INFO]   JAUQYX020000037.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,908 [INFO]   JAUQYX020000081.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,909 [INFO]   JAUQYX020000084.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,910 [INFO]   JAUQYX020000167.1: 0/35 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,913 [INFO]   JAUQYX020000264.1: 0/58 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,913 [INFO]   JAUQYX020000266.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,914 [INFO]   JAUQYX020000085.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,914 [INFO]   JAUQYX020000169.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,915 [INFO]   JAUQYX020000184.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,915 [INFO]   JAUQYX020000229.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,916 [INFO]   JAUQYX020000261.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,916 [INFO]   JAUQYX020000011.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,917 [INFO]   JAUQYX020000013.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,918 [INFO]   JAUQYX020000102.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,918 [INFO]   JAUQYX020000145.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,919 [INFO]   JAUQYX020000223.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,920 [INFO]   JAUQYX020000021.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,920 [INFO]   JAUQYX020000272.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,924 [INFO]   JAUQYX020000060.1: 0/125 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,925 [INFO]   JAUQYX020000047.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,926 [INFO]   JAUQYX020000072.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,926 [INFO]   JAUQYX020000108.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,927 [INFO]   JAUQYX020000120.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,927 [INFO]   JAUQYX020000147.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,929 [INFO]   JAUQYX020000083.1: 0/35 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,932 [INFO]   JAUQYX020000113.1: 0/128 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,933 [INFO]   JAUQYX020000202.1: 0/37 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,935 [INFO]   JAUQYX020000016.1: 0/50 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,937 [INFO]   JAUQYX020000125.1: 0/85 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,938 [INFO]   JAUQYX020000094.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,940 [INFO]   JAUQYX020000143.1: 0/49 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,941 [INFO]   JAUQYX020000293.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,941 [INFO]   JAUQYX020000295.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,942 [INFO]   JAUQYX020000079.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,942 [INFO]   JAUQYX020000093.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,943 [INFO]   JAUQYX020000150.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,943 [INFO]   JAUQYX020000054.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,944 [INFO]   JAUQYX020000066.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,944 [INFO]   JAUQYX020000160.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,945 [INFO]   JAUQYX020000101.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,947 [INFO]   JAUQYX020000096.1: 0/57 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,948 [INFO]   JAUQYX020000200.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,949 [INFO]   JAUQYX020000222.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,950 [INFO]   JAUQYX020000230.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,950 [INFO]   JAUQYX020000270.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,951 [INFO]   JAUQYX020000289.1: 0/30 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,952 [INFO]   JAUQYX020000012.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,952 [INFO]   JAUQYX020000032.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,953 [INFO]   JAUQYX020000255.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,954 [INFO]   JAUQYX020000031.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,955 [INFO]   JAUQYX020000050.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,956 [INFO]   JAUQYX020000087.1: 0/47 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,957 [INFO]   JAUQYX020000115.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,958 [INFO]   JAUQYX020000134.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,958 [INFO]   JAUQYX020000146.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,959 [INFO]   JAUQYX020000197.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,959 [INFO]   JAUQYX020000006.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,960 [INFO]   JAUQYX020000121.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,960 [INFO]   JAUQYX020000194.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,961 [INFO]   JAUQYX020000019.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,962 [INFO]   JAUQYX020000242.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,963 [INFO]   JAUQYX020000275.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,964 [INFO]   JAUQYX020000067.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,965 [INFO]   JAUQYX020000117.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,965 [INFO]   JAUQYX020000127.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,966 [INFO]   JAUQYX020000162.1: 0/1 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/Sigynarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:17,967 [INFO] Successfully patched GCA_030587545.2_ASM3058754v2.gbk: kept 1 contigs, annotated 2/5086 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 14/16 [00:01<00:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:17,968 [INFO] Patching family: Thorarchaeaceae (328 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:17,971 [INFO] Lookup keys sample: ['CEGGCEJE_01685', 'CEGGCEJE_01686', 'CEGGCEJE_01687', 'CEGGCEJE_01688', 'CEGGCEJE_01689']\n",
      "2026-01-21 11:11:17,971 [INFO] Patching GCA_029855935.1_ASM2985593v1.gbk with 328 annotated proteins\n",
      "2026-01-21 11:11:17,973 [INFO]   JAGSHN010000013.1: 0/42 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,975 [INFO]   JAGSHN010000003.1: 0/55 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,976 [INFO]   JAGSHN010000008.1: 0/47 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,981 [INFO]   JAGSHN010000027.1: 0/127 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,982 [INFO]   JAGSHN010000026.1: 0/46 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,986 [INFO]   JAGSHN010000020.1: 0/124 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,988 [INFO]   JAGSHN010000014.1: 0/26 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,991 [INFO]   JAGSHN010000019.1: 0/113 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,992 [INFO]   JAGSHN010000010.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,994 [INFO]   JAGSHN010000024.1: 0/60 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,995 [INFO]   JAGSHN010000021.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:17,997 [INFO]   JAGSHN010000032.1: 0/101 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,000 [INFO]   JAGSHN010000022.1: 0/70 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,006 [INFO]   JAGSHN010000005.1: 0/220 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,011 [INFO]   JAGSHN010000025.1: 0/192 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,014 [INFO]   JAGSHN010000018.1: 0/115 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,019 [INFO]   JAGSHN010000004.1: 0/183 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,020 [INFO]   JAGSHN010000007.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,022 [INFO]   JAGSHN010000028.1: 0/53 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,024 [INFO]   JAGSHN010000011.1: 0/50 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,033 [INFO]   JAGSHN010000012.1: 5/328 genes annotated - KEPT\n",
      "2026-01-21 11:11:18,034 [INFO]   JAGSHN010000002.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,034 [INFO]   JAGSHN010000001.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,037 [INFO]   JAGSHN010000030.1: 0/90 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,038 [INFO]   JAGSHN010000006.1: 0/37 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,039 [INFO]   JAGSHN010000015.1: 0/19 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,042 [INFO]   JAGSHN010000031.1: 0/154 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,048 [INFO]   JAGSHN010000016.1: 0/204 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,051 [INFO]   JAGSHN010000023.1: 0/115 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,053 [INFO]   JAGSHN010000009.1: 0/58 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,055 [INFO]   JAGSHN010000017.1: 0/55 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,056 [INFO]   JAGSHN010000029.1: 0/3 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/Thorarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:18,061 [INFO] Successfully patched GCA_029855935.1_ASM2985593v1.gbk: kept 1 contigs, annotated 5/2731 genes\n",
      "2026-01-21 11:11:18,062 [INFO] Patching family: Wukongarchaeaceae (26 annotations)\n",
      "Index(['genome_id', 'contig', 'gene_index', 'protein_id', 'start', 'end',\n",
      "       'strand', 'architecture', 'num_anchors', 'window_start', 'window_end',\n",
      "       'neighborhood_architecture_compressed', 'position_in_neighborhood',\n",
      "       'genome_id_x', 'family'],\n",
      "      dtype='object')\n",
      "2026-01-21 11:11:18,064 [INFO] Lookup keys sample: ['IAHJMLLN_00791', 'IAHJMLLN_00792', 'IAHJMLLN_00793', 'IAHJMLLN_00794', 'IAHJMLLN_00795']\n",
      "2026-01-21 11:11:18,065 [INFO] Patching GCA_016840425.1_ASM1684042v1.gbk with 26 annotated proteins\n",
      "2026-01-21 11:11:18,065 [INFO]   JAEOSI010000239.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,066 [INFO]   JAEOSI010000053.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,067 [INFO]   JAEOSI010000240.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,067 [INFO]   JAEOSI010000054.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,068 [INFO]   JAEOSI010000241.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,069 [INFO]   JAEOSI010000055.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,069 [INFO]   JAEOSI010000056.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,070 [INFO]   JAEOSI010000242.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,071 [INFO]   JAEOSI010000243.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,071 [INFO]   JAEOSI010000244.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,072 [INFO]   JAEOSI010000245.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,072 [INFO]   JAEOSI010000057.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,073 [INFO]   JAEOSI010000058.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,074 [INFO]   JAEOSI010000246.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,075 [INFO]   JAEOSI010000247.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,075 [INFO]   JAEOSI010000248.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,076 [INFO]   JAEOSI010000059.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,076 [INFO]   JAEOSI010000249.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,077 [INFO]   JAEOSI010000250.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,078 [INFO]   JAEOSI010000060.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,078 [INFO]   JAEOSI010000061.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,079 [INFO]   JAEOSI010000251.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,079 [INFO]   JAEOSI010000062.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,080 [INFO]   JAEOSI010000252.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,081 [INFO]   JAEOSI010000253.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,081 [INFO]   JAEOSI010000254.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,082 [INFO]   JAEOSI010000063.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,082 [INFO]   JAEOSI010000255.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,083 [INFO]   JAEOSI010000064.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,084 [INFO]   JAEOSI010000256.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,084 [INFO]   JAEOSI010000065.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,085 [INFO]   JAEOSI010000066.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,086 [INFO]   JAEOSI010000257.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,087 [INFO]   JAEOSI010000067.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,088 [INFO]   JAEOSI010000258.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,088 [INFO]   JAEOSI010000259.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,088 [INFO]   JAEOSI010000260.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,089 [INFO]   JAEOSI010000261.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,089 [INFO]   JAEOSI010000262.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,090 [INFO]   JAEOSI010000068.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,091 [INFO]   JAEOSI010000069.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,091 [INFO]   JAEOSI010000263.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,092 [INFO]   JAEOSI010000070.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,092 [INFO]   JAEOSI010000264.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,094 [INFO]   JAEOSI010000071.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,095 [INFO]   JAEOSI010000072.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,095 [INFO]   JAEOSI010000073.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,096 [INFO]   JAEOSI010000074.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,097 [INFO]   JAEOSI010000075.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,098 [INFO]   JAEOSI010000265.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,098 [INFO]   JAEOSI010000266.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,099 [INFO]   JAEOSI010000267.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,100 [INFO]   JAEOSI010000076.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,101 [INFO]   JAEOSI010000001.1: 0/27 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,101 [INFO]   JAEOSI010000268.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,102 [INFO]   JAEOSI010000077.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,103 [INFO]   JAEOSI010000078.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,103 [INFO]   JAEOSI010000079.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,104 [INFO]   JAEOSI010000080.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,104 [INFO]   JAEOSI010000269.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,106 [INFO]   JAEOSI010000002.1: 0/33 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,106 [INFO]   JAEOSI010000081.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,107 [INFO]   JAEOSI010000082.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,107 [INFO]   JAEOSI010000270.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,108 [INFO]   JAEOSI010000271.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,109 [INFO]   JAEOSI010000272.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,109 [INFO]   JAEOSI010000273.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,110 [INFO]   JAEOSI010000083.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,111 [INFO]   JAEOSI010000003.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,111 [INFO]   JAEOSI010000084.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,112 [INFO]   JAEOSI010000085.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,113 [INFO]   JAEOSI010000086.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,114 [INFO]   JAEOSI010000274.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,114 [INFO]   JAEOSI010000087.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,115 [INFO]   JAEOSI010000088.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,116 [INFO]   JAEOSI010000275.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,117 [INFO]   JAEOSI010000089.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,118 [INFO]   JAEOSI010000004.1: 0/28 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,118 [INFO]   JAEOSI010000276.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,119 [INFO]   JAEOSI010000277.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,120 [INFO]   JAEOSI010000090.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,120 [INFO]   JAEOSI010000091.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,122 [INFO]   JAEOSI010000092.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,122 [INFO]   JAEOSI010000093.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,123 [INFO]   JAEOSI010000094.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,124 [INFO]   JAEOSI010000095.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,124 [INFO]   JAEOSI010000096.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,125 [INFO]   JAEOSI010000097.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,126 [INFO]   JAEOSI010000098.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,126 [INFO]   JAEOSI010000099.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,127 [INFO]   JAEOSI010000100.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,128 [INFO]   JAEOSI010000101.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,128 [INFO]   JAEOSI010000102.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,129 [INFO]   JAEOSI010000103.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,129 [INFO]   JAEOSI010000104.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,130 [INFO]   JAEOSI010000105.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,131 [INFO]   JAEOSI010000005.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,132 [INFO]   JAEOSI010000106.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,133 [INFO]   JAEOSI010000107.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,133 [INFO]   JAEOSI010000108.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,134 [INFO]   JAEOSI010000109.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,135 [INFO]   JAEOSI010000110.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,135 [INFO]   JAEOSI010000111.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,136 [INFO]   JAEOSI010000112.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,137 [INFO]   JAEOSI010000113.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,138 [INFO]   JAEOSI010000114.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,138 [INFO]   JAEOSI010000115.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,140 [INFO]   JAEOSI010000006.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,141 [INFO]   JAEOSI010000007.1: 5/26 genes annotated - KEPT\n",
      "2026-01-21 11:11:18,142 [INFO]   JAEOSI010000008.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,142 [INFO]   JAEOSI010000116.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,143 [INFO]   JAEOSI010000117.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,144 [INFO]   JAEOSI010000118.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,144 [INFO]   JAEOSI010000119.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,145 [INFO]   JAEOSI010000120.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,146 [INFO]   JAEOSI010000121.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,146 [INFO]   JAEOSI010000009.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,148 [INFO]   JAEOSI010000010.1: 0/25 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,148 [INFO]   JAEOSI010000122.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,149 [INFO]   JAEOSI010000123.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,149 [INFO]   JAEOSI010000124.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,150 [INFO]   JAEOSI010000125.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,151 [INFO]   JAEOSI010000011.1: 0/22 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,152 [INFO]   JAEOSI010000126.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,153 [INFO]   JAEOSI010000012.1: 0/24 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,153 [INFO]   JAEOSI010000127.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,154 [INFO]   JAEOSI010000128.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,155 [INFO]   JAEOSI010000129.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,155 [INFO]   JAEOSI010000130.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,156 [INFO]   JAEOSI010000131.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,157 [INFO]   JAEOSI010000132.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,157 [INFO]   JAEOSI010000133.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,159 [INFO]   JAEOSI010000013.1: 0/23 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,159 [INFO]   JAEOSI010000134.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,160 [INFO]   JAEOSI010000135.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,161 [INFO]   JAEOSI010000014.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,161 [INFO]   JAEOSI010000015.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,162 [INFO]   JAEOSI010000136.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,163 [INFO]   JAEOSI010000137.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,163 [INFO]   JAEOSI010000138.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,164 [INFO]   JAEOSI010000139.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,165 [INFO]   JAEOSI010000016.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,165 [INFO]   JAEOSI010000140.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,166 [INFO]   JAEOSI010000141.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,167 [INFO]   JAEOSI010000017.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,167 [INFO]   JAEOSI010000142.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,168 [INFO]   JAEOSI010000143.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,169 [INFO]   JAEOSI010000144.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,169 [INFO]   JAEOSI010000145.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,170 [INFO]   JAEOSI010000146.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,171 [INFO]   JAEOSI010000147.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,172 [INFO]   JAEOSI010000018.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,172 [INFO]   JAEOSI010000148.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,173 [INFO]   JAEOSI010000149.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,174 [INFO]   JAEOSI010000150.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,174 [INFO]   JAEOSI010000151.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,175 [INFO]   JAEOSI010000152.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,176 [INFO]   JAEOSI010000153.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,177 [INFO]   JAEOSI010000154.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,177 [INFO]   JAEOSI010000155.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,178 [INFO]   JAEOSI010000156.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,178 [INFO]   JAEOSI010000157.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,179 [INFO]   JAEOSI010000158.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,180 [INFO]   JAEOSI010000019.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,181 [INFO]   JAEOSI010000020.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,181 [INFO]   JAEOSI010000159.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,182 [INFO]   JAEOSI010000160.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,182 [INFO]   JAEOSI010000161.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,183 [INFO]   JAEOSI010000162.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,184 [INFO]   JAEOSI010000163.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,185 [INFO]   JAEOSI010000164.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,185 [INFO]   JAEOSI010000165.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,186 [INFO]   JAEOSI010000166.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,187 [INFO]   JAEOSI010000021.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,187 [INFO]   JAEOSI010000167.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,188 [INFO]   JAEOSI010000168.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,189 [INFO]   JAEOSI010000169.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,190 [INFO]   JAEOSI010000022.1: 0/16 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,190 [INFO]   JAEOSI010000170.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,191 [INFO]   JAEOSI010000171.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,192 [INFO]   JAEOSI010000172.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,192 [INFO]   JAEOSI010000023.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,193 [INFO]   JAEOSI010000173.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,194 [INFO]   JAEOSI010000174.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,194 [INFO]   JAEOSI010000175.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,195 [INFO]   JAEOSI010000176.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,195 [INFO]   JAEOSI010000177.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,196 [INFO]   JAEOSI010000178.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,197 [INFO]   JAEOSI010000024.1: 0/21 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,198 [INFO]   JAEOSI010000179.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,199 [INFO]   JAEOSI010000025.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,199 [INFO]   JAEOSI010000026.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,200 [INFO]   JAEOSI010000027.1: 0/18 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,201 [INFO]   JAEOSI010000180.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,202 [INFO]   JAEOSI010000181.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,202 [INFO]   JAEOSI010000182.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,203 [INFO]   JAEOSI010000183.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,203 [INFO]   JAEOSI010000184.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,204 [INFO]   JAEOSI010000028.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,205 [INFO]   JAEOSI010000185.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,206 [INFO]   JAEOSI010000029.1: 0/15 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,206 [INFO]   JAEOSI010000186.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,207 [INFO]   JAEOSI010000187.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,207 [INFO]   JAEOSI010000188.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,208 [INFO]   JAEOSI010000030.1: 0/17 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,209 [INFO]   JAEOSI010000189.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,210 [INFO]   JAEOSI010000031.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,211 [INFO]   JAEOSI010000032.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,211 [INFO]   JAEOSI010000190.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,212 [INFO]   JAEOSI010000191.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,212 [INFO]   JAEOSI010000192.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,213 [INFO]   JAEOSI010000193.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,213 [INFO]   JAEOSI010000194.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,214 [INFO]   JAEOSI010000195.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,215 [INFO]   JAEOSI010000033.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,215 [INFO]   JAEOSI010000196.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,216 [INFO]   JAEOSI010000034.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,217 [INFO]   JAEOSI010000197.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,217 [INFO]   JAEOSI010000198.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,218 [INFO]   JAEOSI010000199.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,218 [INFO]   JAEOSI010000200.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,219 [INFO]   JAEOSI010000201.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,219 [INFO]   JAEOSI010000202.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,220 [INFO]   JAEOSI010000203.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,221 [INFO]   JAEOSI010000204.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,221 [INFO]   JAEOSI010000205.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,222 [INFO]   JAEOSI010000206.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,223 [INFO]   JAEOSI010000035.1: 0/20 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,223 [INFO]   JAEOSI010000207.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,224 [INFO]   JAEOSI010000208.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,225 [INFO]   JAEOSI010000209.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,225 [INFO]   JAEOSI010000036.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,226 [INFO]   JAEOSI010000210.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,227 [INFO]   JAEOSI010000211.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,227 [INFO]   JAEOSI010000037.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,228 [INFO]   JAEOSI010000212.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,229 [INFO]   JAEOSI010000038.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,229 [INFO]   JAEOSI010000213.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,230 [INFO]   JAEOSI010000214.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,231 [INFO]   JAEOSI010000215.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,231 [INFO]   JAEOSI010000216.1: 0/1 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,232 [INFO]   JAEOSI010000039.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,233 [INFO]   JAEOSI010000217.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,233 [INFO]   JAEOSI010000040.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,234 [INFO]   JAEOSI010000218.1: 0/8 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,235 [INFO]   JAEOSI010000219.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,235 [INFO]   JAEOSI010000041.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,236 [INFO]   JAEOSI010000220.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,237 [INFO]   JAEOSI010000042.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,237 [INFO]   JAEOSI010000221.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,238 [INFO]   JAEOSI010000043.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,239 [INFO]   JAEOSI010000222.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,240 [INFO]   JAEOSI010000044.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,240 [INFO]   JAEOSI010000223.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,241 [INFO]   JAEOSI010000224.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,242 [INFO]   JAEOSI010000045.1: 0/9 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,243 [INFO]   JAEOSI010000225.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,244 [INFO]   JAEOSI010000226.1: 0/5 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,245 [INFO]   JAEOSI010000046.1: 0/11 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,245 [INFO]   JAEOSI010000227.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,246 [INFO]   JAEOSI010000047.1: 0/10 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,247 [INFO]   JAEOSI010000228.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,247 [INFO]   JAEOSI010000229.1: 0/6 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,248 [INFO]   JAEOSI010000230.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,248 [INFO]   JAEOSI010000231.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,249 [INFO]   JAEOSI010000048.1: 0/14 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,250 [INFO]   JAEOSI010000232.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,250 [INFO]   JAEOSI010000049.1: 0/13 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,251 [INFO]   JAEOSI010000233.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,252 [INFO]   JAEOSI010000050.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,253 [INFO]   JAEOSI010000051.1: 0/12 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,253 [INFO]   JAEOSI010000234.1: 0/3 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,254 [INFO]   JAEOSI010000235.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,254 [INFO]   JAEOSI010000236.1: 0/4 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,255 [INFO]   JAEOSI010000237.1: 0/2 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,255 [INFO]   JAEOSI010000052.1: 0/7 genes annotated - REMOVED (empty)\n",
      "2026-01-21 11:11:18,256 [INFO]   JAEOSI010000238.1: 0/5 genes annotated - REMOVED (empty)\n",
      "/home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/Wukongarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:18,257 [INFO] Successfully patched GCA_016840425.1_ASM1684042v1.gbk: kept 1 contigs, annotated 5/2100 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:18,259 [INFO] All GBK files patched with architecture annotations\n",
      "2026-01-21 11:11:18,259 [INFO] Starting gap truncation...\n",
      "2026-01-21 11:11:18,260 [INFO] Truncating large gaps in Freyrarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:18,266 [INFO]   JAWBET010000001.1: 545,876 bp -> 20,902 bp (524,974 bp removed)\n",
      "2026-01-21 11:11:18,268 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/Freyrarchaeaceae_truncated.gbk\n",
      "2026-01-21 11:11:18,268 [INFO] Truncating large gaps in Njordarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:18,269 [INFO]   JALWRR010000107.1: 17,870 bp -> 6,609 bp (11,261 bp removed)\n",
      "2026-01-21 11:11:18,270 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/Njordarchaeaceae_truncated.gbk\n",
      "2026-01-21 11:11:18,271 [INFO] Truncating large gaps in Heimdallarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:18,272 [INFO]   DAOVER010000008.1: 89,003 bp -> 11,024 bp (77,979 bp removed)\n",
      "2026-01-21 11:11:18,273 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/Heimdallarchaeaceae_truncated.gbk\n",
      "2026-01-21 11:11:18,274 [INFO] Truncating large gaps in Odinarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:18,332 [INFO]   CP091871.1: 1,418,269 bp -> 33,365 bp (1,384,904 bp removed)\n",
      "2026-01-21 11:11:18,334 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/Odinarchaeaceae_truncated.gbk\n",
      "2026-01-21 11:11:18,335 [INFO] Truncating large gaps in Jordiarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:18,336 [INFO]   JAHQXB010000022.1: 24,208 bp -> 8,153 bp (16,055 bp removed)\n",
      "2026-01-21 11:11:18,337 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/Jordiarchaeaceae_truncated.gbk\n",
      "2026-01-21 11:11:18,337 [INFO] Truncating large gaps in SOKP01_patched.gbk\n",
      "2026-01-21 11:11:18,339 [INFO]   NJBH01000011.1: 107,569 bp -> 8,786 bp (98,783 bp removed)\n",
      "2026-01-21 11:11:18,340 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/SOKP01_truncated.gbk\n",
      "2026-01-21 11:11:18,341 [INFO] Truncating large gaps in Sigynarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:18,354 [INFO]   JAUQYX020000206.1: 27,708 bp -> 6,145 bp (21,563 bp removed)\n",
      "2026-01-21 11:11:18,355 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/Sigynarchaeaceae_truncated.gbk\n",
      "2026-01-21 11:11:18,356 [INFO] Truncating large gaps in Thorarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:18,358 [INFO]   JAGSHN010000012.1: 338,919 bp -> 8,918 bp (330,001 bp removed)\n",
      "2026-01-21 11:11:18,359 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/Thorarchaeaceae_truncated.gbk\n",
      "2026-01-21 11:11:18,360 [INFO] Truncating large gaps in Hodarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:18,374 [INFO]   NJBF01000010.1: 93,451 bp -> 21,195 bp (72,256 bp removed)\n",
      "2026-01-21 11:11:18,375 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/Hodarchaeaceae_truncated.gbk\n",
      "2026-01-21 11:11:18,376 [INFO] Truncating large gaps in Baldrarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:18,378 [INFO]   JAEOSH010000070.1: 9,522 bp -> 8,421 bp (1,101 bp removed)\n",
      "2026-01-21 11:11:18,378 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/Baldrarchaeaceae_truncated.gbk\n",
      "2026-01-21 11:11:18,379 [INFO] Truncating large gaps in Kariarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:18,411 [INFO]   JASBSB010000007.1: 633,630 bp -> 13,191 bp (620,439 bp removed)\n",
      "2026-01-21 11:11:18,412 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/Kariarchaeaceae_truncated.gbk\n",
      "2026-01-21 11:11:18,413 [INFO] Truncating large gaps in MK-D1_patched.gbk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:11:19,011 [INFO]   JAIZWK010000001.1: 4,361,485 bp -> 94,927 bp (4,266,558 bp removed)\n",
      "2026-01-21 11:11:19,013 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/MK-D1_truncated.gbk\n",
      "2026-01-21 11:11:19,014 [INFO] Truncating large gaps in Wukongarchaeaceae_patched.gbk\n",
      "2026-01-21 11:11:19,015 [INFO]   JAEOSI010000007.1: 23,656 bp -> 4,953 bp (18,703 bp removed)\n",
      "2026-01-21 11:11:19,016 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/Wukongarchaeaceae_truncated.gbk\n",
      "2026-01-21 11:11:19,016 [INFO] Truncating large gaps in JABLTI01_patched.gbk\n",
      "2026-01-21 11:11:19,017 [INFO]   JAUWKS010000014.1: 62,672 bp -> 5,029 bp (57,643 bp removed)\n",
      "2026-01-21 11:11:19,018 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/JABLTI01_truncated.gbk\n",
      "2026-01-21 11:11:19,018 [INFO] Truncating large gaps in HEL-GB-B_patched.gbk\n",
      "2026-01-21 11:11:19,022 [INFO]   SUPR01000004.1: 66,728 bp -> 17,895 bp (48,833 bp removed)\n",
      "2026-01-21 11:11:19,023 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/HEL-GB-B_truncated.gbk\n",
      "2026-01-21 11:11:19,023 [INFO] Truncating large gaps in DXJG01_patched.gbk\n",
      "2026-01-21 11:11:19,228 [INFO]   DXJG01000009.1: 338,768 bp -> 27,281 bp (311,487 bp removed)\n",
      "2026-01-21 11:11:19,230 [INFO] Truncated gaps written to /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/DXJG01_truncated.gbk\n",
      "2026-01-21 11:11:19,230 [INFO] All files processed: patched and truncated\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio.Seq import Seq\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "# ============================================================================\n",
    "# CONFIGURATION PARAMETERS\n",
    "# ============================================================================\n",
    "UPSTREAM_BUFFER = 1000      # Max bp to keep upstream of first gene\n",
    "GAP_THRESHOLD = 10000       # Gap size that triggers truncation (25kb)\n",
    "GAP_BUFFER = 1000           # bp to keep on each side of truncated gap\n",
    "MIN_CONTIG_SIZE = 0         # Minimum contig size after truncation (0 = no limit)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class GapStringGenerator:\n",
    "    \"\"\"Generates gap strings with minimal similarity to existing gaps\"\"\"\n",
    "    \n",
    "    def __init__(self, gap_size, num_candidates=500):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            gap_size: Length of each gap string\n",
    "            num_candidates: Number of candidates to evaluate per generation\n",
    "        \"\"\"\n",
    "        self.gap_size = gap_size\n",
    "        self.num_candidates = num_candidates\n",
    "        self.existing_gaps = []\n",
    "        self.nucleotides = ['A', 'C', 'G', 'T']\n",
    "    \n",
    "    def get_next_gap(self):\n",
    "        \"\"\"Generate and return the next gap string\"\"\"\n",
    "        if len(self.existing_gaps) == 0:\n",
    "            # First gap is random\n",
    "            gap = self._random_gap()\n",
    "        else:\n",
    "            # Find gap with minimal similarity to existing gaps\n",
    "            gap = self._find_dissimilar_gap()\n",
    "        \n",
    "        self.existing_gaps.append(gap)\n",
    "        return gap\n",
    "    \n",
    "    def _random_gap(self):\n",
    "        \"\"\"Generate a random nucleotide string\"\"\"\n",
    "        return ''.join(random.choices(self.nucleotides, k=self.gap_size))\n",
    "    \n",
    "    def _find_dissimilar_gap(self):\n",
    "        \"\"\"Find the most dissimilar gap from candidates\"\"\"\n",
    "        best_gap = None\n",
    "        best_min_dissimilarity = -1\n",
    "        \n",
    "        for _ in range(self.num_candidates):\n",
    "            candidate = self._random_gap()\n",
    "            \n",
    "            # Find minimum dissimilarity to any existing gap\n",
    "            min_dissimilarity = min(\n",
    "                self._hamming_distance(candidate, existing)\n",
    "                for existing in self.existing_gaps\n",
    "            )\n",
    "            \n",
    "            # Keep candidate with highest minimum dissimilarity\n",
    "            if min_dissimilarity > best_min_dissimilarity:\n",
    "                best_min_dissimilarity = min_dissimilarity\n",
    "                best_gap = candidate\n",
    "        \n",
    "        return best_gap\n",
    "    \n",
    "    def _hamming_distance(self, s1, s2):\n",
    "        \"\"\"Calculate number of differing positions\"\"\"\n",
    "        return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Clear all existing gaps and start fresh\"\"\"\n",
    "        self.existing_gaps = []\n",
    "    \n",
    "    def get_gap_count(self):\n",
    "        \"\"\"Return number of gaps generated so far\"\"\"\n",
    "        return len(self.existing_gaps)\n",
    "\n",
    "\n",
    "GAP_FEAT_SIZE = 100  # Symbolic gap feature size\n",
    "gap_string_generator = GapStringGenerator(gap_size=GAP_FEAT_SIZE)\n",
    "\n",
    "\n",
    "def has_gene(record):\n",
    "    \"\"\"Check if a record has any CDS or gene features.\"\"\"\n",
    "    return any(f.type in {\"CDS\", \"gene\"} for f in record.features)\n",
    "\n",
    "def patch_gbk_with_architecture(\n",
    "    gbk_path,\n",
    "    arch_df,\n",
    "    gbk_out,\n",
    "    protein_col=\"protein_id\",\n",
    "    arch_col=\"architecture\",\n",
    "    rep_col=\"rep_arch_canonical\"\n",
    "):\n",
    "    \"\"\"\n",
    "    STEP 1: Patch GenBank file with architecture annotations.\n",
    "    Modifies CDS features to include architecture information.\n",
    "    Filters out genes not in lookup and genes with \"other\" architecture.\n",
    "    \"\"\"\n",
    "    print(arch_df.columns)\n",
    "    # Create lookup dictionary\n",
    "    lookup = arch_df.set_index(protein_col).to_dict(\"index\")\n",
    "    logging.info(f\"Lookup keys sample: {list(lookup.keys())[:5]}\")\n",
    "    \n",
    "    logging.info(f\"Patching {gbk_path.name} with {len(lookup)} annotated proteins\")\n",
    "\n",
    "    records = []\n",
    "    total_genes_found = 0\n",
    "    total_genes_annotated = 0\n",
    "\n",
    "    for record in SeqIO.parse(gbk_path, \"genbank\"):\n",
    "        new_features = []\n",
    "        genes_found = 0\n",
    "        genes_annotated = 0\n",
    "\n",
    "        for feat in record.features:\n",
    "            # Keep non-CDS features as-is\n",
    "            if feat.type != \"CDS\":\n",
    "                new_features.append(feat)\n",
    "                continue\n",
    "\n",
    "            genes_found += 1\n",
    "            \n",
    "            # Get protein_id from the CDS feature\n",
    "            pid = feat.qualifiers.get(\"locus_tag\", [None])[0]\n",
    "\n",
    "            if pid is None or pid not in lookup:\n",
    "                # Gene is outside annotation windows - DISCARD\n",
    "                continue\n",
    "\n",
    "            # Get architecture info\n",
    "            info = lookup[pid]\n",
    "            arch = info.get(arch_col, \"other\")\n",
    "            rep = info.get(rep_col, \"NA\")\n",
    "\n",
    "            # Only keep genes with real architecture (discard \"other\")\n",
    "            if arch == \"other\":\n",
    "                continue\n",
    "\n",
    "            genes_annotated += 1\n",
    "\n",
    "            # Modify the CDS feature qualifiers for clinker compatibility\n",
    "            feat.qualifiers[\"gene\"] = [arch]\n",
    "            feat.qualifiers[\"product\"] = [arch]  # Clinker uses this for labeling\n",
    "            \n",
    "            # Add architecture notes\n",
    "            if \"note\" not in feat.qualifiers:\n",
    "                feat.qualifiers[\"note\"] = []\n",
    "            \n",
    "            feat.qualifiers[\"note\"].append(f\"architecture={arch}\")\n",
    "            if rep != \"NA\":\n",
    "                feat.qualifiers[\"note\"].append(f\"representative_arch={rep}\")\n",
    "            \n",
    "            new_features.append(feat)\n",
    "\n",
    "        record.features = new_features\n",
    "        total_genes_found += genes_found\n",
    "        total_genes_annotated += genes_annotated\n",
    "        \n",
    "        # Only keep records that have genes after patching\n",
    "        if has_gene(record):\n",
    "            records.append(record)\n",
    "            logging.info(\n",
    "                f\"  {record.id}: {genes_annotated}/{genes_found} genes annotated - KEPT\"\n",
    "            )\n",
    "        else:\n",
    "            logging.info(\n",
    "                f\"  {record.id}: {genes_annotated}/{genes_found} genes annotated - REMOVED (empty)\"\n",
    "            )\n",
    "\n",
    "    gbk_file = gbk_out / f\"{arch_df['family'].unique()[0]}_patched.gbk\"\n",
    "    print(gbk_file)\n",
    "    \n",
    "    out_gbk_path = gbk_file\n",
    "    \n",
    "    # Write modified records back\n",
    "    with open(out_gbk_path, \"w\") as out_handle:\n",
    "        SeqIO.write(records, out_handle, \"genbank\")\n",
    "    \n",
    "    logging.info(\n",
    "        f\"Successfully patched {gbk_path.name}: \"\n",
    "        f\"kept {len(records)} contigs, \"\n",
    "        f\"annotated {total_genes_annotated}/{total_genes_found} genes\"\n",
    "    )\n",
    "    \n",
    "    return out_gbk_path, len(records), total_genes_annotated\n",
    "\n",
    "\n",
    "def create_gap_feature(start, end, gap_size, gap_id):\n",
    "    \"\"\"Create a CDS feature representing a truncated gap.\"\"\"\n",
    "    gap_label = f\"gap [{gap_size:,} bp]\"\n",
    "    gap_feature = SeqFeature(\n",
    "        FeatureLocation(start, end),\n",
    "        type=\"CDS\",\n",
    "        qualifiers={\n",
    "            \"gene\": [gap_label],\n",
    "            \"product\": [gap_label],\n",
    "            \"note\": [f\"Truncated gap: {gap_size:,} bp removed\"],\n",
    "            \"pseudo\": [\"true\"]\n",
    "        }\n",
    "    )\n",
    "    return gap_feature\n",
    "\n",
    "\n",
    "def truncate_large_gaps(\n",
    "    gbk_path,\n",
    "    gbk_out,\n",
    "    gap_generator,\n",
    "    upstream_buffer=UPSTREAM_BUFFER,\n",
    "    gap_threshold=GAP_THRESHOLD,\n",
    "    gap_buffer=GAP_BUFFER,\n",
    "    min_contig_size=MIN_CONTIG_SIZE\n",
    "):\n",
    "    \"\"\"\n",
    "    STEP 2: Truncate large gaps in already-filtered GenBank files.\n",
    "    \n",
    "    Args:\n",
    "        gbk_path: Path to the filtered/patched GenBank file\n",
    "        gbk_out: Output directory\n",
    "        upstream_buffer: Max bp to keep upstream of first gene\n",
    "        gap_threshold: Gap size that triggers truncation\n",
    "        gap_buffer: bp to keep on each side of a truncated gap\n",
    "        min_contig_size: Minimum contig size after truncation (0 = no limit)\n",
    "    \"\"\"\n",
    "    logging.info(f\"Truncating large gaps in {gbk_path.name}\")\n",
    "    \n",
    "    # Create truncated subdirectory\n",
    "    truncated_dir = gbk_out / \"truncated\"\n",
    "    truncated_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    for record in SeqIO.parse(gbk_path, \"genbank\"):\n",
    "        # Get only CDS features\n",
    "        cds_features = [f for f in record.features if f.type == \"CDS\"]\n",
    "        non_cds_features = [f for f in record.features if f.type != \"CDS\"]\n",
    "        \n",
    "        if not cds_features:\n",
    "            records.append(record)\n",
    "            continue\n",
    "        \n",
    "        # Sort CDS features by start position\n",
    "        sorted_cds = sorted(cds_features, key=lambda f: f.location.start)\n",
    "        \n",
    "        # Calculate truncation map and build new sequence\n",
    "        position_map = {}\n",
    "        new_pos = 0\n",
    "        new_features = []\n",
    "        new_seq_parts = []\n",
    "        \n",
    "        # Handle upstream region before first gene\n",
    "        first_gene_start = sorted_cds[0].location.start\n",
    "        upstream_start = max(0, first_gene_start - upstream_buffer)\n",
    "        \n",
    "        # Add upstream sequence\n",
    "        if upstream_start < first_gene_start:\n",
    "            new_seq_parts.append(record.seq[upstream_start:first_gene_start])\n",
    "            for i in range(upstream_start, first_gene_start):\n",
    "                position_map[i] = new_pos\n",
    "                new_pos += 1\n",
    "        \n",
    "        # Process each gene and gaps between them\n",
    "        for i, feat in enumerate(sorted_cds):\n",
    "            gene_start = feat.location.start\n",
    "            gene_end = feat.location.end\n",
    "            \n",
    "            # Map gene positions\n",
    "            for pos in range(gene_start, gene_end):\n",
    "                position_map[pos] = new_pos\n",
    "                new_pos += 1\n",
    "            \n",
    "            # Add gene sequence\n",
    "            new_seq_parts.append(record.seq[gene_start:gene_end])\n",
    "            \n",
    "            # Update feature location\n",
    "            new_feat = SeqFeature(\n",
    "                FeatureLocation(position_map[gene_start], new_pos, strand=feat.location.strand),\n",
    "                type=feat.type,\n",
    "                qualifiers=feat.qualifiers.copy()\n",
    "            )\n",
    "            new_features.append(new_feat)\n",
    "            \n",
    "            # Handle gap to next gene\n",
    "            if i < len(sorted_cds) - 1:\n",
    "                next_gene_start = sorted_cds[i + 1].location.start\n",
    "                gap_size = next_gene_start - gene_end\n",
    "                \n",
    "                if gap_size > gap_threshold:\n",
    "                    # Large gap - truncate it\n",
    "                    # Keep gap_buffer on current gene side\n",
    "                    buffer_end = gene_end + gap_buffer\n",
    "                    for pos in range(gene_end, buffer_end):\n",
    "                        position_map[pos] = new_pos\n",
    "                        new_pos += 1\n",
    "                    new_seq_parts.append(record.seq[gene_end:buffer_end])\n",
    "                    \n",
    "                    # Add gap feature\n",
    "                    gap_feat_start = new_pos\n",
    "                    gap_feat_size = gap_generator.gap_size\n",
    "                    gap_feat = create_gap_feature(gap_feat_start, gap_feat_start + gap_feat_size, gap_size - 2 * gap_buffer, None)\n",
    "                    new_features.append(gap_feat)\n",
    "                    \n",
    "                    # Add placeholder sequence for gap feature (Ns)\n",
    "                    new_seq_parts.append(Seq(gap_generator.get_next_gap()))\n",
    "                    new_pos += gap_feat_size\n",
    "                    \n",
    "                    # Keep gap_buffer on next gene side\n",
    "                    buffer_start = next_gene_start - gap_buffer\n",
    "                    for pos in range(buffer_start, next_gene_start):\n",
    "                        position_map[pos] = new_pos\n",
    "                        new_pos += 1\n",
    "                    new_seq_parts.append(record.seq[buffer_start:next_gene_start])\n",
    "                else:\n",
    "                    # Small gap - keep it all\n",
    "                    for pos in range(gene_end, next_gene_start):\n",
    "                        position_map[pos] = new_pos\n",
    "                        new_pos += 1\n",
    "                    new_seq_parts.append(record.seq[gene_end:next_gene_start])\n",
    "        \n",
    "        # Create new record\n",
    "        new_record = record[:]\n",
    "        new_record.seq = sum(new_seq_parts, Seq(\"\"))\n",
    "        new_record.features = new_features\n",
    "        \n",
    "        # Check minimum contig size\n",
    "        if min_contig_size > 0 and len(new_record.seq) < min_contig_size:\n",
    "            logging.info(\n",
    "                f\"  {record.id}: {len(record.seq):,} bp -> {len(new_record.seq):,} bp \"\n",
    "                f\"- DISCARDED (below minimum size {min_contig_size:,} bp)\"\n",
    "            )\n",
    "            continue\n",
    "        \n",
    "        logging.info(\n",
    "            f\"  {record.id}: {len(record.seq):,} bp -> {len(new_record.seq):,} bp \"\n",
    "            f\"({len(record.seq) - len(new_record.seq):,} bp removed)\"\n",
    "        )\n",
    "        \n",
    "        records.append(new_record)\n",
    "    \n",
    "    # Output file in truncated subdirectory\n",
    "    out_path = truncated_dir / gbk_path.name.replace(\"_patched.gbk\", \"_truncated.gbk\")\n",
    "    \n",
    "    with open(out_path, \"w\") as out_handle:\n",
    "        SeqIO.write(records, out_handle, \"genbank\")\n",
    "    \n",
    "    logging.info(f\"Truncated gaps written to {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "# STEP 1: Patch all GBK files with architecture annotations\n",
    "for family, fam_df in tqdm(rep_df.groupby(\"family\")):\n",
    "    fam_dir = GBK_OUT_DIR / family\n",
    "    \n",
    "    logging.info(f\"Patching family: {family} ({len(fam_df)} annotations)\")\n",
    "\n",
    "    for gbk_file in fam_dir.glob(\"*.gbk\"):\n",
    "        # Extract genome_id from filename\n",
    "        genome_id = gbk_file.stem  # removes .gbk extension\n",
    "        \n",
    "        # Filter annotations for this specific genome\n",
    "        genome_df = fam_df[fam_df[\"genome_id\"] == genome_id]\n",
    "        \n",
    "        if genome_df.empty:\n",
    "            logging.warning(f\"No annotations found for {genome_id}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        patched_path, num_contigs, num_genes = patch_gbk_with_architecture(\n",
    "            gbk_path=gbk_file,\n",
    "            arch_df=genome_df,\n",
    "            gbk_out=gbk_out\n",
    "        )\n",
    "\n",
    "logging.info(\"All GBK files patched with architecture annotations\")\n",
    "\n",
    "# STEP 2: Truncate large gaps in patched files\n",
    "logging.info(\"Starting gap truncation...\")\n",
    "\n",
    "for patched_file in gbk_out.glob(\"*_patched.gbk\"):\n",
    "    truncate_large_gaps(\n",
    "        gbk_path=patched_file,\n",
    "        gbk_out=gbk_out,\n",
    "        gap_generator=gap_string_generator,\n",
    "        upstream_buffer=UPSTREAM_BUFFER,\n",
    "        gap_threshold=GAP_THRESHOLD,\n",
    "        gap_buffer=GAP_BUFFER,\n",
    "        min_contig_size=MIN_CONTIG_SIZE\n",
    "    )\n",
    "\n",
    "logging.info(\"All files processed: patched and truncated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1f5d8536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 11:14:00,344 [INFO] Clinker command for synteny visualization:\n",
      "conda activate clinker\n",
      "clinker /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/*.gbk -o /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/ESCRT_SYNTENY --plot /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/GBK_patched_dir/truncated/ESCRT_synteny.html -gf /home/anirudh/synteny/hmms/ESCRT_synteny_pipeline_output_family_2026-01-21-11-08-12/architecture_results_2026-01-21-11-08-12/[STEP:17.9]representative_genomes_gene_function_annotation.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "code_block = f\"conda activate clinker\\nclinker {gbk_out / 'truncated'}/*.gbk -o {gbk_out / 'truncated'}/ESCRT_SYNTENY --plot {gbk_out / 'truncated'}/ESCRT_synteny.html -gf {annotation_csv}\"\n",
    "\n",
    "logging.info(\"Clinker command for synteny visualization:\\n%s\", code_block)\n",
    "\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
